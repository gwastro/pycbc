; PLEASE NOTE, SECTION NAMES AND OPTIONS SHOULD BE BLOCK LOWER CASE
; VALUES CAN BE MIXED CASE

[ahope]
; https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/initialization.html
; provides details of how to set up an ahope configuration .ini file
h1-channel-name = H1:LDAS-STRAIN
l1-channel-name = L1:LDAS-STRAIN
;h2-channel-name = H2:LDAS-STRAIN
ahope-html-basedir = /home/spxiwh/public_html/ahope/development/weekly_ahope/test
pipedown-tmp-space = /usr1/spxiwh

[ahope-ifos]
; This is the list of ifos to analyse
h1 =
l1 =

[ahope-datafind]
; See https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/datafind.html
datafind-method = AT_RUNTIME_SINGLE_FRAMES
datafind-h1-frame-type = H1_LDAS_C02_L2
datafind-l1-frame-type = L1_LDAS_C02_L2
;datafind-h2-frame-type = H2_LDAS_C02_L2
datafind-check-segment-gaps = update_times
datafind-check-frames-exist = raise_error
datafind-check-segment-summary = no_test
; Set this to sepcify the datafind server. If this is not set the code will
; use the value in ${LIGO_DATAFIND_SERVER}
;datafind-ligo-datafind-server = ""

[ahope-segments]
; See https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/segments.html
; PIPEDOWN demands we use AT_RUNTIME
segments-method = AT_RUNTIME
segments-H1-science-name = H1:DMT-SCIENCE:4
segments-L1-science-name = L1:DMT-SCIENCE:4
;segments-V1-science-name = V1:ITF_SCIENCEMODE:6
segments-database-url = https://segdb.ligo.caltech.edu
segments-veto-definer-url = https://www.lsc-group.phys.uwm.edu/ligovirgo/cbc/public/segments/S6/H1L1V1-S6_CBC_LOWMASS_B_OFFLINE-937473702-0.xml
segments-maximum-veto-category = 5
segments-minimum-segment-length = 2000
segments-generate-coincident-segments =

[ahope-tmpltbank]
; See https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/template_bank.html
tmpltbank-method=WORKFLOW_INDEPENDENT_IFOS
; Remove the option below to disable linking with matchedfilter_utils
tmpltbank-link-to-matchedfltr=

[ahope-injections]
; See https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/injections.html
injections-method=IN_WORKFLOW

[ahope-timeslides]
; See https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/time_slides.html
timeslides-method=AT_RUNTIME
timeslides-exe = tisi

[ahope-splittable]
splittable-method=IN_WORKFLOW
splittable-num-banks=20

[ahope-matchedfilter]
; See https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/matched_filter.html
matchedfilter-method=WORKFLOW_INDEPENDENT_IFOS

[ahope-coincidence]
; See See https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/coincidence.html
coincidence-method=WORKFLOW_DISCRETE_SLIDES 

[ahope-postprocprep]
; See See https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/postpropprep.html
postprocprep-method=PIPEDOWN_AHOPE
; Avoiding namespace collisions with pipedown.ini until that gets removed
postprocprep-combiner1-exe=pycbcsqlite
postprocprep-combiner2-exe=pycbcsqlite
postprocprep-cluster-exe=clustercoincs
postprocprep-injfind-exe=databaseinjfind

[ahope-postproc]
; See See https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/postprop.html
postproc-method=PIPEDOWN_AHOPE
postproc-computedurations-exe=computedurs
postproc-cfar-exe=pycbccfar

[executables]
; setup of condor universe and location of executables
tmpltbank         = ${which:lalapps_tmpltbank_ahope}
inspiral          = ${which:lalapps_inspiral_ahope}
splittable = ${which:pycbc_splitbank}
segment_query = ${which:ligolw_segment_query}
segments_from_cats = ${which:ligolw_segments_from_cats}
llwadd = ${which:ligolw_add}
ligolw_combine_segments = ${which:ligolw_combine_segments}
injections = ${which:lalapps_inspinj}
thinca = ${which:ligolw_sstinca}
tisi = ${which:pycbc_timeslides}
write_ihope_page = ${which:lalapps_write_ihope_page}
pycbcsqlite = ${which:pycbc_sqlite_simplify}
clustercoincs = ${which:ligolw_cbc_cluster_coincs}
databaseinjfind = ${which:ligolw_dbinjfind}
computedurs = ${which:pycbc_compute_durations}
pycbccfar = ${which:pycbc_calculate_far}

[datafind]
urltype=file

[segments_from_cats]

[ligolw_combine_segments]

[inspiral&tmpltbank]
; These options added to both inspiral and tmpltbank jobs
low-frequency-cutoff = 40.0
calibrated-data = real_8
dynamic-range-exponent = 69.0
strain-high-pass-freq = 30
strain-high-pass-order = 8
strain-high-pass-atten = 0.1
enable-high-pass = 30.0
high-pass-order = 8
high-pass-attenuation = 0.1
resample-filter = ldas
spectrum-type = median

[tmpltbank]
; template bank generation parameters -- added to all tmpltbank jobs
pad-data = 8
segment-length = 1048576
number-of-segments = 15
sample-rate = 4096
grid-spacing = Hexagonal
minimal-match = 0.97
high-frequency-cutoff = 2048.0
order = twoPN
approximant = TaylorF2
space = Tau0Tau3
write-compress = 
num-freq-cutoffs = 1
max-high-freq-cutoff = SchwarzISCO
min-high-freq-cutoff = SchwarzISCO
minimum-mass = 1.0
maximum-mass = 25.0
max-total-mass = 25.0
;disable-compute-moments =

[tmpltbank-h1]
; h1 specific tmpltbank parameters
channel-name = ${ahope|h1-channel-name}

;[tmpltbank-h2]
; h2 specific tmpltbank parameters
;channel-name = ${ahope|h2-channel-name}

[tmpltbank-l1]
; l1 specific tmpltbank parameters
channel-name = ${ahope|l1-channel-name}

[splittable]
; options for splittable job
random-sort =

[inspiral]
; inspiral analysis parameters -- added to all inspiral jobs
pad-data = 8
segment-length = 1048576
number-of-segments = 15
sample-rate = 4096
approximant = FindChirpSP
order = threePointFivePN
segment-overlap = 524288
inverse-spec-length = 16
enable-output = 
cluster-method = template
maximization-interval = 30
write-compress = 
bank-veto-subbank-size = 20
bank-veto-time-freq =
autochisq-length = 100
autochisq-stride = 2
autochisq-two-sided =
chisq-bins = 16
enable-rsq-veto =
rsq-veto-window = 6.0
rsq-veto-threshold = 15.0
do-rsq-veto =
rsq-veto-time-thresh = 0.0002
rsq-veto-max-snr = 12.0
enable-filter-inj-only =
snr-threshold = 5.5
chisq-threshold = 10.0
chisq-delta = 0.2

[inspiral-h1]
; h1 specific inspiral parameters
channel-name = ${ahope|h1-channel-name}

[inspiral-l1]
; l1 specific inspiral parameters
channel-name = ${ahope|l1-channel-name}

;[inspiral-h2]
; h2 specific inspiral parameters
;channel-name =${ahope|h2-channel-name}

[llwadd]

[thinca]
drop-veto-info =
make-expr-tables =
e-thinca-parameter = 0.5
weighted-snr = newsnr
magic-number = 6.0 
depop-sngl-inspiral =

[tisi]

[tisi-zerolag]
tisi-slides = H1=0:0:0 L1=0:0:0

[tisi-slides]
inspiral-num-slides = 100:H1=0,L1=5
remove-zero-lag =

[pycbcsqlite]
tmp-space = ${ahope|pipedown-tmp-space}
vacuum =

[clustercoincs]
cluster-window = 10000
ranking-table = coinc_inspiral
ranking-stat = snr
rank-by = MAX
;   following are optional
param-name = mchirp
param-ranges = [0,3.48);[3.48,7.4);[7.4,20]
group-by-ifos =
tmp-space = ${ahope|pipedown-tmp-space}
time-column = end_time
;exclude-coincs = [ALLinH1,H2];[H1,H2inALL];[H2,L1inH1,H2,L1]
; Commenting vacuum as we'll let the combiner do this.
;vacuum =

[databaseinjfind]
simulation-table = sim_inspiral
recovery-table = sngl_inspiral
match-criteria = endTime:endTime:1.0
map-label = insp_nearby
rough-match = geocent_end_time:end_time:10
search = inspiral
tmp-space = ${ahope|pipedown-tmp-space}

[computedurs]
;   set options for compute_durations jobs
livetime-program = inspiral

[pycbccfar]
uncombined-far-column = false_alarm_rate
combined-far-column = combined_far
ranking-table = coinc_inspiral
ranking-stat = snr
rank-by = MAX
param-name = mchirp
param-ranges = [0,3.48);[3.48,7.4);[7.4,20]
group-by-ifos =

