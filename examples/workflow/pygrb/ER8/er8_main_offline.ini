; PLEASE NOTE, SECTION NAMES AND OPTIONS SHOULD BE BLOCK LOWER CASE
; VALUES CAN BE MIXED CASE

[workflow]
; https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/initialization.html
; provides details of how to set up a pycbc workflow configuration .ini file
file-retention-level = all_files
h1-channel-name = H1:GDS-CALIB_STRAIN
l1-channel-name = L1:GDS-CALIB_STRAIN

[workflow-ifos]
; This is the list of ifos to analyse
h1 =
l1 =

[workflow-datafind]
; See https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/datafind.html
datafind-method = AT_RUNTIME_SINGLE_CACHES
datafind-h1-frame-type = H1_HOFT_C00
datafind-l1-frame-type = L1_HOFT_C00
datafind-check-segment-gaps = update_times
datafind-check-frames-exist = raise_error
datafind-check-segment-summary = no_test

[workflow-segments]
; See https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/segments.html
segments-method = AT_RUNTIME
segments-h1-science-name = H1:DMT-ANALYSIS_READY:1
segments-l1-science-name = L1:DMT-ANALYSIS_READY:1
segments-database-url = https://segments.ligo.org
segments-veto-definer-url = https://code.pycbc.phy.syr.edu/detchar/veto-definitions/download/master/cbc/ER8/H1L1-HOFT_C00_ER8A_CBC.xml
segments-veto-categories = 3
segments-minimum-segment-length = 256

[workflow-tmpltbank]
; See https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/template_bank.html
tmpltbank-method=PREGENERATED_BANK
; The bank is available on CIT
;tmpltbank-pregenerated-bank=/home/francesco.pannarale/LLMDC/BNS_NSBH_EMbright_bank.xml.gz
; This bank is available on ARCCA:
tmpltbank-pregenerated-bank=/home/c1239174/ER8/BANKS/BNS_NSBH_EMbright_bank_O1_test.xml.gz

[workflow-timeslides]
; See https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/time_slides.html
timeslides-method=AT_RUNTIME
timeslides-exe = tisi

[workflow-splittable]
splittable-method=IN_WORKFLOW

[workflow-splittable-inspiral]
splittable-num-banks = 100
splittable-exe-tag = splitbank

[workflow-matchedfilter]
; See https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/ahope/matched_filter.html
matchedfilter-method=WORKFLOW_MULTIPLE_IFOS

[executables]
; setup of condor universe and location of executables
tmpltbank               = ${which:lalapps_tmpltbank_ahope}
inspiral                = ${which:lalapps_coh_PTF_inspiral}
splitbank               = ${which:pycbc_splitbank}
segment_query           = ${which:ligolw_segment_query_dqsegdb}
segments_from_cats      = ${which:ligolw_segments_from_cats_dqsegdb}
llwadd                  = ${which:ligolw_add}
ligolw_combine_segments = ${which:ligolw_combine_segments}

[datafind]
urltype=file

[segments_from_cats]

[ligolw_combine_segments]

[tmpltbank]

[tmpltbank-h1]
; h1 specific tmpltbank parameters
channel-name = ${workflow|h1-channel-name}

[tmpltbank-l1]
; l1 specific tmpltbank parameters
channel-name = ${workflow|l1-channel-name}

[splitbank]
; options for splittable job
random-sort =

[inspiral]
; coh_PTF_inspiral analysis parameters -- added to all inspiral jobs
; Note that some values are dynamically recalculated during workflow generation
ligo-calibrated-data = real_8
low-template-freq = 40.0
highpass-frequency = 35
snr-threshold = 6.
trig-time-window = 1
low-template-freq = 38
low-filter-freq = 40
high-filter-freq = 1000
strain-data =
sample-rate = 4096
segment-duration = 256
block-duration = 5248
;do-sngl-chi-tests =
do-trace-snr =
;do-null-stream
do-bank-veto =
do-auto-veto =
do-chi-square =
num-auto-chisq-points = 40
auto-veto-time-step = 0.001
num-chi-square-bins = 16
chi-square-threshold = 6
approximant = SpinTaylorFrameless
order = threePointFivePN
sngl-snr-threshold = 4
psd-segment-duration = 256
do-clustering =
cluster-window = 0.1
inverse-spec-length = 32
face-on-analysis =
face-away-analysis =

[inspiral-no_injections]
do-short-slides =
short-slide-offset = 6

[inspiral-injections]
inj-search-window = 1
inj-mchirp-window = 0.05
analyze-inj-segs-only =

[inspiral-h1]
; h1 specific inspiral parameters
h1-channel-name = ${workflow|h1-channel-name}

[inspiral-l1]
; l1 specific inspiral parameters
l1-channel-name = ${workflow|l1-channel-name}

[pegasus_profile-inspiral]
condor|request_memory=1300M

[workflow-exttrig_segments]
; options for the coherent search (development)
on-before = 5
on-after = 1
min-before = 64
min-after = 64
min-duration = 256
max-duration = 5264
quanta = 128
num-buffer-before = 8
num-buffer-after = 8

[inspiral&workflow-exttrig_segments]
pad-data = 8
