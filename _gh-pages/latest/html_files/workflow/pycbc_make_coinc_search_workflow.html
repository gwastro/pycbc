<!DOCTYPE html>
<html class="writer-html4" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pycbc_make_coinc_search_workflow: A workflow to search for gravitational waves &mdash; PyCBC 0.0a8230 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/plot_directive.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/terminal.css" type="text/css" />
      <link rel="stylesheet" href="../_static/theme_overrides.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script type="text/javascript" src="../_static/typed.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="pycbc_make_offline_grb_workflow: A GRB triggered CBC analysis workflow generator" href="pygrb.html" />
    <link rel="prev" title="pycbc_make_psd_estimation_workflow: A workflow generator for noise estimation" href="pycbc_make_psd_estimation_workflow.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> PyCBC
          </a>
              <div class="version">
                1.18.3
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../credit.html">Use of PyCBC in Scientific Publications</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../docker.html">Running PyCBC under Docker</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing PyCBC</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../inference.html">PyCBC inference documentation (<code class="docutils literal notranslate"><span class="pre">pycbc.inference</span></code>)</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="pycbc_make_psd_estimation_workflow.html"><code class="docutils literal notranslate"><span class="pre">pycbc_make_psd_estimation_workflow</span></code>: A workflow generator for noise estimation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#"><code class="docutils literal notranslate"><span class="pre">pycbc_make_coinc_search_workflow</span></code>: A workflow to search for gravitational waves</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#configuration-file">Configuration file</a></li>
<li class="toctree-l2"><a class="reference internal" href="#generating-the-workflow">Generating the workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="#planning-and-submitting-the-workflow">Planning and Submitting the Workflow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#monitor-and-debug-the-workflow-detailed-pegasus-documentation">Monitor and Debug the Workflow (Detailed Pegasus Documentation)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pegasus-dashboard">Pegasus Dashboard</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pegasus-analyzer">Pegasus Analyzer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#reuse-of-data-from-a-previous-workflow">Reuse of data from a previous workflow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#setting-up-a-workflow-for-data-reuse">Setting up a workflow for data reuse</a></li>
<li class="toctree-l3"><a class="reference internal" href="#extending-the-gps-end-time-of-a-previous-workflow">Extending the GPS end time of a previous workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#re-running-a-workflow-using-a-new-veto-definer-file">Re-running a workflow using a new veto definer file</a></li>
<li class="toctree-l3"><a class="reference internal" href="#re-running-a-failed-workflow">Re-running a failed workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-partial-products-from-a-previous-workflow">Using partial products from a previous workflow</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#running-on-the-open-science-grid">Running on the Open Science Grid</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configuring-the-workflow">Configuring the workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#running-the-workflow">Running the workflow</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pygrb.html"><code class="docutils literal notranslate"><span class="pre">pycbc_make_offline_grb_workflow</span></code>: A GRB triggered CBC analysis workflow generator</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tmpltbank.html">PyCBC template bank generation documentation (<code class="docutils literal notranslate"><span class="pre">pycbc.tmpltbank</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hwinj.html">Hardware injection waveform generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../banksim.html">Calculating the Effectualness (Fitting Factor) of Template Banks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faithsim.html">Dag Generator for Doing Faithfulness Comparisons</a></li>
<li class="toctree-l1"><a class="reference internal" href="../upload_to_gracedb.html">Uploading triggers to gracedb</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../waveform_plugin.html">Making new waveform approximants available to PyCBC</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../catalog.html">Catalog of Observed Gravitational-wave Mergers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataquality.html">Query times of valid data, hardware injections, and more.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frame.html">Reading Gravitational-wave Frames</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fft.html">Performing FFTs in PyCBC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gw150914.html">Signal Processing with GW150914</a></li>
<li class="toctree-l1"><a class="reference internal" href="../detector.html">Gravitational-wave Detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../psd.html">Handling PSDs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../noise.html">Generating Noise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../waveform.html">Waveforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../filter.html">Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributions.html">Using PyCBC Distributions from PyCBC Inference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../building_bundled_executables.html">Building Bundled Executables</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../documentation.html">Documenting PyCBC code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release.html">Creating Releases of PyCBC</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../formats/hdf_format.html">HDF files within the PyCBC workflow</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../workflow.html">Workflow: the inspiral analysis workflow generator (<code class="docutils literal notranslate"><span class="pre">pycbc.workflow</span></code>)</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">pycbc</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PyCBC</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li><code class="docutils literal notranslate"><span class="pre">pycbc_make_coinc_search_workflow</span></code>: A workflow to search for gravitational waves</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/workflow/pycbc_make_coinc_search_workflow.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="pycbc-make-coinc-search-workflow-a-workflow-to-search-for-gravitational-waves">
<h1><code class="docutils literal notranslate"><span class="pre">pycbc_make_coinc_search_workflow</span></code>: A workflow to search for gravitational waves<a class="headerlink" href="#pycbc-make-coinc-search-workflow-a-workflow-to-search-for-gravitational-waves" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>The executable <code class="docutils literal notranslate"><span class="pre">pycbc_make_coinc_search_workflow</span></code> is a tool used to search
for gravitational waves using data from a network of gravitational-wave
detectors.  It performs all of the necessary steps in the workflow, including
data management, template bank construction (if required), matched filtering
and signal-based vetoes, multi-detector coincidence, data-quality cuts,
background estimation, and software injections to test the search. Its
ultimate task is to determine whether or not a compact binary coalescence is
present in the given data.  The output is a webpage containing the plots that
can be used to understand the results of the analysis</p>
</div>
<div class="section" id="configuration-file">
<span id="configurationfiles"></span><h2>Configuration file<a class="headerlink" href="#configuration-file" title="Permalink to this headline">¶</a></h2>
<p>The behavior of the workflow is controlled by a configuration file (also known as an <code class="docutils literal notranslate"><span class="pre">ini</span></code> file) that is made up of three types of sections: workflow, the pegasus profile and the executable options. The workflow sections control how different parts of the the workflow hang together. The pegasus profile sections are equivalent to lines you would have in a condor_submit file (e.g. requirements, storage size etc). Anything you would do in condor you would do here. The third section type maps the options to an executable.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">pegasus_profile</span><span class="p">]</span>
<span class="n">condor</span><span class="o">|</span><span class="n">accounting_group</span><span class="o">=</span><span class="n">ligo</span><span class="o">.</span><span class="n">dev</span><span class="o">.</span><span class="n">o1</span><span class="o">.</span><span class="n">cbc</span><span class="o">.</span><span class="n">bns_spin</span><span class="o">.</span><span class="n">pycbcoffline</span>
</pre></div>
</div>
<p>This is used for keeping an account of the pycbc usage</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">workflow</span><span class="p">]</span>
<span class="p">;</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">ldas</span><span class="o">-</span><span class="n">jobs</span><span class="o">.</span><span class="n">ligo</span><span class="o">.</span><span class="n">caltech</span><span class="o">.</span><span class="n">edu</span><span class="o">/~</span><span class="n">cbc</span><span class="o">/</span><span class="n">docs</span><span class="o">/</span><span class="n">pycbc</span><span class="o">/</span><span class="n">workflow</span><span class="o">/</span><span class="n">initialization</span><span class="o">.</span><span class="n">html</span>
<span class="n">h1</span><span class="o">-</span><span class="n">channel</span><span class="o">-</span><span class="n">name</span> <span class="o">=</span> <span class="n">H1</span><span class="p">:</span><span class="n">GDS</span><span class="o">-</span><span class="n">FAKE_STRAIN</span>
<span class="n">l1</span><span class="o">-</span><span class="n">channel</span><span class="o">-</span><span class="n">name</span> <span class="o">=</span> <span class="n">L1</span><span class="p">:</span><span class="n">GDS</span><span class="o">-</span><span class="n">CALIB_STRAIN</span>
<span class="n">file</span><span class="o">-</span><span class="n">retention</span><span class="o">-</span><span class="n">level</span> <span class="o">=</span> <span class="n">all_triggers</span>
</pre></div>
</div>
<p>You tend to put things in here which will be referred to later (but you can leave it empty). This is a nice way to keep options the same without the need to repeatedly define them. Here the L1/H1 data channel name are given. We also add an option to keep all the triggers/plots the analysis produces</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">workflow</span><span class="o">-</span><span class="n">ifos</span><span class="p">]</span>
<span class="n">l1</span> <span class="o">=</span>
<span class="n">h1</span> <span class="o">=</span>
</pre></div>
</div>
<p>Set up which detectors you are going to run over. A blank space after an equals sign denotes True.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">workflow</span><span class="o">-</span><span class="n">datafind</span><span class="p">]</span>
<span class="p">;</span> <span class="n">See</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">ldas</span><span class="o">-</span><span class="n">jobs</span><span class="o">.</span><span class="n">ligo</span><span class="o">.</span><span class="n">caltech</span><span class="o">.</span><span class="n">edu</span><span class="o">/~</span><span class="n">cbc</span><span class="o">/</span><span class="n">docs</span><span class="o">/</span><span class="n">pycbc</span><span class="o">/</span><span class="n">workflow</span><span class="o">/</span><span class="n">datafind</span><span class="o">.</span><span class="n">html</span>
<span class="n">datafind</span><span class="o">-</span><span class="n">method</span> <span class="o">=</span> <span class="n">AT_RUNTIME_SINGLE_FRAMES</span>
<span class="n">datafind</span><span class="o">-</span><span class="n">h1</span><span class="o">-</span><span class="n">frame</span><span class="o">-</span><span class="nb">type</span> <span class="o">=</span> <span class="n">H1_ER_C00_AGG</span>
<span class="n">datafind</span><span class="o">-</span><span class="n">l1</span><span class="o">-</span><span class="n">frame</span><span class="o">-</span><span class="nb">type</span> <span class="o">=</span> <span class="n">L1_ER_C01_L1</span>
<span class="n">datafind</span><span class="o">-</span><span class="n">check</span><span class="o">-</span><span class="n">segment</span><span class="o">-</span><span class="n">gaps</span> <span class="o">=</span> <span class="n">update_times</span>
<span class="n">datafind</span><span class="o">-</span><span class="n">check</span><span class="o">-</span><span class="n">frames</span><span class="o">-</span><span class="n">exist</span> <span class="o">=</span> <span class="n">raise_error</span>
<span class="n">datafind</span><span class="o">-</span><span class="n">check</span><span class="o">-</span><span class="n">segment</span><span class="o">-</span><span class="n">summary</span> <span class="o">=</span> <span class="n">no_test</span>
</pre></div>
</div>
<p>This section defines which frames we are going to use and employs different levels of checks to see whether the data exists, there are gaps etc.</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">‘datafind-method’</span></code> states how we are going to find the frames. The ‘AT_RUNTIME_SINGLE_FRAMES’ means the executable returns a list of single frame files. You can however provide a cache file, but then the options need to be changed.</li>
<li><code class="docutils literal notranslate"><span class="pre">‘datafind-h1-frame-type’</span></code> refers to the frame type the H1 channel name will be found in for the time specified. Same for L1.</li>
<li><code class="docutils literal notranslate"><span class="pre">‘datafind-check-segment-gaps’</span></code> option checks to see if there are gaps in the segments from the segment database and the option ‘update_times’ will change the analysis times to skip over these gaps.</li>
<li><code class="docutils literal notranslate"><span class="pre">‘datafind-check-frames-exist’</span></code> checks to see if the frames you are looking at actually exists, and if they don’t the ‘raise_error’ option will stop the workflow.</li>
<li><code class="docutils literal notranslate"><span class="pre">‘datafind-check-segment-summary’</span></code> Checks the segment summary table and makes sure that the frames exist for all times that the segments are known</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">workflow</span><span class="o">-</span><span class="n">segments</span><span class="p">]</span>
<span class="p">;</span> <span class="n">See</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">ldas</span><span class="o">-</span><span class="n">jobs</span><span class="o">.</span><span class="n">ligo</span><span class="o">.</span><span class="n">caltech</span><span class="o">.</span><span class="n">edu</span><span class="o">/~</span><span class="n">cbc</span><span class="o">/</span><span class="n">docs</span><span class="o">/</span><span class="n">pycbc</span><span class="o">/</span><span class="n">workflow</span><span class="o">/</span><span class="n">segments</span><span class="o">.</span><span class="n">html</span>
<span class="n">segments</span><span class="o">-</span><span class="n">method</span> <span class="o">=</span> <span class="n">AT_RUNTIME</span>
<span class="n">segments</span><span class="o">-</span><span class="n">h1</span><span class="o">-</span><span class="n">science</span><span class="o">-</span><span class="n">name</span> <span class="o">=</span> <span class="n">H1</span><span class="p">:</span><span class="n">DMT</span><span class="o">-</span><span class="n">SCIENCE</span><span class="p">:</span><span class="mi">1</span>
<span class="n">segments</span><span class="o">-</span><span class="n">l1</span><span class="o">-</span><span class="n">science</span><span class="o">-</span><span class="n">name</span> <span class="o">=</span> <span class="n">L1</span><span class="p">:</span><span class="n">DMT</span><span class="o">-</span><span class="n">ANALYSIS_READY</span><span class="p">:</span><span class="mi">1</span>
<span class="n">segments</span><span class="o">-</span><span class="n">database</span><span class="o">-</span><span class="n">url</span> <span class="o">=</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">dqsegdb5</span><span class="o">.</span><span class="n">phy</span><span class="o">.</span><span class="n">syr</span><span class="o">.</span><span class="n">edu</span>
<span class="n">segments</span><span class="o">-</span><span class="n">veto</span><span class="o">-</span><span class="n">definer</span><span class="o">-</span><span class="n">url</span> <span class="o">=</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">lsc</span><span class="o">-</span><span class="n">group</span><span class="o">.</span><span class="n">phys</span><span class="o">.</span><span class="n">uwm</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">ligovirgo</span><span class="o">/</span><span class="n">cbc</span><span class="o">/</span><span class="n">public</span><span class="o">/</span><span class="n">segments</span><span class="o">/</span><span class="n">ER6</span><span class="o">/</span><span class="n">H1L1V1</span><span class="o">-</span><span class="n">ER6_GDS_CALIB_STRAIN</span><span class="o">.</span><span class="n">xml</span>
<span class="n">segments</span><span class="o">-</span><span class="n">science</span><span class="o">-</span><span class="n">veto</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">segments</span><span class="o">-</span><span class="n">veto</span><span class="o">-</span><span class="n">groups</span> <span class="o">=</span>
<span class="n">segments</span><span class="o">-</span><span class="n">final</span><span class="o">-</span><span class="n">veto</span><span class="o">-</span><span class="n">group</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>This section does a series of checks to the segment database for the segments you need for your analysis.</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">‘segments-method’</span></code> option should not change.</li>
<li><code class="docutils literal notranslate"><span class="pre">‘segments-h1-science-name’</span></code> option specifies the segment name at LHO we consider to flag science time. The same is given for L1.</li>
<li><code class="docutils literal notranslate"><span class="pre">‘segments-data-url’</span></code> specifies the url for the segment database we want to query.</li>
<li><code class="docutils literal notranslate"><span class="pre">‘segments-veto-definer-url’</span></code> is the url for the veto definer file we want to use for the search.</li>
<li><code class="docutils literal notranslate"><span class="pre">‘segments-science-veto’</span></code> species which category of veto you want to eliminate from your search before it is performed to consider the data science. In this instance, 1 denotes that all the times of Cat 1 vetoes. Time vetoed here is not used in any part of the analysis, and is treated as if it were not collected.</li>
<li><code class="docutils literal notranslate"><span class="pre">‘segments-veto-groups’</span></code> is an option you can populate with different veto categories and diagnostic plots will be made after each veto is employed.</li>
<li><code class="docutils literal notranslate"><span class="pre">‘segments-final-veto-group’</span></code> is an important option as the vetoes defined here will be used to remove triggers from the search before coincidence is performed. An option of 1 will remove all Cat 1 veto times from the analysis before it is performed. If you want to add cat 2 then the option is 12.</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">workflow</span><span class="o">-</span><span class="n">tmpltbank</span><span class="p">]</span>
<span class="p">;</span> <span class="n">See</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">ldas</span><span class="o">-</span><span class="n">jobs</span><span class="o">.</span><span class="n">ligo</span><span class="o">.</span><span class="n">caltech</span><span class="o">.</span><span class="n">edu</span><span class="o">/~</span><span class="n">cbc</span><span class="o">/</span><span class="n">docs</span><span class="o">/</span><span class="n">pycbc</span><span class="o">/</span><span class="n">ahope</span><span class="o">/</span><span class="n">template_bank</span><span class="o">.</span><span class="n">html</span>
<span class="n">tmpltbank</span><span class="o">-</span><span class="n">method</span><span class="o">=</span><span class="n">PREGENERATED_BANK</span>
<span class="n">tmpltbank</span><span class="o">-</span><span class="n">pregenerated</span><span class="o">-</span><span class="n">bank</span><span class="o">=/</span><span class="n">home</span><span class="o">/</span><span class="n">jveitch</span><span class="o">/</span><span class="n">projects</span><span class="o">/</span><span class="n">mdc</span><span class="o">/</span><span class="n">spin</span><span class="o">/</span><span class="n">tmpltbanks</span><span class="o">/</span><span class="n">nonspin</span><span class="o">/</span><span class="n">BNS_NonSpin_30Hz_earlyaLIGO</span><span class="o">.</span><span class="n">xml</span>
</pre></div>
</div>
<p>This section specifies which template bank to use</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">’tmpltbank-method’</span></code> option specifies whether you want to use a regenerated bank or to make it on the fly. In O1 we will be us a pregenerated bank.</li>
<li><code class="docutils literal notranslate"><span class="pre">‘tmpltbank-pregnerated-bank’</span></code> specifies the location of the xml with the pregenerated bank. Note that this exact location is only valid for SUGAR, and that in general one must provide their own template bank.</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">workflow</span><span class="o">-</span><span class="n">splittable</span><span class="p">]</span>
<span class="n">splittable</span><span class="o">-</span><span class="n">method</span> <span class="o">=</span> <span class="n">IN_WORKFLOW</span>
<span class="n">splittable</span><span class="o">-</span><span class="n">num</span><span class="o">-</span><span class="n">banks</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
<p>This section sets the options for splitting the bank to help with computational costs.</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">‘splittable-method’</span></code> tells you the method by which to split the bank, in this instance it is IN_WORKFLOW. If you do not want to split the bank, change this option to NOOP</li>
<li><code class="docutils literal notranslate"><span class="pre">‘splittable-num-banks’</span></code> specifies how many banks to split the original bank into.</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">workflow</span><span class="o">-</span><span class="n">matchedfilter</span><span class="p">]</span>
<span class="p">;</span> <span class="n">See</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">ldas</span><span class="o">-</span><span class="n">jobs</span><span class="o">.</span><span class="n">ligo</span><span class="o">.</span><span class="n">caltech</span><span class="o">.</span><span class="n">edu</span><span class="o">/~</span><span class="n">cbc</span><span class="o">/</span><span class="n">docs</span><span class="o">/</span><span class="n">pycbc</span><span class="o">/</span><span class="n">ahope</span><span class="o">/</span><span class="n">matched_filter</span><span class="o">.</span><span class="n">html</span>
<span class="n">matchedfilter</span><span class="o">-</span><span class="n">method</span><span class="o">=</span><span class="n">WORKFLOW_INDEPENDENT_IFOS</span>
<span class="nb">min</span><span class="o">-</span><span class="n">analysis</span><span class="o">-</span><span class="n">segments</span> <span class="o">=</span> <span class="mi">5</span>
<span class="nb">max</span><span class="o">-</span><span class="n">analysis</span><span class="o">-</span><span class="n">segments</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">output</span><span class="o">-</span><span class="nb">type</span> <span class="o">=</span> <span class="n">hdf</span>
</pre></div>
</div>
<p>This section defines how the matched filter is going to be performed. Whether it is going to be independent for each detector, and also how the analysis is actually going to be separated in to chunks given the data available.</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">‘matched-filter-method’</span></code> defines where the data is going to be separated and searched over, in this instance the data for each IFO will be considered independently and in the workflow</li>
<li><code class="docutils literal notranslate"><span class="pre">‘min-analysis-segments’</span></code> defines the minimum number of overlapping chunks you separate the data in to to analyze. This is a proxy for segment length. In this instance 5 has been stated. Therefore if the data cannot be split in to 5 overlapping chunks the code skips over the data. To understand how much time this is you need to look in the [inspiral] options and consider the segment-length and padding options specified. ‘max-analysis-segments’ is the same but for the maximum number of overlapping chunks. Be aware if you lower/raise either of these numbers you will affect the psd estimation.</li>
<li><code class="docutils literal notranslate"><span class="pre">‘output-type’</span></code> is the format of the output trigger files from the matched filter search</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">workflow</span><span class="o">-</span><span class="n">coincidence</span><span class="p">]</span>
<span class="p">;</span> <span class="n">See</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">ldas</span><span class="o">-</span><span class="n">jobs</span><span class="o">.</span><span class="n">ligo</span><span class="o">.</span><span class="n">caltech</span><span class="o">.</span><span class="n">edu</span><span class="o">/~</span><span class="n">cbc</span><span class="o">/</span><span class="n">docs</span><span class="o">/</span><span class="n">pycbc</span><span class="o">/</span><span class="n">ahope</span><span class="o">/</span><span class="n">coincidence</span><span class="o">.</span><span class="n">html</span>
<span class="n">parallelization</span><span class="o">-</span><span class="n">factor</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
</div>
<p>This part of the workflow looks for coincidence between templates between detectors. All coincidences are kept. If you have a large template bank you probably want make the <code class="docutils literal notranslate"><span class="pre">‘parallelization-factor’</span></code> large</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">workflow</span><span class="o">-</span><span class="n">injections</span><span class="p">]</span>
<span class="n">injections</span><span class="o">-</span><span class="n">method</span><span class="o">=</span><span class="n">IN_WORKFLOW</span>
</pre></div>
</div>
<p>This section deals with software injections. Here you are specifying whether to use either pregenerated injections sets or ones made within the workflow itself. In this case, we will use one that is created within the workflow.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>[executables]
; setup of condor universe and location of executables
inspiral          = ${which:pycbc_inspiral}
injections = ${which:lalapps_inspinj}
splittable = ${which:pycbc_splitbank}
segment_query = ${which:ligolw_segment_query_dqsegdb}
segments_from_cats = ${which:ligolw_segments_from_cats_dqsegdb}
llwadd = ${which:ligolw_add}
ligolw_combine_segments = ${which:ligolw_combine_segments}
bank2hdf = ${which:pycbc_coinc_bank2hdf}
hdfinjfind = ${which:pycbc_coinc_hdfinjfind}
coinc = ${which:pycbc_coinc_findtrigs}
statmap = ${which:pycbc_coinc_statmap}
statmap_inj = ${which:pycbc_coinc_statmap_inj}
plot_sensitivity = ${which:pycbc_page_sensitivity}
plot_foundmissed = ${which:pycbc_page_foundmissed}
plot_snrifar = ${which:pycbc_page_snrifar}
page_foreground = ${which:pycbc_page_foreground}
page_injections = ${which:pycbc_page_injtable}
hdf_trigger_merge = ${which:pycbc_coinc_mergetrigs}
plot_snrchi = ${which:pycbc_page_snrchi}
plot_coinc_snrchi = ${which:pycbc_page_coinc_snrchi}
plot_segments = ${which:pycbc_page_segments}
results_page = ${which:pycbc_make_html_page}
</pre></div>
</div>
<p>This section defines where each of the executables live; it tells the workflow which files to process. It might be worth checking you can find all of these paths before you set the code running.</p>
<p>The following options are those associated to a given executable.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">llwadd</span><span class="p">]</span>
<span class="p">[</span><span class="n">datafind</span><span class="p">]</span>
<span class="n">urltype</span><span class="o">=</span><span class="n">file</span>
</pre></div>
</div>
<p>This is the format for the return of the data find executable - you want a file.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">segments_from_cats</span><span class="p">]</span>
</pre></div>
</div>
<p>Some sections are left empty. That is fine, but you have to define each option otherwise the code will complain</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">ligolw_combine_segments</span><span class="p">]</span>

<span class="p">[</span><span class="n">splittable</span><span class="p">]</span>
<span class="p">;</span> <span class="n">options</span> <span class="k">for</span> <span class="n">splittable</span> <span class="n">job</span>
<span class="n">random</span><span class="o">-</span><span class="n">sort</span> <span class="o">=</span>
</pre></div>
</div>
<p>This option randomly sorts the bank to be split up before processing</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">injections</span><span class="p">]</span>
<span class="n">waveform</span> <span class="o">=</span> <span class="n">SpinTaylorT4threePointFivePN</span>
</pre></div>
</div>
<p>Define the waveforms you want to use for injections</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">injections</span><span class="o">-</span><span class="n">bnslininj</span><span class="p">]</span>
<span class="n">f</span><span class="o">-</span><span class="n">lower</span> <span class="o">=</span> <span class="mi">20</span>
<span class="nb">min</span><span class="o">-</span><span class="n">distance</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="nb">max</span><span class="o">-</span><span class="n">distance</span> <span class="o">=</span> <span class="mi">150000</span>
<span class="n">d</span><span class="o">-</span><span class="n">distr</span> <span class="o">=</span> <span class="n">uniform</span>
<span class="n">l</span><span class="o">-</span><span class="n">distr</span> <span class="o">=</span> <span class="n">random</span>
<span class="n">i</span><span class="o">-</span><span class="n">distr</span> <span class="o">=</span> <span class="n">uniform</span>
<span class="nb">min</span><span class="o">-</span><span class="n">mass1</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="nb">max</span><span class="o">-</span><span class="n">mass1</span> <span class="o">=</span> <span class="mf">3.1</span>
<span class="nb">min</span><span class="o">-</span><span class="n">mass2</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="nb">max</span><span class="o">-</span><span class="n">mass2</span> <span class="o">=</span> <span class="mf">3.1</span>
<span class="n">m</span><span class="o">-</span><span class="n">distr</span> <span class="o">=</span> <span class="n">componentMass</span>
<span class="nb">min</span><span class="o">-</span><span class="n">mtotal</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="nb">max</span><span class="o">-</span><span class="n">mtotal</span> <span class="o">=</span> <span class="mf">6.2</span>
<span class="n">disable</span><span class="o">-</span><span class="n">spin</span> <span class="o">=</span>
<span class="n">time</span><span class="o">-</span><span class="n">step</span> <span class="o">=</span> <span class="mf">89.155</span>
<span class="n">time</span><span class="o">-</span><span class="n">interval</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">1234</span>
</pre></div>
</div>
<p>These are the injections parameters you want to define. Only defining ones which aren’t so obvious</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">f-lower</span></code> = low frequency cut off</li>
<li><code class="docutils literal notranslate"><span class="pre">min-distance</span></code> =  (kpc)</li>
<li><code class="docutils literal notranslate"><span class="pre">max-distance</span></code> = (kpc)</li>
<li><code class="docutils literal notranslate"><span class="pre">d-distr</span></code> = the distance distribution of the injections</li>
<li><code class="docutils literal notranslate"><span class="pre">l-distr</span></code> = the distribution of injections in the sky</li>
<li><code class="docutils literal notranslate"><span class="pre">i-distr</span></code> = inclination of the injection</li>
<li><code class="docutils literal notranslate"><span class="pre">time-step</span></code> = time between injections. This can be whatever time you want, but remember if the injections are too close together you can screw up your psd estimation. ~90s seems ok.</li>
<li><code class="docutils literal notranslate"><span class="pre">time-interval</span></code> = time interval to inject the signal. It will not always be exactly at time-step, but at a time of time-step +/- random_number(0,time-interval)</li>
<li><code class="docutils literal notranslate"><span class="pre">seed</span></code> = random seed, choose different numbers to get different realizations of the same background distribution</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">inspiral</span><span class="p">]</span>
<span class="p">;</span> <span class="n">inspiral</span> <span class="n">analysis</span> <span class="n">parameters</span> <span class="o">--</span> <span class="n">added</span> <span class="n">to</span> <span class="nb">all</span> <span class="n">inspiral</span> <span class="n">jobs</span>
<span class="n">chisq</span><span class="o">-</span><span class="n">bins</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">snr</span><span class="o">-</span><span class="n">threshold</span> <span class="o">=</span> <span class="mf">5.0</span>
<span class="n">approximant</span> <span class="o">=</span> <span class="n">SPAtmplt</span>
<span class="n">order</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">cluster</span><span class="o">-</span><span class="n">method</span> <span class="o">=</span> <span class="n">window</span>
<span class="n">cluster</span><span class="o">-</span><span class="n">window</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">segment</span><span class="o">-</span><span class="n">length</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">segment</span><span class="o">-</span><span class="n">start</span><span class="o">-</span><span class="n">pad</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">segment</span><span class="o">-</span><span class="n">end</span><span class="o">-</span><span class="n">pad</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">psd</span><span class="o">-</span><span class="n">estimation</span> <span class="o">=</span> <span class="n">median</span>
<span class="n">psd</span><span class="o">-</span><span class="n">segment</span><span class="o">-</span><span class="n">length</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">psd</span><span class="o">-</span><span class="n">segment</span><span class="o">-</span><span class="n">stride</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">psd</span><span class="o">-</span><span class="n">inverse</span><span class="o">-</span><span class="n">length</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">strain</span><span class="o">-</span><span class="n">high</span><span class="o">-</span><span class="k">pass</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">pad</span><span class="o">-</span><span class="n">data</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">processing</span><span class="o">-</span><span class="n">scheme</span> <span class="o">=</span> <span class="n">mkl</span>
<span class="n">sample</span><span class="o">-</span><span class="n">rate</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="nb">filter</span><span class="o">-</span><span class="n">inj</span><span class="o">-</span><span class="n">only</span> <span class="o">=</span>
<span class="n">low</span><span class="o">-</span><span class="n">frequency</span><span class="o">-</span><span class="n">cutoff</span> <span class="o">=</span> <span class="mi">40</span>
</pre></div>
</div>
<p>These are the parameters you want to define for the inspiral search</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">chisq-bins</span></code> = number of chisq bins for the standard Bruce Allen chisq</li>
<li><code class="docutils literal notranslate"><span class="pre">snr-threshold</span></code> = SNR threshold</li>
<li><code class="docutils literal notranslate"><span class="pre">approximant</span></code> = approximation you want to use. SPAtmplt is stationary phase approximation template which is a fast implementation of Taylor F2.</li>
<li><code class="docutils literal notranslate"><span class="pre">order</span></code> = PN order, the numbers are double the order. So 7=3.5PN</li>
<li><code class="docutils literal notranslate"><span class="pre">cluster-method</span></code> = method over which to identify the loudest trigger - in this case a window</li>
<li><code class="docutils literal notranslate"><span class="pre">cluster-window</span></code> = take a 1 second window around the loudest trigger</li>
<li><code class="docutils literal notranslate"><span class="pre">segment-length</span></code> = the length of a segment you want to analyze. Remember previously we mention we want 5 overlapping segments</li>
<li><code class="docutils literal notranslate"><span class="pre">segment-start-pad</span></code> = the amount of time we want to pad the start of the data by. In this instance we want to not use the first 64 seconds of data, as it will contain errors from filtering. This takes in to account the length of time we lose due to PSD corruption (16s) and the wrap around effect we have due to the template (48s)</li>
<li><code class="docutils literal notranslate"><span class="pre">segment-end-pad</span></code> = the amount of time we want to pad the end of the data by. See above.</li>
<li><code class="docutils literal notranslate"><span class="pre">psd-estimation</span></code> = the method by which we want to estimate the psd</li>
<li><code class="docutils literal notranslate"><span class="pre">psd-segment-length</span></code> = length of time used in each psd calculation</li>
<li><code class="docutils literal notranslate"><span class="pre">psd-segment-stride</span></code> = time spacing between each psd calculation. 16s length with 8s stride implies a 50% overlap</li>
<li><code class="docutils literal notranslate"><span class="pre">psd-inverse-length</span></code> = time length used to truncate the inverse FFT (that is, the time domain realization) of the psd</li>
<li><code class="docutils literal notranslate"><span class="pre">strain-high-pass</span></code> = high pass filter applied to strain data before psd estimation</li>
<li><code class="docutils literal notranslate"><span class="pre">pad-data</span></code> = 8 second padding added to beginning of data to account for filter corruption for resampling and high-pass before data is broken up into chunks</li>
<li><code class="docutils literal notranslate"><span class="pre">processing-scheme</span></code> = indicates which software to use for processing (MKL = math kernel library made by Intel)</li>
<li><code class="docutils literal notranslate"><span class="pre">sample-rate</span></code> = sample rate of data (will be down sampled in workflow)</li>
<li><code class="docutils literal notranslate"><span class="pre">filter-inj-only</span></code> = Use only segments with injections in them for matched filter</li>
<li><code class="docutils literal notranslate"><span class="pre">low-frequency-cutoff</span></code> = low frequency limit for the matched filter search</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>[inspiral-h1]
; h1 specific inspiral parameters
channel-name = ${workflow|h1-channel-name}
</pre></div>
</div>
<p>Specify the name of the channel you want to run the inspiral analysis over for H1. Here we are referring back to the name in the workflow module</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>[inspiral-l1]
; l1 specific inspiral parameters
channel-name = ${workflow|l1-channel-name}

[bank2hdf]
[trig2hdf]

[coinc]
coinc-threshold = 0.000
</pre></div>
</div>
<p>Here we are doing exact match coincidence. So we take the light travel time between detectors and look for triggers which are coincident within this time window. The threshold defines if you want to extend the window.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">coinc</span><span class="o">-</span><span class="n">full</span><span class="p">]</span>
<span class="n">decimation</span><span class="o">-</span><span class="n">factor</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">loudest</span><span class="o">-</span><span class="n">keep</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">timeslide</span><span class="o">-</span><span class="n">interval</span><span class="o">=</span><span class="mf">1.1</span>
</pre></div>
</div>
<p>This section concerns time slides without injections, and its purpose is to keep a small number of timesmlide triggers for background estimation. Time slides are done at all relative offsets that are multiple of the ‘timeslide-interval’, which is defined here to be 1.1 seconds. We don’t store all the coincident triggers due from time slides. We keep 200 of the loudest triggers from each template time slide, given by the second option, which gives a good estimation of the background at low FAR. The top option specifies for which timeslides we will keep all triggers, to get an overall estimation of background (not just the loudest). In this instance we would keep the triggers from 1000th, 2000th, 3000th timeslide.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">coinc</span><span class="o">-</span><span class="n">injfull</span><span class="o">&amp;</span><span class="n">coinc</span><span class="o">-</span><span class="n">fullinj</span><span class="p">]</span>
<span class="n">timeslide</span><span class="o">-</span><span class="n">interval</span><span class="o">=</span><span class="p">{</span><span class="n">coinc</span><span class="o">-</span><span class="n">full</span><span class="p">:</span><span class="n">timeslide</span><span class="o">-</span><span class="n">interval</span><span class="p">}</span>
<span class="n">loudest</span><span class="o">-</span><span class="n">keep</span><span class="o">-</span><span class="n">value</span> <span class="o">=</span> <span class="mf">8.5</span>
<span class="n">cluster</span><span class="o">-</span><span class="n">window</span> <span class="o">=</span> <span class="p">{</span><span class="n">statmap</span><span class="o">|</span><span class="n">cluster</span><span class="o">-</span><span class="n">window</span><span class="p">}</span>
</pre></div>
</div>
<p>This section concerns time slides with injections in the data. We assume only one injection will be coincident with a timeslide (done every 1.1 seconds - see first option) trigger and we keep its coincidence if its ranking statistic (newSNR) &gt; 8.5 as specified in the second option. This is to limit storage of unimpactful triggers only.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">coinc</span><span class="o">-</span><span class="n">injinj</span><span class="p">]</span>

<span class="p">[</span><span class="n">pegasus_profile</span><span class="o">-</span><span class="n">statmap</span><span class="o">&amp;</span><span class="n">pegasus_profile</span><span class="o">-</span><span class="n">statmap_inj</span><span class="p">]</span>
<span class="n">condor</span><span class="o">|</span><span class="n">request_memory</span> <span class="o">=</span> <span class="mi">20</span><span class="n">GB</span>
</pre></div>
</div>
<p>This is the amount of memory the jobs might take</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">statmap</span><span class="o">&amp;</span><span class="n">statmap_inj</span><span class="p">]</span>
<span class="n">veto</span><span class="o">-</span><span class="n">window</span> <span class="o">=</span> <span class="mf">0.050</span>
<span class="n">cluster</span><span class="o">-</span><span class="n">window</span> <span class="o">=</span> <span class="mf">10.0</span>
</pre></div>
</div>
<p>This controls the final clustering after all coincidence testing. The <code class="docutils literal notranslate"><span class="pre">cluster-window</span></code> indicates the time window used for clustering.
The <code class="docutils literal notranslate"><span class="pre">veto-window</span></code> is used to remove all coincident zero-lag triggers so that they aren’t included in background estimation</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">hdfinjfind</span><span class="p">]</span>
<span class="n">injection</span><span class="o">-</span><span class="n">window</span> <span class="o">=</span> <span class="mf">1.0</span>
</pre></div>
</div>
<p>The rest of the config file concerns plotting formats</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">page_foreground</span><span class="p">]</span>
<span class="p">[</span><span class="n">plot_snrifar</span><span class="p">]</span>

<span class="p">[</span><span class="n">plot_snrchi</span><span class="p">]</span>
<span class="p">[</span><span class="n">plot_coinc_snrchi</span><span class="p">]</span>
<span class="p">[</span><span class="n">plot_coinc_snrchi</span><span class="o">-</span><span class="n">inj</span><span class="p">]</span>
<span class="p">[</span><span class="n">plot_coinc_snrchi</span><span class="o">-</span><span class="n">bkg</span><span class="p">]</span>
<span class="n">background</span><span class="o">-</span><span class="n">front</span><span class="o">=</span>
<span class="p">[</span><span class="n">plot_coinc_snrchi</span><span class="o">-</span><span class="n">inj</span><span class="o">&amp;</span><span class="n">plot_coinc_snrchi</span><span class="o">-</span><span class="n">bkg</span><span class="o">&amp;</span><span class="n">plot_snrchi</span><span class="p">]</span>
<span class="n">newsnr</span><span class="o">-</span><span class="n">contours</span> <span class="o">=</span>  <span class="mi">6</span> <span class="mi">8</span> <span class="mi">10</span>

<span class="p">[</span><span class="n">plot_sensitivity</span><span class="p">]</span>
<span class="n">sig</span><span class="o">-</span><span class="nb">type</span> <span class="o">=</span> <span class="n">ifar</span>
<span class="n">sig</span><span class="o">-</span><span class="n">bins</span> <span class="o">=</span> <span class="mi">1</span> <span class="mi">3</span> <span class="mi">10</span> <span class="mi">30</span> <span class="mi">100</span> <span class="mi">300</span> <span class="mi">1000</span> <span class="mi">3000</span> <span class="mi">10000</span> <span class="mi">30000</span> <span class="mi">100000</span>

<span class="p">[</span><span class="n">plot_sensitivity</span><span class="o">-</span><span class="n">mchirp</span><span class="p">]</span>
<span class="nb">bin</span><span class="o">-</span><span class="nb">type</span> <span class="o">=</span>  <span class="n">mchirp</span>
<span class="n">bins</span> <span class="o">=</span> <span class="mf">0.89</span> <span class="mf">1.31</span> <span class="mf">1.74</span> <span class="mf">2.17</span> <span class="mf">2.60</span>
<span class="nb">min</span><span class="o">-</span><span class="n">dist</span> <span class="o">=</span> <span class="mi">40</span>
<span class="nb">max</span><span class="o">-</span><span class="n">dist</span> <span class="o">=</span> <span class="mi">120</span>
<span class="n">dist</span><span class="o">-</span><span class="n">bins</span> <span class="o">=</span> <span class="mi">50</span>

<span class="p">[</span><span class="n">plot_sensitivity</span><span class="o">-</span><span class="n">mtotal</span><span class="p">]</span>
<span class="nb">bin</span><span class="o">-</span><span class="nb">type</span> <span class="o">=</span>  <span class="n">total_mass</span>
<span class="n">bins</span> <span class="o">=</span> <span class="mi">2</span> <span class="mf">2.4</span> <span class="mf">3.2</span> <span class="mi">4</span> <span class="mi">6</span>
<span class="nb">min</span><span class="o">-</span><span class="n">dist</span> <span class="o">=</span> <span class="mi">40</span>
<span class="nb">max</span><span class="o">-</span><span class="n">dist</span> <span class="o">=</span> <span class="mi">120</span>
<span class="n">dist</span><span class="o">-</span><span class="n">bins</span> <span class="o">=</span> <span class="mi">50</span>

<span class="p">[</span><span class="n">plot_sensitivity</span><span class="o">-</span><span class="n">spin</span><span class="p">]</span>
<span class="nb">bin</span><span class="o">-</span><span class="nb">type</span> <span class="o">=</span>  <span class="n">spin</span>
<span class="n">bins</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.4</span> <span class="o">-</span><span class="mf">0.2</span> <span class="mf">0.2</span> <span class="mf">0.4</span>
<span class="nb">min</span><span class="o">-</span><span class="n">dist</span> <span class="o">=</span> <span class="mi">40</span>
<span class="nb">max</span><span class="o">-</span><span class="n">dist</span> <span class="o">=</span> <span class="mi">120</span>
<span class="n">dist</span><span class="o">-</span><span class="n">bins</span> <span class="o">=</span> <span class="mi">50</span>

<span class="p">[</span><span class="n">plot_sensitivity</span><span class="o">-</span><span class="n">mchirp_binless</span><span class="p">]</span>
<span class="nb">bin</span><span class="o">-</span><span class="nb">type</span> <span class="o">=</span>  <span class="n">mchirp</span>
<span class="n">bins</span> <span class="o">=</span> <span class="mf">0.89</span> <span class="mf">1.31</span> <span class="mf">1.74</span> <span class="mf">2.17</span> <span class="mf">2.60</span>
<span class="nb">min</span><span class="o">-</span><span class="n">dist</span> <span class="o">=</span> <span class="mi">40</span>
<span class="nb">max</span><span class="o">-</span><span class="n">dist</span> <span class="o">=</span> <span class="mi">120</span>

<span class="p">[</span><span class="n">plot_sensitivity</span><span class="o">-</span><span class="n">mtotal_binless</span><span class="p">]</span>
<span class="nb">bin</span><span class="o">-</span><span class="nb">type</span> <span class="o">=</span>  <span class="n">total_mass</span>
<span class="n">bins</span> <span class="o">=</span> <span class="mi">2</span> <span class="mf">2.4</span> <span class="mf">3.2</span> <span class="mi">4</span> <span class="mi">6</span>
<span class="nb">min</span><span class="o">-</span><span class="n">dist</span> <span class="o">=</span> <span class="mi">40</span>
<span class="nb">max</span><span class="o">-</span><span class="n">dist</span> <span class="o">=</span> <span class="mi">120</span>

<span class="p">[</span><span class="n">plot_sensitivity</span><span class="o">-</span><span class="n">spin_binless</span><span class="p">]</span>
<span class="nb">bin</span><span class="o">-</span><span class="nb">type</span> <span class="o">=</span>  <span class="n">spin</span>
<span class="n">bins</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.4</span> <span class="o">-</span><span class="mf">0.2</span> <span class="mf">0.2</span> <span class="mf">0.4</span>
<span class="nb">min</span><span class="o">-</span><span class="n">dist</span> <span class="o">=</span> <span class="mi">40</span>
<span class="nb">max</span><span class="o">-</span><span class="n">dist</span> <span class="o">=</span> <span class="mi">120</span>

<span class="p">[</span><span class="n">plot_foundmissed</span><span class="p">]</span>
<span class="p">[</span><span class="n">plot_foundmissed</span><span class="o">-</span><span class="n">mchirp</span><span class="p">]</span>
<span class="n">axis</span><span class="o">-</span><span class="nb">type</span><span class="o">=</span><span class="n">mchirp</span>
<span class="n">dynamic</span><span class="o">=</span>
<span class="p">[</span><span class="n">plot_foundmissed</span><span class="o">-</span><span class="n">chirpdistmchirp</span><span class="p">]</span>
<span class="n">axis</span><span class="o">-</span><span class="nb">type</span><span class="o">=</span><span class="n">mchirp</span>
<span class="n">dynamic</span><span class="o">=</span>
<span class="n">distance</span><span class="o">-</span><span class="nb">type</span><span class="o">=</span><span class="n">chirp_distance</span>
<span class="p">[</span><span class="n">plot_foundmissed</span><span class="o">-</span><span class="n">time</span><span class="p">]</span>
<span class="n">axis</span><span class="o">-</span><span class="nb">type</span><span class="o">=</span><span class="n">time</span>
<span class="n">dynamic</span><span class="o">=</span>

<span class="p">[</span><span class="n">plot_foundmissed</span><span class="o">-</span><span class="n">mchirp_static</span><span class="p">]</span>
<span class="n">axis</span><span class="o">-</span><span class="nb">type</span><span class="o">=</span><span class="n">mchirp</span>
<span class="n">log</span><span class="o">-</span><span class="n">distance</span><span class="o">=</span>
<span class="p">[</span><span class="n">plot_foundmissed</span><span class="o">-</span><span class="n">chirpdistmchirp_static</span><span class="p">]</span>
<span class="n">axis</span><span class="o">-</span><span class="nb">type</span><span class="o">=</span><span class="n">mchirp</span>
<span class="n">distance</span><span class="o">-</span><span class="nb">type</span><span class="o">=</span><span class="n">chirp_distance</span>
<span class="n">log</span><span class="o">-</span><span class="n">distance</span><span class="o">=</span>
<span class="p">[</span><span class="n">plot_foundmissed</span><span class="o">-</span><span class="n">time_static</span><span class="p">]</span>
<span class="n">axis</span><span class="o">-</span><span class="nb">type</span><span class="o">=</span><span class="n">time</span>
<span class="n">log</span><span class="o">-</span><span class="n">distance</span><span class="o">=</span>

<span class="p">[</span><span class="n">hdf_trigger_merge</span><span class="p">]</span>
<span class="p">[</span><span class="n">pegasus_profile</span><span class="o">-</span><span class="n">hdf_trigger_merge</span><span class="p">]</span>
<span class="n">condor</span><span class="o">|</span><span class="n">request_memory</span> <span class="o">=</span> <span class="mi">10</span><span class="n">GB</span>

<span class="p">[</span><span class="n">page_injections</span><span class="p">]</span>
<span class="p">[</span><span class="n">plot_segments</span><span class="p">]</span>

<span class="p">[</span><span class="n">results_page</span><span class="p">]</span>
<span class="n">analysis</span><span class="o">-</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;PyCBC Coincident Analysis&quot;</span>
<span class="n">analysis</span><span class="o">-</span><span class="n">subtitle</span><span class="o">=</span><span class="s2">&quot;...&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="generating-the-workflow">
<span id="coincworkflowgenerate"></span><h2>Generating the workflow<a class="headerlink" href="#generating-the-workflow" title="Permalink to this headline">¶</a></h2>
<p>The workflow is generated by running the script <code class="docutils literal notranslate"><span class="pre">pycbc_make_coinc_search_workflow</span></code>. This program takes the command line arguments</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ pycbc_make_coinc_search_workflow --help
usage: pycbc_make_coinc_search_workflow [-h] [--version]
                                        [--workflow-name WORKFLOW_NAME]
                                        [-d OUTPUT_DIR]
                                        [--config-files CONFIGFILE [CONFIGFILE ...]]
                                        [--config-overrides [SECTION:OPTION:VALUE [SECTION:OPTION:VALUE ...]]]
                                        [--config-delete [SECTION:OPTION [SECTION:OPTION ...]]]

Program for running multi-detector workflow analysis through coincidence and
then generate post-processing and plots.

optional arguments:
  -h, --help            show this help message and exit
  --version             show program&#39;s version number and exit
  --workflow-name WORKFLOW_NAME
  -d OUTPUT_DIR, --output-dir OUTPUT_DIR
                        Path to output directory.

Configuration:
  Options needed for parsing config file(s).

  --config-files CONFIGFILE [CONFIGFILE ...]
                        List of config files to be used in analysis.
  --config-overrides [SECTION:OPTION:VALUE [SECTION:OPTION:VALUE ...]]
                        List of section,option,value combinations to add into
                        the configuration file. Normally the gps start and end
                        times might be provided this way, and user specific
                        locations (ie. output directories). This can also be
                        provided as SECTION:OPTION or SECTION:OPTION: both of
                        which indicate that the corresponding value is left
                        blank.
  --config-delete [SECTION:OPTION [SECTION:OPTION ...]]
                        List of section,option combinations to delete from the
                        configuration file. This can also be provided as
                        SECTION which deletes the enture section from the
                        configuration file or SECTION:OPTION which deletes a
                        specific option from a given section.
</pre></div>
</div>
<p>The configuration files can either be passes as local files, or given as URLs
to specific configuration files managed for an analysis. For example, to
generate a workflow to search two weeks of S6D data and place the results in
your <code class="docutils literal notranslate"><span class="pre">public_html</span></code> directory, run the command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pycbc_make_coinc_search_workflow</span> <span class="o">--</span><span class="n">workflow</span><span class="o">-</span><span class="n">name</span> <span class="n">s6d_chunk3</span> <span class="o">--</span><span class="n">output</span><span class="o">-</span><span class="nb">dir</span> <span class="n">output</span> \
  <span class="o">--</span><span class="n">config</span><span class="o">-</span><span class="n">files</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">code</span><span class="o">.</span><span class="n">pycbc</span><span class="o">.</span><span class="n">phy</span><span class="o">.</span><span class="n">syr</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">ligo</span><span class="o">-</span><span class="n">cbc</span><span class="o">/</span><span class="n">pycbc</span><span class="o">-</span><span class="n">config</span><span class="o">/</span><span class="n">download</span><span class="o">/</span><span class="n">master</span><span class="o">/</span><span class="n">S6</span><span class="o">/</span><span class="n">pipeline</span><span class="o">/</span><span class="n">s6_run_pycbc_er8_pre_release</span><span class="o">.</span><span class="n">ini</span> \
  <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">code</span><span class="o">.</span><span class="n">pycbc</span><span class="o">.</span><span class="n">phy</span><span class="o">.</span><span class="n">syr</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">ligo</span><span class="o">-</span><span class="n">cbc</span><span class="o">/</span><span class="n">pycbc</span><span class="o">-</span><span class="n">config</span><span class="o">/</span><span class="n">download</span><span class="o">/</span><span class="n">master</span><span class="o">/</span><span class="n">S6</span><span class="o">/</span><span class="n">pipeline</span><span class="o">/</span><span class="n">executables</span><span class="o">.</span><span class="n">ini</span> \
  <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">code</span><span class="o">.</span><span class="n">pycbc</span><span class="o">.</span><span class="n">phy</span><span class="o">.</span><span class="n">syr</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">ligo</span><span class="o">-</span><span class="n">cbc</span><span class="o">/</span><span class="n">pycbc</span><span class="o">-</span><span class="n">config</span><span class="o">/</span><span class="n">download</span><span class="o">/</span><span class="n">master</span><span class="o">/</span><span class="n">S6</span><span class="o">/</span><span class="n">pipeline</span><span class="o">/</span><span class="n">injections</span><span class="o">.</span><span class="n">ini</span> \
  <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">code</span><span class="o">.</span><span class="n">pycbc</span><span class="o">.</span><span class="n">phy</span><span class="o">.</span><span class="n">syr</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">ligo</span><span class="o">-</span><span class="n">cbc</span><span class="o">/</span><span class="n">pycbc</span><span class="o">-</span><span class="n">config</span><span class="o">/</span><span class="n">download</span><span class="o">/</span><span class="n">master</span><span class="o">/</span><span class="n">S6</span><span class="o">/</span><span class="n">pipeline</span><span class="o">/</span><span class="n">data_S6</span><span class="o">.</span><span class="n">ini</span> \
  <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">code</span><span class="o">.</span><span class="n">pycbc</span><span class="o">.</span><span class="n">phy</span><span class="o">.</span><span class="n">syr</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">ligo</span><span class="o">-</span><span class="n">cbc</span><span class="o">/</span><span class="n">pycbc</span><span class="o">-</span><span class="n">config</span><span class="o">/</span><span class="n">download</span><span class="o">/</span><span class="n">master</span><span class="o">/</span><span class="n">S6</span><span class="o">/</span><span class="n">pipeline</span><span class="o">/</span><span class="n">gps_times_s6d_big_dog_two_weeks</span><span class="o">.</span><span class="n">ini</span> \
  <span class="o">--</span><span class="n">config</span><span class="o">-</span><span class="n">overrides</span> <span class="s2">&quot;results_page:output-path:$</span><span class="si">{HOME}</span><span class="s2">/public_html/s6/s6d-big-dog-weeks&quot;</span>
</pre></div>
</div>
<p>The configuration <code class="docutils literal notranslate"><span class="pre">results_page:output-path</span></code> can be changed appropriately to
set the output web page location.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">To use released executables for production analysis, you should specify
the URL to an <code class="docutils literal notranslate"><span class="pre">executables.ini</span></code> file from the
<a class="reference external" href="https://code.pycbc.phy.syr.edu/ligo-cbc/pycbc-software">PyCBC Software repository</a>.</p>
</div>
</div>
<div class="section" id="planning-and-submitting-the-workflow">
<span id="coincworkflowplan"></span><h2>Planning and Submitting the Workflow<a class="headerlink" href="#planning-and-submitting-the-workflow" title="Permalink to this headline">¶</a></h2>
<p>Pegasus is used to plan and submit the workflow. To involve Pegasus to plan a
PyCBC workflow, you use the command <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code> which takes the
command line arguments</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>$ pycbc_submit_dax --help
usage: pycbc_submit_dax [-h] --dax DAX [optional arguments]

required arguments:
  -d, --dax DAX           name of the dax file to plan

workflow submission required one of:
  -a, --accounting-group GROUP tagged string used for site 
                               resource accounting.
  -F, --force-no-accounting-group submit without an accounting
                               group. Will cause condor submission
                               to fail on LIGO Data Grid clusters

optional arguments:
  -h, --help              show this help message and exit
  -c, --cache-file FILE   replica cache file for data reuse
  -g, --local-staging-server uri://host provide a uri on host
                                 for the local site scratch
                                 (default is file://)
  -r, --remote-staging-server uri://host provide a uri on host
                                 for the remote site scratch.
  -p, --pegasus-properties FILE use the specified file as
                               the pegasus properties file
  -P, --append-pegasus-property STRING add the extra property
                                          specified by the argument
  -s, --execution-sites A,B,C specify a comma separated list
                               of execution sites that will be
                               used in addition to the local site
  -S, --staging-sites A=X,B=Y,C=Z  comma separated list of key=value
                                   pairs, where the key is the
                                   execution site and value is the
                                   staging site for that execution site
  -k, --append-site-profile SITE:NAMESPACE|KEY:VALUE
                               append the profile determined by
                               NAMESPACE, KEY, and VALUE to the
                               site catalog entry for SITE
  -t, --transformation-catalog FILE pass the specified
                                   transformation catalog to Pegasus
  -K, --no-create-proxy   Do not run ligo-proxy-init and assume
                             that the user has a valid grid proxy
  -n, --no-submit         Plan the DAX but do not submit it
  -l, --local-dir         Directory to put condor files under
  -G, --no-grid           Disable checks for grid proxy and
                             GLOBUS_LOCATION in pegasus-plan

If the environment variable TMPDIR is set then this is prepended to the 
path to the temporary workflow execute directory passed to pegasus-plan.
If the --local-dir option is not given.

If the environment variable PEGASUS_FILE_DIRECTORY is set then the
script will look there for pegasus site catalog and configuration
otherwise, the script will look for this directory by querying the
pycbc.workflow module.

If the environment variable PEGASUS_SITE_CATALOG_PATH is set then the
script will look for site catalog templates in this directory.
Site catalog templates may contain other environment variables that
must be set in order for them to be rendered correctly.
</pre></div>
</div>
<p>Note that  you are running on a resource that mandates accounting, then you
will also need to add a valid tag with the <code class="docutils literal notranslate"><span class="pre">--accounting-tag</span></code> command line
argument. Please see
<a class="reference external" href="https://ldas-gridmon.ligo.caltech.edu/ldg_accounting/user">the LDG accounting page</a>. to
determine the correct tags. These can be applied by adding the following line
to your submit invocation.</p>
<p>For example, to plan and submit the workflow in the example above, change to the directory that you specified with the <code class="docutils literal notranslate"><span class="pre">--output</span></code>
command line option to <code class="docutils literal notranslate"><span class="pre">pycbc_make_coinc_search_workflow</span></code> and plan and submit
the workflow:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">output</span>
<span class="n">pycbc_submit_dax</span> <span class="o">--</span><span class="n">accounting</span><span class="o">-</span><span class="n">group</span> <span class="n">ligo</span><span class="o">.</span><span class="n">dev</span><span class="o">.</span><span class="n">o1</span><span class="o">.</span><span class="n">cbc</span><span class="o">.</span><span class="n">explore</span><span class="o">.</span><span class="n">test</span> <span class="o">--</span><span class="n">dax</span> <span class="n">s6d_chunk3</span><span class="o">.</span><span class="n">dax</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The above example uses the accounting tag <code class="docutils literal notranslate"><span class="pre">ligo.dev.o1.cbc.explore.test</span></code>
which should not be used in practice.</p>
</div>
<p>You can monitor the status of the workflow with Pegasus Dashboard, or the
other Pegasus tools described below.</p>
<p>If the workflow runs successfully, the output will be place under the
directory specified by <code class="docutils literal notranslate"><span class="pre">results_page:output-path</span></code> when the workflow is
complete.</p>
<div class="section" id="monitor-and-debug-the-workflow-detailed-pegasus-documentation">
<h3>Monitor and Debug the Workflow (<a class="reference external" href="https://pegasus.isi.edu/wms/docs/latest/tutorial.php#idm78622034400">Detailed Pegasus Documentation</a>)<a class="headerlink" href="#monitor-and-debug-the-workflow-detailed-pegasus-documentation" title="Permalink to this headline">¶</a></h3>
<p>To monitor the above workflow, one would run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pegasus</span><span class="o">-</span><span class="n">status</span> <span class="o">/</span><span class="n">usr1</span><span class="o">/</span><span class="n">ahnitz</span><span class="o">/</span><span class="n">log</span><span class="o">/</span><span class="n">ahnitz</span><span class="o">/</span><span class="n">pegasus</span><span class="o">/</span><span class="n">weekly_ahope</span><span class="o">/</span><span class="n">run0011</span>
</pre></div>
</div>
<p>To get debugging information in the case of failures.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pegasus</span><span class="o">-</span><span class="n">analyzer</span> <span class="o">/</span><span class="n">usr1</span><span class="o">/</span><span class="n">ahnitz</span><span class="o">/</span><span class="n">log</span><span class="o">/</span><span class="n">ahnitz</span><span class="o">/</span><span class="n">pegasus</span><span class="o">/</span><span class="n">weekly_ahope</span><span class="o">/</span><span class="n">run0011</span>
</pre></div>
</div>
</div>
<div class="section" id="pegasus-dashboard">
<h3>Pegasus Dashboard<a class="headerlink" href="#pegasus-dashboard" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference external" href="http://pegasus.isi.edu/wms/docs/latest/ch02s11.php">pegasus dashboard</a> is a visual and interactive way to get information about the progress, status, etc of your workflows.</p>
<p>The software can be obtained from a separate pegasus package here &lt;<a class="reference external" href="https://github.com/pegasus-isi/pegasus-service">https://github.com/pegasus-isi/pegasus-service</a>&gt;.</p>
<p>Pegasus Dashboard is currently installed on sugar. To view your Pegasus Dashboard, in a browser go to:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">sugar</span><span class="o">.</span><span class="n">phy</span><span class="o">.</span><span class="n">syr</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">pegasus</span><span class="o">/</span><span class="n">u</span><span class="o">/</span><span class="n">albert</span><span class="o">.</span><span class="n">einstein</span>
</pre></div>
</div>
<p>This shows a page that has a table of all your workflows that were submitted from sugar. You can view the details of a workflow by clicking on the link in the Workflow Details column of the table.</p>
<p>Clicking on the Workflow Details link will take you to a webpage that gives a high-level overview of the workflow, telling you how many many jobs succeeded, fail, the submit directory, etc. There is a table with tabs at the bottom of the page. If you click the tabs Failed, Running, and Successful the page will generate a table that lists all the failed, running, and successful jobs in the workflow respectively. You also have the ability to search the table for a particular kind of job using the Search bar.</p>
<p>You can view the details of a job by clicking the link in the Job Name column. This will take you to a Job Details page. This page will tell you where to find stdout files, stderr files, how much wall clock time the job took to run, etc. There is a table at the bottom of the page with a Failed and Successful tab. If you click on the respective tab, it will list all invocations of that job. You can click on the link in the Invocations column for more information.</p>
<p>On the Invocation Details page there is information about the command line arguments, executable path, CPU time, wall clock time, etc.</p>
<p>In certain cases, the pegasus monitor daemon may crash and this could result in
invalid or nonsensical information on the dashboard (e.g. a cumulative
computing time of None). This problem can be solved by running
<code class="docutils literal notranslate"><span class="pre">pegasus-plots</span></code> on the workflow directory: the command should tell you what
to do. Typically this will be running <code class="docutils literal notranslate"><span class="pre">pegasus-monitord</span></code> in replay mode (see
its man page).</p>
</div>
<div class="section" id="pegasus-analyzer">
<h3>Pegasus Analyzer<a class="headerlink" href="#pegasus-analyzer" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference external" href="http://pegasus.isi.edu/wms/docs/trunk/cli-pegasus-analyzer.php">pegasus analyzer</a> is a command-line tool for reporting sucessful and failed jobs.</p>
<p>To run <code class="docutils literal notranslate"><span class="pre">pegasus_analyzer</span></code> on your workflow, type:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pegasus</span><span class="o">-</span><span class="n">analyzer</span> <span class="o">/</span><span class="n">usr1</span><span class="o">/</span><span class="n">ahnitz</span><span class="o">/</span><span class="n">log</span><span class="o">/</span><span class="n">ahnitz</span><span class="o">/</span><span class="n">pegasus</span><span class="o">/</span><span class="n">weekly_ahope</span><span class="o">/</span><span class="n">run0011</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">pegasus_analyzer</span></code> will display a summary of suceeded, failed, and unsubmitted jobs in the workflow. After the summary information, <code class="docutils literal notranslate"><span class="pre">pegasus_analyzer</span></code> will display information about each failed job. An example would be:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">************************************</span><span class="n">Summary</span><span class="o">*************************************</span>

<span class="n">Submit</span> <span class="n">Directory</span>   <span class="p">:</span> <span class="o">/</span><span class="n">usr1</span><span class="o">/</span><span class="n">cbiwer</span><span class="o">/</span><span class="n">log</span><span class="o">/</span><span class="n">H1L1V1</span><span class="o">-</span><span class="n">s6d_test</span><span class="o">-</span><span class="mi">970012743</span><span class="o">-</span><span class="mf">258000.9</span><span class="n">apn7X</span>
<span class="n">Total</span> <span class="n">jobs</span>         <span class="p">:</span>     <span class="mi">24</span> <span class="p">(</span><span class="mf">100.00</span><span class="o">%</span><span class="p">)</span>
<span class="c1"># jobs succeeded   :     19 (79.17%)</span>
<span class="c1"># jobs failed      :      5 (20.83%)</span>
<span class="c1"># jobs unsubmitted :      0 (0.00%)</span>

<span class="o">******************************</span><span class="n">Failed</span> <span class="n">jobs</span><span class="s1">&#39; details******************************</span>

<span class="o">=====================</span><span class="n">ligolw_cbc_hardware_inj_page_ID000020</span><span class="o">======================</span>

<span class="n">last</span> <span class="n">state</span><span class="p">:</span> <span class="n">POST_SCRIPT_FAILED</span>
     <span class="n">site</span><span class="p">:</span> <span class="n">local</span>
<span class="n">submit</span> <span class="n">file</span><span class="p">:</span> <span class="n">ligolw_cbc_hardware_inj_page_ID000020</span><span class="o">.</span><span class="n">sub</span>
<span class="n">output</span> <span class="n">file</span><span class="p">:</span> <span class="n">ligolw_cbc_hardware_inj_page_ID000020</span><span class="o">.</span><span class="n">out</span><span class="mf">.001</span>
<span class="n">error</span> <span class="n">file</span><span class="p">:</span> <span class="n">ligolw_cbc_hardware_inj_page_ID000020</span><span class="o">.</span><span class="n">err</span><span class="mf">.001</span>

<span class="o">-------------------------------</span><span class="n">Task</span> <span class="c1">#1 - Summary--------------------------------</span>

<span class="n">site</span>        <span class="p">:</span> <span class="n">local</span>
<span class="n">hostname</span>    <span class="p">:</span> <span class="n">avhe2010</span><span class="o">.</span><span class="n">sugar</span><span class="o">.</span><span class="n">phy</span><span class="o">.</span><span class="n">syr</span><span class="o">.</span><span class="n">edu</span>
<span class="n">executable</span>  <span class="p">:</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">cbiwer</span><span class="o">/</span><span class="n">projects</span><span class="o">/</span><span class="n">test_workflow</span><span class="o">/</span><span class="mi">970012743</span><span class="o">-</span><span class="mi">970270743</span><span class="o">/</span><span class="n">executables</span><span class="o">/</span><span class="n">ligolw_cbc_hardware_inj_page</span>
<span class="n">arguments</span>   <span class="p">:</span> <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">xml</span> <span class="n">hardware_injection_summary</span><span class="o">/</span><span class="n">H1L1V1</span><span class="o">-</span><span class="n">S6_CBC_HW_INJECTIONS</span><span class="o">-</span><span class="mi">930493015</span><span class="o">-</span><span class="mf">42111800.</span><span class="n">xml</span> <span class="o">--</span><span class="n">outfile</span> <span class="n">hardware_injection_summary</span><span class="o">/</span><span class="n">H1L1V1</span><span class="o">-</span><span class="n">HWINJ_SUMMARY_CAT_2</span><span class="o">-</span><span class="mi">9</span>
<span class="mi">70012743</span><span class="o">-</span><span class="mf">258000.</span><span class="n">html</span> <span class="o">----</span><span class="n">segments</span><span class="o">-</span><span class="n">xml</span><span class="o">-</span><span class="n">glob</span> <span class="o">../</span><span class="n">segments</span><span class="o">/*-</span><span class="n">SCIENCE_SEGMENTS</span><span class="o">-*-*.</span><span class="n">xml</span> <span class="o">--</span><span class="n">v1</span><span class="o">-</span><span class="n">injections</span> <span class="o">----</span><span class="n">vetos</span><span class="o">-</span><span class="n">xml</span><span class="o">-</span><span class="n">glob</span> <span class="o">../</span><span class="n">segments</span><span class="o">/*-</span><span class="n">COMBINED_CAT_2_VETO_SEGS</span><span class="o">-*-*.</span><span class="n">xml</span> <span class="o">--</span><span class="n">gps</span><span class="o">-</span>
<span class="n">start</span><span class="o">-</span><span class="n">time</span> <span class="mi">970012743</span> <span class="o">--</span><span class="n">segment</span><span class="o">-</span><span class="nb">dir</span> <span class="n">hardware_injection_summary</span> <span class="o">--</span><span class="n">gps</span><span class="o">-</span><span class="n">end</span><span class="o">-</span><span class="n">time</span> <span class="mi">970270743</span> <span class="o">--</span><span class="n">l1</span><span class="o">-</span><span class="n">injections</span> <span class="o">--</span><span class="n">analyze</span><span class="o">-</span><span class="n">injections</span> <span class="o">--</span><span class="n">cache</span><span class="o">-</span><span class="n">file</span> <span class="n">full_data</span><span class="o">/</span><span class="n">H1L1V1</span><span class="o">-</span><span class="n">INSPIRAL_HIPE_FU</span>
<span class="n">LL_DATA_CAT_2_VETO</span><span class="o">-</span><span class="mi">970012743</span><span class="o">-</span><span class="mf">258000.</span><span class="n">cache</span> <span class="o">--</span><span class="n">h1</span><span class="o">-</span><span class="n">injections</span> <span class="o">--</span><span class="n">cache</span><span class="o">-</span><span class="n">pattern</span> <span class="o">*</span><span class="n">SIRE_FIRST</span><span class="o">*</span>
<span class="n">exitcode</span>    <span class="p">:</span> <span class="mi">2</span>
<span class="n">working</span> <span class="nb">dir</span> <span class="p">:</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">cbiwer</span><span class="o">/</span><span class="n">projects</span><span class="o">/</span><span class="n">test_workflow</span><span class="o">/</span><span class="mi">970012743</span><span class="o">-</span><span class="mi">970270743</span>

<span class="n">Task</span> <span class="c1">#1 - ligo-hwinjpagejob::ligolw_cbc_hardware_inj_page:1.0 - ID000020 - Kickstart stderr</span>

<span class="n">Usage</span><span class="p">:</span>  <span class="n">ligolw_cbc_hardware_inj_page</span> <span class="p">[</span><span class="n">options</span><span class="p">]</span>
<span class="n">Program</span> <span class="n">to</span> <span class="n">parse</span> <span class="n">the</span> <span class="n">inspiral</span> <span class="n">injection</span> <span class="n">log</span>
<span class="n">ligolw_cbc_hardware_inj_page</span><span class="p">:</span> <span class="n">error</span><span class="p">:</span> <span class="n">no</span> <span class="n">such</span> <span class="n">option</span><span class="p">:</span> <span class="o">----</span><span class="n">segments</span><span class="o">-</span><span class="n">xml</span><span class="o">-</span><span class="n">glob</span>
</pre></div>
</div>
<p>The output provides you with the <code class="docutils literal notranslate"><span class="pre">stderr</span></code>, the command line, and where the job was run.</p>
<p>If you have a subdax that failed, <code class="docutils literal notranslate"><span class="pre">pegasus_analyzer</span></code> will provide you with a command to recieve more information about the failed jobs in the subdax.</p>
</div>
</div>
<div class="section" id="reuse-of-data-from-a-previous-workflow">
<span id="weeklyahopereuse"></span><h2>Reuse of data from a previous workflow<a class="headerlink" href="#reuse-of-data-from-a-previous-workflow" title="Permalink to this headline">¶</a></h2>
<p>One of the features of Pegasus is reuse the data products of prior runs.
This can be used to e.g. expand an analysis or recover a run with mistaken settings without
duplicating work. The steps below explain how to do this.</p>
<div class="section" id="setting-up-a-workflow-for-data-reuse">
<h3>Setting up a workflow for data reuse<a class="headerlink" href="#setting-up-a-workflow-for-data-reuse" title="Permalink to this headline">¶</a></h3>
<p>The first step is to generate a new workflow that performs the analysis that
you would like to do. This workflow should be generated in a new directory so that it does not overwrite data from your previous workflows.
Data reuse happens at the <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code> step, so
first run <code class="docutils literal notranslate"><span class="pre">pycbc_make_coinc_search_workflow</span></code> to build a new workflow,
following the instructions in the section <a class="reference internal" href="#coincworkflowgenerate"><span class="std std-ref">Generating the workflow</span></a> of this
page.</p>
<p><strong>Stop</strong> before you plan and submit the workflow with <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code>.
You will pass an additional file to <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code> using the
<code class="docutils literal notranslate"><span class="pre">--cache-file</span></code> option with a list of files that Pegasus can re-use from a
previous run.  The Pegasus Workflow Planner will reduce the workflow
using this cache file. Reduction works by deleting jobs from the workflow
whose output files have been found in some location in this cache file.</p>
<p>The key to data reuse is building the cache file passed to <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code>. This file maps a file created in the workflow to a URL and a site where that URL can be found. The syntax of the cache file is plain ASCII with each line in the file giving the location of a file in the format:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">LOGICAL_FILE_NAME</span> <span class="n">PHYSICAL_FILE_URL</span> <span class="n">pool</span><span class="o">=</span><span class="s2">&quot;SITE&quot;</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">LOGICAL_FILE_NAME</span></code> is the name of the file as it appears in the
workflow. This should include any subdirectory path used by the workflow to organize files in the case of, e.g.,
<code class="docutils literal notranslate"><span class="pre">INSPIRAL</span></code> files but it should not be the absolute path to the file. <code class="docutils literal notranslate"><span class="pre">PHYSICAL_FILE_URL</span></code> is a
full URL where the file can be found, and <code class="docutils literal notranslate"><span class="pre">SITE</span></code> is the site on which that URL
resides.</p>
<p>The URI in the <code class="docutils literal notranslate"><span class="pre">PHYSICAL_FILE_URL</span></code> can be any of the URIs that Pegasus
recognizes. The URIs <code class="docutils literal notranslate"><span class="pre">file://</span></code>, <code class="docutils literal notranslate"><span class="pre">gsiftp://</span></code>, and <code class="docutils literal notranslate"><span class="pre">http://</span></code> are likely
the most useful. Pegasus will take care of adding transfer jobs for
<code class="docutils literal notranslate"><span class="pre">gsiftp://</span></code> and <code class="docutils literal notranslate"><span class="pre">http://</span></code> URIs, if the data is not available locally.</p>
<p>The string <code class="docutils literal notranslate"><span class="pre">SITE</span></code> is a hint that tells Pegasus on which site the
<code class="docutils literal notranslate"><span class="pre">PHYSICAL_FILE_URL</span></code> can be found. The <code class="docutils literal notranslate"><span class="pre">SITE</span></code> string should be one of the
names used by <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code> to identify the cluster where jobs are run.
In practice there are only two execution sites used by PyCBC workflows:</p>
<ol class="arabic simple">
<li><code class="docutils literal notranslate"><span class="pre">local</span></code> which is the regular Condor pool on the local cluster where the workflow is being run from. This is typically used when re-using data that exists on the filesystem of the local cluster.</li>
<li><code class="docutils literal notranslate"><span class="pre">osg</span></code> which is the Open Science Grid pool, as described in <a class="reference internal" href="#weeklyahopeosg"><span class="std std-ref">Running on the Open Science Grid</span></a> below. This is only used if the data to be re-used is accessible via the <code class="docutils literal notranslate"><span class="pre">/cvmfs</span></code> filesystem.</li>
</ol>
<p>If the <code class="docutils literal notranslate"><span class="pre">SITE</span></code> string for a file matches the site where a job will be run,
then Pegasus assumes that the file can be accessed locally via the regular
file open commands. If the <code class="docutils literal notranslate"><span class="pre">SITE</span></code> string does not match the site where a job
will be run, then Pegasus adds transfer jobs to the workflow to move the file
to the site where it will be needed by a job.</p>
<p>To tell Pegasus that the file is neither accessible via file open on the
<code class="docutils literal notranslate"><span class="pre">local</span></code> submit host nor on the <code class="docutils literal notranslate"><span class="pre">osg</span></code> pool, then the <code class="docutils literal notranslate"><span class="pre">SITE</span></code> string can be
set to <code class="docutils literal notranslate"><span class="pre">remote</span></code>. This tells Pegasus that the file is neither on the
<code class="docutils literal notranslate"><span class="pre">local</span></code> or the <code class="docutils literal notranslate"><span class="pre">osg</span></code> site and so Pegasus must add file transfer jobs to
fetch the file from some other site.  This <code class="docutils literal notranslate"><span class="pre">SITE</span></code> attribute is needed
beacuse a map between the job execution site and the location of the file
might not be obvious from the hostname in the <code class="docutils literal notranslate"><span class="pre">PHYSICAL_FILE_URL</span></code>.</p>
<p>The following rule should be helpful when chosing the <code class="docutils literal notranslate"><span class="pre">SITE</span></code> string:</p>
<ul class="simple">
<li>If you are re-using a file that is available locally with a <code class="docutils literal notranslate"><span class="pre">file://</span></code> URI in its <code class="docutils literal notranslate"><span class="pre">PHYSICAL_FILE_URL</span></code> (or has an implicit <code class="docutils literal notranslate"><span class="pre">file://</span></code> URI since the <code class="docutils literal notranslate"><span class="pre">PHYSICAL_FILE_URL</span></code> starts with a <code class="docutils literal notranslate"><span class="pre">/</span></code>) then the string <code class="docutils literal notranslate"><span class="pre">SITE</span></code> should be set to <code class="docutils literal notranslate"><span class="pre">local</span></code>.</li>
<li>If you are re-using a file from another cluster, e.g. you are on the Syracuse cluster and want to re-use data from AEI Atlas cluster, then the string <code class="docutils literal notranslate"><span class="pre">SITE</span></code> should be set to <code class="docutils literal notranslate"><span class="pre">remote</span></code> for that file. In this case, the URI in <code class="docutils literal notranslate"><span class="pre">PHYSICAL_FILE_URL</span></code> will be either <code class="docutils literal notranslate"><span class="pre">gsiftp://</span></code> or <code class="docutils literal notranslate"><span class="pre">http://</span></code> depending on how the file can be accessed.</li>
</ul>
<p>To illustrate this, an example of a simple cache file containing four files for re-use from the <code class="docutils literal notranslate"><span class="pre">local</span></code> site is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">H1</span><span class="o">-</span><span class="n">VETOTIME_CAT3</span><span class="o">-</span><span class="mi">1169107218</span><span class="o">-</span><span class="mf">1066800.</span><span class="n">xml</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">localhost</span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">dbrown</span><span class="o">/</span><span class="n">projects</span><span class="o">/</span><span class="n">aligo</span><span class="o">/</span><span class="n">o2</span><span class="o">/</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">o2</span><span class="o">-</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">results</span><span class="o">/</span><span class="mf">1.</span><span class="n">_analysis_time</span><span class="o">/</span><span class="mf">1.01</span><span class="n">_segment_data</span><span class="o">/</span><span class="n">H1</span><span class="o">-</span><span class="n">VETOTIME_CAT3</span><span class="o">-</span><span class="mi">1169107218</span><span class="o">-</span><span class="mf">1066800.</span><span class="n">xml</span> <span class="n">pool</span><span class="o">=</span><span class="s2">&quot;local&quot;</span>
<span class="n">L1</span><span class="o">-</span><span class="n">VETOTIME_CAT3</span><span class="o">-</span><span class="mi">1169107218</span><span class="o">-</span><span class="mf">1066800.</span><span class="n">xml</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">localhost</span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">dbrown</span><span class="o">/</span><span class="n">projects</span><span class="o">/</span><span class="n">aligo</span><span class="o">/</span><span class="n">o2</span><span class="o">/</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">o2</span><span class="o">-</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">results</span><span class="o">/</span><span class="mf">1.</span><span class="n">_analysis_time</span><span class="o">/</span><span class="mf">1.01</span><span class="n">_segment_data</span><span class="o">/</span><span class="n">L1</span><span class="o">-</span><span class="n">VETOTIME_CAT3</span><span class="o">-</span><span class="mi">1169107218</span><span class="o">-</span><span class="mf">1066800.</span><span class="n">xml</span> <span class="n">pool</span><span class="o">=</span><span class="s2">&quot;local&quot;</span>
<span class="mi">116912</span><span class="o">/</span><span class="n">H1</span><span class="o">-</span><span class="n">INSPIRAL_FULL_DATA_JOB0</span><span class="o">-</span><span class="mi">1169120586</span><span class="o">-</span><span class="mf">1662.</span><span class="n">hdf</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">localhost</span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">dbrown</span><span class="o">/</span><span class="n">projects</span><span class="o">/</span><span class="n">aligo</span><span class="o">/</span><span class="n">o2</span><span class="o">/</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">o2</span><span class="o">-</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">full_data</span><span class="o">/</span><span class="n">H1</span><span class="o">-</span><span class="n">INSPIRAL_FULL_DATA_JOB0</span><span class="o">-</span><span class="mi">1169120586</span><span class="o">-</span><span class="mf">1662.</span><span class="n">hdf</span> <span class="n">pool</span><span class="o">=</span><span class="s2">&quot;local&quot;</span>
<span class="mi">116912</span><span class="o">/</span><span class="n">H1</span><span class="o">-</span><span class="n">INSPIRAL_FULL_DATA_JOB1</span><span class="o">-</span><span class="mi">1169120586</span><span class="o">-</span><span class="mf">1662.</span><span class="n">hdf</span> <span class="n">file</span><span class="p">:</span><span class="o">//</span><span class="n">localhost</span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">dbrown</span><span class="o">/</span><span class="n">projects</span><span class="o">/</span><span class="n">aligo</span><span class="o">/</span><span class="n">o2</span><span class="o">/</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">o2</span><span class="o">-</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">full_data</span><span class="o">/</span><span class="n">H1</span><span class="o">-</span><span class="n">INSPIRAL_FULL_DATA_JOB1</span><span class="o">-</span><span class="mi">1169120586</span><span class="o">-</span><span class="mf">1662.</span><span class="n">hdf</span> <span class="n">pool</span><span class="o">=</span><span class="s2">&quot;local&quot;</span>
</pre></div>
</div>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">LOGICAL_FILE_NAME</span></code> for the veto files is just the name of the
file, but for the two inspiral files it contains the subdirectory that the
workflow uses to organize the files by GPS time. In the case of this file Pegasus will delete from the workflow the jobs that create the files <code class="docutils literal notranslate"><span class="pre">H1-VETOTIME_CAT3-1169107218-1066800.xml</span></code>, <code class="docutils literal notranslate"><span class="pre">L1-VETOTIME_CAT3-1169107218-1066800.xml</span></code>, <code class="docutils literal notranslate"><span class="pre">116912/H1-INSPIRAL_FULL_DATA_JOB0-1169120586-1662.hdf</span></code>, and <code class="docutils literal notranslate"><span class="pre">116912/H1-INSPIRAL_FULL_DATA_JOB1-1169120586-1662.hdf</span></code> when it plans the workflow. Insted, the data will be re-used from the URLs specified in the cache. Since <code class="docutils literal notranslate"><span class="pre">site=&quot;local&quot;</span></code> for these files, Pegasus expects that the files all exist on the host where the workflow is run from.</p>
<p>To re-use data from a remote cluster, the URLs must contain a file transfer
mechanism and the <code class="docutils literal notranslate"><span class="pre">SITE</span></code> should be set to <code class="docutils literal notranslate"><span class="pre">remote</span></code>. For example, if the
files listed in the example above are available on
<code class="docutils literal notranslate"><span class="pre">sugwg-condor.phy.syr.edu</span></code> and you want to re-use them in a workflow on the
AEI Atlas cluster, then the cache file would contain:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">H1</span><span class="o">-</span><span class="n">VETOTIME_CAT3</span><span class="o">-</span><span class="mi">1169107218</span><span class="o">-</span><span class="mf">1066800.</span><span class="n">xml</span> <span class="n">gsiftp</span><span class="p">:</span><span class="o">//</span><span class="n">sugwg</span><span class="o">-</span><span class="n">condor</span><span class="o">.</span><span class="n">phy</span><span class="o">.</span><span class="n">syr</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">dbrown</span><span class="o">/</span><span class="n">projects</span><span class="o">/</span><span class="n">aligo</span><span class="o">/</span><span class="n">o2</span><span class="o">/</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">o2</span><span class="o">-</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">results</span><span class="o">/</span><span class="mf">1.</span><span class="n">_analysis_time</span><span class="o">/</span><span class="mf">1.01</span><span class="n">_segment_data</span><span class="o">/</span><span class="n">H1</span><span class="o">-</span><span class="n">VETOTIME_CAT3</span><span class="o">-</span><span class="mi">1169107218</span><span class="o">-</span><span class="mf">1066800.</span><span class="n">xml</span> <span class="n">pool</span><span class="o">=</span><span class="s2">&quot;remote&quot;</span>
<span class="n">L1</span><span class="o">-</span><span class="n">VETOTIME_CAT3</span><span class="o">-</span><span class="mi">1169107218</span><span class="o">-</span><span class="mf">1066800.</span><span class="n">xml</span> <span class="n">gsiftp</span><span class="p">:</span><span class="o">//</span><span class="n">sugwg</span><span class="o">-</span><span class="n">condor</span><span class="o">.</span><span class="n">phy</span><span class="o">.</span><span class="n">syr</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">dbrown</span><span class="o">/</span><span class="n">projects</span><span class="o">/</span><span class="n">aligo</span><span class="o">/</span><span class="n">o2</span><span class="o">/</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">o2</span><span class="o">-</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">results</span><span class="o">/</span><span class="mf">1.</span><span class="n">_analysis_time</span><span class="o">/</span><span class="mf">1.01</span><span class="n">_segment_data</span><span class="o">/</span><span class="n">L1</span><span class="o">-</span><span class="n">VETOTIME_CAT3</span><span class="o">-</span><span class="mi">1169107218</span><span class="o">-</span><span class="mf">1066800.</span><span class="n">xml</span> <span class="n">pool</span><span class="o">=</span><span class="s2">&quot;remote&quot;</span>
<span class="mi">116912</span><span class="o">/</span><span class="n">H1</span><span class="o">-</span><span class="n">INSPIRAL_FULL_DATA_JOB0</span><span class="o">-</span><span class="mi">1169120586</span><span class="o">-</span><span class="mf">1662.</span><span class="n">hdf</span> <span class="n">gsiftp</span><span class="p">:</span><span class="o">//</span><span class="n">sugwg</span><span class="o">-</span><span class="n">condor</span><span class="o">.</span><span class="n">phy</span><span class="o">.</span><span class="n">syr</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">dbrown</span><span class="o">/</span><span class="n">projects</span><span class="o">/</span><span class="n">aligo</span><span class="o">/</span><span class="n">o2</span><span class="o">/</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">o2</span><span class="o">-</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">full_data</span><span class="o">/</span><span class="n">H1</span><span class="o">-</span><span class="n">INSPIRAL_FULL_DATA_JOB0</span><span class="o">-</span><span class="mi">1169120586</span><span class="o">-</span><span class="mf">1662.</span><span class="n">hdf</span> <span class="n">pool</span><span class="o">=</span><span class="s2">&quot;remote&quot;</span>
<span class="mi">116912</span><span class="o">/</span><span class="n">H1</span><span class="o">-</span><span class="n">INSPIRAL_FULL_DATA_JOB1</span><span class="o">-</span><span class="mi">1169120586</span><span class="o">-</span><span class="mf">1662.</span><span class="n">hdf</span> <span class="n">gsiftp</span><span class="p">:</span><span class="o">//</span><span class="n">sugwg</span><span class="o">-</span><span class="n">condor</span><span class="o">.</span><span class="n">phy</span><span class="o">.</span><span class="n">syr</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">dbrown</span><span class="o">/</span><span class="n">projects</span><span class="o">/</span><span class="n">aligo</span><span class="o">/</span><span class="n">o2</span><span class="o">/</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">o2</span><span class="o">-</span><span class="n">analysis</span><span class="o">-</span><span class="mi">4</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">full_data</span><span class="o">/</span><span class="n">H1</span><span class="o">-</span><span class="n">INSPIRAL_FULL_DATA_JOB1</span><span class="o">-</span><span class="mi">1169120586</span><span class="o">-</span><span class="mf">1662.</span><span class="n">hdf</span> <span class="n">pool</span><span class="o">=</span><span class="s2">&quot;remote&quot;</span>
</pre></div>
</div>
<p>Note that the URL now contains <code class="docutils literal notranslate"><span class="pre">gsiftp://sugwg-condor.phy.syr.edu</span></code> rather
than <code class="docutils literal notranslate"><span class="pre">file://localhost</span></code> and the files are listes as <code class="docutils literal notranslate"><span class="pre">pool=&quot;remote&quot;</span></code> rather
than <code class="docutils literal notranslate"><span class="pre">pool=&quot;local&quot;</span></code>. Pegasus will re-use these data files adding in
file transfer jobs to the workflow to move them into the appropriate
locations.</p>
<p>Once a cache file has been constructed, to enable data re-use, you follow the
standard instructions for planning and submitting the workflow in the section
<a class="reference internal" href="#coincworkflowplan"><span class="std std-ref">Planning and Submitting the Workflow</span></a>, but add the <code class="docutils literal notranslate"><span class="pre">--cache-file</span></code> argument that points to
the cache file that you have created. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pycbc_submit_dax</span> <span class="o">--</span><span class="n">cache</span><span class="o">-</span><span class="n">file</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">prior_data</span><span class="o">.</span><span class="n">map</span> <span class="o">--</span><span class="n">accounting</span><span class="o">-</span><span class="n">group</span> <span class="n">ligo</span><span class="o">.</span><span class="n">dev</span><span class="o">.</span><span class="n">o1</span><span class="o">.</span><span class="n">cbc</span><span class="o">.</span><span class="n">explore</span><span class="o">.</span><span class="n">test</span> <span class="o">--</span><span class="n">dax</span> <span class="n">s6d_chunk3</span><span class="o">.</span><span class="n">dax</span>
</pre></div>
</div>
<p>will use the URLs from the file <code class="docutils literal notranslate"><span class="pre">/path/to/prior_data.map</span></code> to implement
data re-use and subsequent workflow reduction. If more than once cache file is
provided, pass the paths as a comma separated list to <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pycbc_submit_dax</span> <span class="o">--</span><span class="n">cache</span><span class="o">-</span><span class="n">file</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">prior_data</span><span class="o">.</span><span class="n">map</span><span class="p">,</span><span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">other</span><span class="o">.</span><span class="n">map</span> <span class="o">--</span><span class="n">accounting</span><span class="o">-</span><span class="n">group</span> <span class="n">ligo</span><span class="o">.</span><span class="n">dev</span><span class="o">.</span><span class="n">o1</span><span class="o">.</span><span class="n">cbc</span><span class="o">.</span><span class="n">explore</span><span class="o">.</span><span class="n">test</span> <span class="o">--</span><span class="n">dax</span> <span class="n">s6d_chunk3</span><span class="o">.</span><span class="n">dax</span>
</pre></div>
</div>
<p>Which file URLs should be included in the reuse cache? There is no single
correct way of deciding this, as it depends on exactly what you are trying to do. The sections
below explain how to do this for a few common situations.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The <code class="docutils literal notranslate"><span class="pre">[workflow]</span></code> section of the ini configuration file contains an
option <code class="docutils literal notranslate"><span class="pre">file-retention-level</span></code>. This is commonly set to <code class="docutils literal notranslate"><span class="pre">all_files</span></code> or
<code class="docutils literal notranslate"><span class="pre">all_triggers</span></code>, in which case the data products re-used will be copied
from the input locations and stored into the output location of the new
workflow when the new workflow is run with data re-use. This can be
wasteful of disk space, so you may want to set this option to either
<code class="docutils literal notranslate"><span class="pre">merged_triggers</span></code> or <code class="docutils literal notranslate"><span class="pre">results</span></code> to store a smaller sub-set of the
workflow’s data products. These setting will allow the use of data from
a previous run, but not make duplicate copies of intermediate data files.
See the documentation under <a class="reference internal" href="initialization.html#workflowconfigparsermod"><span class="std std-ref">Pycbc’s workflow module configuration file(s) and command line interface</span></a> for more
details of the <code class="docutils literal notranslate"><span class="pre">file-retention-level</span></code> configuration option.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">At present you <em>cannot</em> re-use <code class="docutils literal notranslate"><span class="pre">.dax</span></code> and <code class="docutils literal notranslate"><span class="pre">.map</span></code> files from a previous
run. A workflow using data reuse must regenerate and re-run any sub-daxes
from scratch. If you re-use a <code class="docutils literal notranslate"><span class="pre">.map</span></code> file rather than re-generating it,
then the new workflow will write results files in the location of the old
workflow. All of the examples below use an <code class="docutils literal notranslate"><span class="pre">egrep</span> <span class="pre">-v</span> <span class="pre">'(dax|map)'</span></code> to
filter out these files.</p>
</div>
</div>
<div class="section" id="extending-the-gps-end-time-of-a-previous-workflow">
<span id="workflow-rerun-extend"></span><h3>Extending the GPS end time of a previous workflow<a class="headerlink" href="#extending-the-gps-end-time-of-a-previous-workflow" title="Permalink to this headline">¶</a></h3>
<p>A common mode of data re-use is to extend the GPS end time of a previous
workflow to generate a new result page that e.g. extends the analysis by a few
days. This assumes that:</p>
<ul class="simple">
<li>The previous workflow completed successfully.</li>
<li>There are no changes to the workflow configuration file, other than incrementing the end time of the workflow.</li>
</ul>
<p>In this case, first re-run <code class="docutils literal notranslate"><span class="pre">pycbc_make_coinc_search_workflow</span></code> to build the
new workflow. The normal file retention level will copy a lot of reused data
from the previous workflow directory into the new workflow directory. If you
do not want to do this, use a <code class="docutils literal notranslate"><span class="pre">--config-override</span></code> to change the value of
<code class="docutils literal notranslate"><span class="pre">workflow:file-retention-level</span></code> as described on the page
<a class="reference internal" href="initialization.html#workflowconfigparsermod"><span class="std std-ref">Pycbc’s workflow module configuration file(s) and command line interface</span></a>.</p>
<p>Then create a cache file in the following way:</p>
<ol class="arabic simple">
<li>Locate the PyCBC result page for the workflow that you wish to extend.</li>
<li>In the menu under <strong>Section 8: Workflow</strong>, locate the <strong>Output map</strong> section (usually Section 8.06) and open that page.</li>
<li>This page will show three output cache files that contain the URLs of the data created by the workflow. Locate the file that ends <code class="docutils literal notranslate"><span class="pre">main.map</span></code> and download it by clicking on the <strong>Link to file</strong>. This file contains the main intermediate and output data products of the workflow.</li>
</ol>
<p>4. Edit this file so that it only contains the output of the <code class="docutils literal notranslate"><span class="pre">pycbc_inspiral</span></code> jobs, i.e. delete all of the lines that do not match the pattern <code class="docutils literal notranslate"><span class="pre">*INSPIRAL*hdf</span></code>. You can do this in a text editor, or with your favorite combination of UNIX <code class="docutils literal notranslate"><span class="pre">grep</span></code>, <code class="docutils literal notranslate"><span class="pre">sed</span></code>, <code class="docutils literal notranslate"><span class="pre">awk</span></code>, or <code class="docutils literal notranslate"><span class="pre">perl</span></code> commands.
For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">egrep</span> <span class="s1">&#39;INSPIRAL.*hdf&#39;</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">downloaded</span><span class="o">/</span><span class="n">workflow</span><span class="o">-</span><span class="n">main</span><span class="o">.</span><span class="n">map</span> <span class="o">&gt;</span> <span class="n">inspiral_files</span><span class="o">.</span><span class="n">map</span>
</pre></div>
</div>
<p>will pull out all cache file lines for the outputs of <code class="docutils literal notranslate"><span class="pre">pycbc_inspiral</span></code> files and write them to a new cache file called <code class="docutils literal notranslate"><span class="pre">inspiral_files.map</span></code>.</p>
<ol class="arabic" start="5">
<li><p class="first">If the files in the new cache file exist locally on the cluster where you are submitting the workflow, then the cache file is complete. If they do not, you will need to modify the file to change the <code class="docutils literal notranslate"><span class="pre">PHYSICAL_FILE_URL</span></code> to a valid <code class="docutils literal notranslate"><span class="pre">gsiftp://</span></code> or <code class="docutils literal notranslate"><span class="pre">http://</span></code> URL on the remote cluster, and change <code class="docutils literal notranslate"><span class="pre">pool=&quot;local&quot;</span></code> to <code class="docutils literal notranslate"><span class="pre">pool=&quot;remote&quot;</span></code>. Again, these changes can be made with a text editor or UNIX shell tools. For example, if the file URLs begin with <code class="docutils literal notranslate"><span class="pre">/home/dbrown</span></code> and they are on the Syracuse cluster, to run on Atlas you would use the following <code class="docutils literal notranslate"><span class="pre">sed</span></code> commands to change the <code class="docutils literal notranslate"><span class="pre">SITE</span></code> and the URI in the cache file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sed</span> <span class="s1">&#39;s/pool=&quot;local&quot;/pool=&quot;remote&quot;/g&#39;</span> <span class="n">inspiral_files</span><span class="o">.</span><span class="n">map</span> <span class="o">&gt;</span> <span class="n">inspiral_files</span><span class="o">.</span><span class="n">map</span><span class="o">.</span><span class="n">tmp</span>
<span class="n">sed</span> <span class="s1">&#39;s+/home/dbrown+gsiftp://sugwg-condor.phy.syr.edu/home/dbrown+g&#39;</span> <span class="n">inspiral_files</span><span class="o">.</span><span class="n">map</span><span class="o">.</span><span class="n">tmp</span> <span class="o">&gt;</span> <span class="n">inspiral_files</span><span class="o">.</span><span class="n">map</span>
<span class="n">rm</span> <span class="n">inspiral_files</span><span class="o">.</span><span class="n">map</span><span class="o">.</span><span class="n">tmp</span>
</pre></div>
</div>
</li>
<li><p class="first">Finally, copy the file <code class="docutils literal notranslate"><span class="pre">inspiral_files.map</span></code> to your new workflow directory and then run <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code> as usual, giving the path to <code class="docutils literal notranslate"><span class="pre">inspiral_files.map</span></code> as the <code class="docutils literal notranslate"><span class="pre">--cache-file</span></code> argument.</p>
</li>
</ol>
</div>
<div class="section" id="re-running-a-workflow-using-a-new-veto-definer-file">
<h3>Re-running a workflow using a new veto definer file<a class="headerlink" href="#re-running-a-workflow-using-a-new-veto-definer-file" title="Permalink to this headline">¶</a></h3>
<p>Data reuse can be used to re-running a workflow with a new veto definer file, assuming that:</p>
<ul class="simple">
<li>The previous workflow completed successfully.</li>
<li>No changes to the configuration file are made, other than changing the <code class="docutils literal notranslate"><span class="pre">segments-veto-definer-url</span></code> in the <code class="docutils literal notranslate"><span class="pre">[workflow-segments]</span></code> section of the workflow configration file (although the GPS end time can also be extended at the same time, if necessary).</li>
</ul>
<p>In this case, first re-run <code class="docutils literal notranslate"><span class="pre">pycbc_make_coinc_search_workflow</span></code> to build the
new workflow. The normal file retention level will copy a lot of reused data
from the previous workflow directory into the new workflow directory. If you
do not want to do this, use a <code class="docutils literal notranslate"><span class="pre">--config-override</span></code> to change the value of
<code class="docutils literal notranslate"><span class="pre">workflow:file-retention-level</span></code> as described on the page
<a class="reference internal" href="initialization.html#workflowconfigparsermod"><span class="std std-ref">Pycbc’s workflow module configuration file(s) and command line interface</span></a>.</p>
<p>Then create the cache file as follows:</p>
<ol class="arabic simple">
<li>Locate the PyCBC result page for the workflow that you wish to extend.</li>
<li>In the menu under <strong>Section 8: Workflow</strong>, locate the <strong>Output map</strong> section (usually Section 8.06) and open that page.</li>
<li>This page will show three output cache files that contain the URLs of the data created by the workflow. Locate the file that ends <code class="docutils literal notranslate"><span class="pre">main.map</span></code> and download it by clicking on the <strong>Link to file</strong>. This file contains the main intermediate and output data products of the workflow.</li>
<li>If only category 2 and higher vetoes have change, remove the output files that match the following strings from the output map file:</li>
</ol>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">VETOTIME</span></code> to remove the files containing the old veto segments.</li>
<li><code class="docutils literal notranslate"><span class="pre">LIGOLW_COMBINE_SEGMENTS</span></code> to remove the files that combine the veto segments into categories.</li>
<li><code class="docutils literal notranslate"><span class="pre">CUMULATIVE_CAT_12H_VETO_SEGMENTS</span></code> to remove the files that contain times to veto.</li>
<li><code class="docutils literal notranslate"><span class="pre">COINC</span></code> to remove the output of the coincidence code.</li>
<li><code class="docutils literal notranslate"><span class="pre">FIT</span></code> to remove the background bin statistic results.</li>
<li><code class="docutils literal notranslate"><span class="pre">STATMAP</span></code> to remove the detection statistic ranking output.</li>
<li><code class="docutils literal notranslate"><span class="pre">INJFIND</span></code> to remove the results of software-injection tests.</li>
<li><code class="docutils literal notranslate"><span class="pre">PAGE</span></code> to remove the results make with the loudest events.</li>
<li><code class="docutils literal notranslate"><span class="pre">FOREGROUND_CENSOR</span></code> to remove the veto files used to remove events from the closed box plots.</li>
<li><code class="docutils literal notranslate"><span class="pre">html</span></code> to remove any output web pages genereated.</li>
<li><code class="docutils literal notranslate"><span class="pre">png</span></code> to remove any output plots generated.</li>
<li><code class="docutils literal notranslate"><span class="pre">dax</span></code> to remove any follow-up workflows generated.</li>
</ul>
</div></blockquote>
<p>This can be acomplished with the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">egrep</span> <span class="o">-</span><span class="n">v</span> <span class="s1">&#39;(VETOTIME|LIGOLW_COMBINE_SEGMENTS|CUMULATIVE_CAT_12H_VETO_SEGMENTS|COINC|FIT|STATMAP|INJFIND|PAGE|FOREGROUND_CENSOR|html|png|dax)&#39;</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">main</span><span class="o">.</span><span class="n">map</span> <span class="o">&gt;</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">reuse_cache</span><span class="o">.</span><span class="n">map</span>
</pre></div>
</div>
<p>If category 1 vetoes have changed, you must also remove files matching <code class="docutils literal notranslate"><span class="pre">PSD</span></code>, <code class="docutils literal notranslate"><span class="pre">OPTIMAL</span></code>, and <code class="docutils literal notranslate"><span class="pre">MERGE</span></code> to remove the PSD estimation jobs, the jobs that compute the optimal SNR of injections, and the merged single-detector inspiral trigger files which may also change if the category 1 vetoes change.</p>
<ol class="arabic simple" start="6">
<li>Copy the file <code class="docutils literal notranslate"><span class="pre">reuse_cache.map</span></code> to your new workflow directory and then run <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code> as usual, giving the path to <code class="docutils literal notranslate"><span class="pre">reuse_cache.map</span></code> as the <code class="docutils literal notranslate"><span class="pre">--cache-file</span></code> argument.</li>
</ol>
</div>
<div class="section" id="re-running-a-failed-workflow">
<h3>Re-running a failed workflow<a class="headerlink" href="#re-running-a-failed-workflow" title="Permalink to this headline">¶</a></h3>
<p>Occasionally it may be necessary to use data from a partially completed
workflow, e.g. if there a bug in an executable and you wish to re-run the
workflow with a new version of the executable. If the workflow failed, no
results web page will have been generated and the output data may not have
been copied to the locations in <code class="docutils literal notranslate"><span class="pre">main.map</span></code>. To re-use data from a previous
failed workflow, you need to create a cache file containing the completed jobs
from the previous workflow.</p>
<p>To do this, <code class="docutils literal notranslate"><span class="pre">cd</span></code> into the <code class="docutils literal notranslate"><span class="pre">local-site-scratch/work</span></code> directory of your
failed workflow. For example, if you used <code class="docutils literal notranslate"><span class="pre">--output-dir</span> <span class="pre">output</span></code> when
planning the workflow, and then run the command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">workflow</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">local</span><span class="o">-</span><span class="n">site</span><span class="o">-</span><span class="n">scratch</span><span class="o">/</span><span class="n">work</span>
</pre></div>
</div>
<p>Once in this directory there should be a directory that ends with
<code class="docutils literal notranslate"><span class="pre">main_ID0000001</span></code> (e.g. <code class="docutils literal notranslate"><span class="pre">my-workflow-main_ID0000001</span></code>) Change into that
directory.</p>
<p>Once in the <code class="docutils literal notranslate"><span class="pre">main_ID0000001</span></code> directory, run the command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>for pfn in `find . -type f | sed &#39;s+^./++g&#39;` ; do echo $pfn file://`pwd`/$pfn pool=\&quot;local\&quot; ; done | egrep -v &#39;(dax|map)&#39; &gt; /path/to/partial_workflow.map
</pre></div>
</div>
<p>changing <code class="docutils literal notranslate"><span class="pre">/path/to</span></code> to a location where you want to save the cache.</p>
<p>Now you can than use the <code class="docutils literal notranslate"><span class="pre">partial_workflow.map</span></code> cache file as the <code class="docutils literal notranslate"><span class="pre">--cache-file</span></code> argument to <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code>.</p>
</div>
<div class="section" id="using-partial-products-from-a-previous-workflow">
<h3>Using partial products from a previous workflow<a class="headerlink" href="#using-partial-products-from-a-previous-workflow" title="Permalink to this headline">¶</a></h3>
<p>If you are changing the configuration parameters of a workflow, then you can
build a cache file from a previous <code class="docutils literal notranslate"><span class="pre">main.map</span></code> file or the files under
<code class="docutils literal notranslate"><span class="pre">local-site-scratch</span></code>, but you will need to filter the cache file to remove
the files for jobs that have a changed configuration.  Here are a few
examples:</p>
<ul>
<li><p class="first">If you are changing the configuration of <code class="docutils literal notranslate"><span class="pre">pycbc_inspiral</span></code> you must regenerate almost all the files in the workflow so it easier to start from scratch.</p>
</li>
<li><p class="first">If you are changing the injections, but want to re-use the <code class="docutils literal notranslate"><span class="pre">FULL_DATA</span></code> previous analysis, you can filter the <code class="docutils literal notranslate"><span class="pre">main.map</span></code> to keep the veto files, template bank files, full data inspiral files, and PSD files but filtering out any plots and result pages. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">egrep</span> <span class="s1">&#39;(VETO|BANK|INSPIRAL_FULL_DATA|MERGE_FULL_DATA|PSD)&#39;</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">main</span><span class="o">.</span><span class="n">map</span> <span class="o">|</span> <span class="n">egrep</span> <span class="o">-</span><span class="n">v</span> <span class="s1">&#39;(png|html|dax)&#39;</span> <span class="o">&gt;</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">reuse</span><span class="o">.</span><span class="n">map</span>
</pre></div>
</div>
</li>
<li><p class="first">If you are changing the configuration of the coincident code, you can reuse all the injection files and inspiral files. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">egrep</span> <span class="s1">&#39;(VETO|BANK|FULL_DATA|PSD)&#39;</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">main</span><span class="o">.</span><span class="n">map</span> <span class="o">|</span> <span class="n">egrep</span> <span class="o">-</span><span class="n">v</span> <span class="s1">&#39;(COINC|FIT|STATMAP|INJFIND|html|png|dax)&#39;</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">main</span><span class="o">.</span><span class="n">map</span> <span class="o">&gt;</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">reuse</span><span class="o">.</span><span class="n">map</span>
</pre></div>
</div>
</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">There is no rule for exactly which products can be reused as it depends on what you are changing in the workflow configuration. For partial reuse, it is best to consult an expert on how to build the cache file.</p>
</div>
</div>
</div>
<div class="section" id="running-on-the-open-science-grid">
<span id="weeklyahopeosg"></span><h2>Running on the Open Science Grid<a class="headerlink" href="#running-on-the-open-science-grid" title="Permalink to this headline">¶</a></h2>
<div class="section" id="prerequisites">
<h3>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h3>
<p>There are a number of requirements on the machine on which the workflow will be started:</p>
<ul>
<li><p class="first">Pegasus version 4.7.1 or later (at least 4.9.2 recommended).</p>
</li>
<li><p class="first">A gridftp server running on the submit machine</p>
</li>
<li><p class="first">Condor configured on the head node to connect to OSG as documented at:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>https://its-condor-blog.syr.edu/dokuwiki/doku.php?id=researchgroups:physics:sl7_cluster_setup
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="configuring-the-workflow">
<h3>Configuring the workflow<a class="headerlink" href="#configuring-the-workflow" title="Permalink to this headline">¶</a></h3>
<p>These instructions are for the case where you plan to run all <code class="docutils literal notranslate"><span class="pre">pycbc_inspiral</span></code> jobs
on the Open Science Grid, but the rest of the workflow will run on the local HTCondor pool
attached to the submit machine.  For many clusters, including LDG clusters,
running in this fashion may not be available from every submit machine. First,
check with local sysadmins or other experts if there is a particular node from which
you must plan and submit your workflow if you desire to run on the OSG.</p>
<p>The first step in such running is to ensure that your workflow knows where to find
all of the data it needs. While some of the files generated during the workflow will need
to be served via gridftp from your submission head node (as detailed below), the gravitational
wave frame data files are too large for this. They are available from CVMFS and other
fall-back locations, but you need to make sure that your datafind server returns these
locations (it may not do so on an LDG head node, for example, if you use the default datafind
server). If you have LIGO.org credentials, you should execute:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">LIGO_DATAFIND_SERVER</span><span class="o">=</span><span class="s2">&quot;datafind.ligo.org&quot;</span>
</pre></div>
</div>
<p>before you run <code class="docutils literal notranslate"><span class="pre">pycbc_make_coinc_search_workflow</span></code>. Otherwise, contact your local system
administrator for a valid datafind server that points to publicly available frame files.</p>
<p>In order to run <code class="docutils literal notranslate"><span class="pre">pycbc_inspiral</span></code> on OSG worker nodes, it must be available
in a Singularity container served from CVMFS. Releases of PyCBC build such containers
and publish them to CVMFS, but the workflow needs to be told to only run on nodes that
have Singularity available, and it needs the location of the <code class="docutils literal notranslate"><span class="pre">pycbc_inspiral</span></code> executable
inside of the Singularity image. To do this, add the following to the <code class="docutils literal notranslate"><span class="pre">--config-overrides</span></code>
given to <code class="docutils literal notranslate"><span class="pre">pycbc_make_coinc_search_workflow</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;pegasus_profile-inspiral:pycbc|site:osg&quot;</span> \
<span class="s2">&quot;pegasus_profile-inspiral:hints|execution.site:osg&quot;</span> \
<span class="s2">&quot;pegasus_profile-inspiral:condor|Requirements:(HAS_SINGULARITY =?= TRUE) &amp;&amp; (IS_GLIDEIN =?= True)&quot;</span> \
<span class="s2">&quot;executables:inspiral:/bin/pycbc_inspiral&quot;</span> \
</pre></div>
</div>
<p>These lines tell <code class="docutils literal notranslate"><span class="pre">pycbc_make_coinc_search_workflow</span></code> that the inspiral jobs will
run on the Open Science Grid, and that such jobs need to run at sites where Singularity
is installed. They also tell them that the path to <code class="docutils literal notranslate"><span class="pre">pycbc_inspiral</span></code> inside the container
is <code class="docutils literal notranslate"><span class="pre">/bin/pycbc_inspiral</span></code>. If you are an LVK user, and you will be accessing non-public
LVK data, then you additionally must specify that you need to run at nodes where this
authenticated frame data is available.  To do that, change the <code class="docutils literal notranslate"><span class="pre">Requirements</span></code> line above
to read instead:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;pegasus_profile-inspiral:condor|Requirements:(HAS_SINGULARITY =?= TRUE) &amp;&amp; (HAS_LIGO_FRAMES =?= True) &amp;&amp; (IS_GLIDEIN =?= True)&quot;</span> \
</pre></div>
</div>
<p>Because the data that the inspiral jobs will need in addition to the frame files must
come from the submit machine, you also need a <code class="docutils literal notranslate"><span class="pre">--config-overrides</span></code> argument to
<code class="docutils literal notranslate"><span class="pre">pycbc_make_coinc_search_workflow</span></code> that sets the staging site for the main workflow to be
the local site. To do this, add the following argument, replacing <code class="docutils literal notranslate"><span class="pre">${WORKFLOW_NAME}</span></code> with
the string that is given as the argument to the option <code class="docutils literal notranslate"><span class="pre">--workflow-name</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;workflow-$</span><span class="si">{WORKFLOW_NAME}</span><span class="s2">-main:staging-site:osg=local&quot;</span>
</pre></div>
</div>
<p>Optionally, you can add a configuration that will check that your grid proxy
is valid locally before submitting the job. This means that if your grid proxy
expires before the workflow is complete, the failure will be on the local site
before the job is actually submitted, and not on the remote site once the job
has been scheduled and matched:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;pegasus_profile-inspiral:dagman|pre:/usr/bin/grid-proxy-info&quot;</span>
</pre></div>
</div>
<p>Another useful enhancement for OSG running is to add profiles to your inspiral
job that will tell Condor to put it on hold if it has been running for more
that 48 hours and terminate it after 5 failed attempts. To do this, add the
follwing lines to your <code class="docutils literal notranslate"><span class="pre">executables.ini</span></code> file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">pegasus_profile</span><span class="o">-</span><span class="n">inspiral</span><span class="p">]</span>
<span class="n">condor</span><span class="o">|</span><span class="n">periodic_hold</span> <span class="o">=</span> <span class="p">(</span><span class="n">JobStatus</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="p">((</span><span class="n">CurrentTime</span> <span class="o">-</span> <span class="n">EnteredCurrentStatus</span><span class="p">)</span> <span class="o">&gt;</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="mi">86400</span><span class="p">))</span>
<span class="n">condor</span><span class="o">|</span><span class="n">periodic_release</span> <span class="o">=</span> <span class="p">(</span><span class="n">JobStatus</span> <span class="o">==</span> <span class="mi">5</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">HoldReasonCode</span> <span class="o">==</span> <span class="mi">3</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">NumJobStarts</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="p">((</span><span class="n">CurrentTime</span> <span class="o">-</span> <span class="n">EnteredCurrentStatus</span><span class="p">)</span> <span class="o">&gt;</span> <span class="p">(</span><span class="mi">300</span><span class="p">))</span>
<span class="n">condor</span><span class="o">|</span><span class="n">periodic_remove</span> <span class="o">=</span> <span class="p">(</span><span class="n">NumJobStarts</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="running-the-workflow">
<h3>Running the workflow<a class="headerlink" href="#running-the-workflow" title="Permalink to this headline">¶</a></h3>
<p>Once you have planned the workflow as above, you must also modify the submission of the
workflow if it is to run successfully on the OSG.  Add the following additional
arguments to <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>--no-create-proxy \
--execution-sites osg \
--append-pegasus-property &#39;pegasus.transfer.bypass.input.staging=true&#39; \
--local-staging-server gsiftp://`hostname -f` \
--remote-staging-server gsiftp://`hostname -f` \
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">hostname</span> <span class="pre">-f</span></code> will give the correct value if there is a gsiftp server running on the
submit machine.  If not, change this as needed. The <code class="docutils literal notranslate"><span class="pre">remote-staging-server</span></code> is the
intermediary computer than can pass files between the submitting computer and the computers
doing the work.  <code class="docutils literal notranslate"><span class="pre">hostname</span> <span class="pre">-f</span></code> returns the full name of the computer. This full name has
to be one that is accessible to both the submit machine and the workers. The <code class="docutils literal notranslate"><span class="pre">--no-create-proxy</span></code>
may be omitted if you have LIGO.org credentials and will be retrieving data from authenticated
locations in CVMFS.</p>
<p>You will also need to specify where the code should get the data needed to generate reduced
order model waveforms. To do this add the following additional arguments to <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">append</span><span class="o">-</span><span class="n">site</span><span class="o">-</span><span class="n">profile</span> <span class="s1">&#39;local:env|LAL_DATA_PATH:/cvmfs/oasis.opensciencegrid.org/ligo/sw/pycbc/lalsuite-extra/current/share/lalsimulation&#39;</span> \
<span class="o">--</span><span class="n">append</span><span class="o">-</span><span class="n">site</span><span class="o">-</span><span class="n">profile</span> <span class="s1">&#39;osg:env|LAL_DATA_PATH:/cvmfs/oasis.opensciencegrid.org/ligo/sw/pycbc/lalsuite-extra/current/share/lalsimulation&#39;</span> \
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">current</span></code> is a symbolic link to the latest version of the data and can be replaced with a
specific release (e.g. <code class="docutils literal notranslate"><span class="pre">e02dab8c</span></code>) if required.</p>
<p>It is also through arguments to <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code> that the workflow is made aware of which
Singularity image to use when running <code class="docutils literal notranslate"><span class="pre">pycbc_inspiral</span></code>. This is done by including the following
argument to <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">append</span><span class="o">-</span><span class="n">site</span><span class="o">-</span><span class="n">profile</span> <span class="s2">&quot;osg:condor|+SingularityImage:</span><span class="se">\&quot;</span><span class="s2">/cvmfs/singularity.opensciencegrid.org/pycbc/pycbc-el8:latest</span><span class="se">\&quot;</span><span class="s2">&quot;</span> \
</pre></div>
</div>
<p>The precise line above will cause <code class="docutils literal notranslate"><span class="pre">pycbc_inspiral</span></code> to run using the code in the latest version of PyCBC
as found on the <code class="docutils literal notranslate"><span class="pre">master</span></code> branch. You may well prefer a specific version (for example, for a production
run) and each release will also have a corresponding Singularity image published to CVMFS.  For example,
to use the <code class="docutils literal notranslate"><span class="pre">1.14.3</span></code> release of PyCBC, use instead the line:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">append</span><span class="o">-</span><span class="n">site</span><span class="o">-</span><span class="n">profile</span> <span class="s2">&quot;osg:condor|+SingularityImage:</span><span class="se">\&quot;</span><span class="s2">/cvmfs/singularity.opensciencegrid.org/pycbc/pycbc-el8:v1.14.3</span><span class="se">\&quot;</span><span class="s2">&quot;</span> \
</pre></div>
</div>
<p>You may also direct the workflow to use a Singularity image of your own, if that has been published to CVMFS.</p>
<p>When running on the OSG under Singularity, by default much of the environment of the host node where the
job runs will be inherited inside the container.  In many cases this is desired, as some of the file-transfer
tools that Pegasus requires can come from that environment. In other cases, however, that environment may
interfere with what is in the container, and from release 1.14.3 onwards, the container itself includes
any necessary file transfer tools. If you want to be sure that it is the tools installed inside the container
that are used, then you must direct the workflow to have a clean environment inside the container, with nothing
in it that you have not specified using lines of the form <code class="docutils literal notranslate"><span class="pre">--append-site-profile</span> <span class="pre">'osg:env|VARNAME:VALUE</span></code>
(there will also be present in the environment a few other variables that are needed for proper running of
Pegasus and HTCondor). To specify that you need your OSG jobs to run in a clean environment, also include
the following lines when invoking <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">append</span><span class="o">-</span><span class="n">site</span><span class="o">-</span><span class="n">profile</span> <span class="s2">&quot;osg:condor|+InitializeModulesEnv:False&quot;</span> \
<span class="o">--</span><span class="n">append</span><span class="o">-</span><span class="n">site</span><span class="o">-</span><span class="n">profile</span> <span class="s2">&quot;osg:condor|+SingularityCleanEnv:True&quot;</span> \
<span class="o">--</span><span class="n">append</span><span class="o">-</span><span class="n">site</span><span class="o">-</span><span class="n">profile</span> <span class="s2">&quot;osg:condor|getenv:False&quot;</span> \
</pre></div>
</div>
<p>In particular, it is recommended that LVK users run with the lines above.</p>
<p>So far, we have described the arguments that  will allow <code class="docutils literal notranslate"><span class="pre">pycbc_inspiral</span></code> to run on any OSG machine to which
you have access. If, in addition, you would like to run on an XSEDE resource on which you have an allocation,
then add the argument:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">append</span><span class="o">-</span><span class="n">site</span><span class="o">-</span><span class="n">profile</span> <span class="s1">&#39;osg:condor|+DESIRED_XSEDE_Sites:&quot;Comet&quot;&#39;</span> \
</pre></div>
</div>
<p>where you replace the desired site (in this example the Comet cluster) with wherever you have an allocation. If
you want to run <strong>only</strong> on that XSEDE cluster, then also add:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">append</span><span class="o">-</span><span class="n">site</span><span class="o">-</span><span class="n">profile</span> <span class="s1">&#39;osg:condor|+DESIRED_SITES:&quot;Comet&quot;&#39;</span> \
</pre></div>
</div>
<p>Shared file systems cannot be used with the OSG, so make sure that the <code class="docutils literal notranslate"><span class="pre">--enable-shared-filesystem</span></code> argument is
not provided to <code class="docutils literal notranslate"><span class="pre">pycbc_submit_dax</span></code> when running on the OSG.</p>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="pycbc_make_psd_estimation_workflow.html" class="btn btn-neutral float-left" title="pycbc_make_psd_estimation_workflow: A workflow generator for noise estimation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="pygrb.html" class="btn btn-neutral float-right" title="pycbc_make_offline_grb_workflow: A GRB triggered CBC analysis workflow generator" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2015, 2016, 2017, Alexander Nitz, Ian Harry, Christopher M. Biwer, Duncan A.  Brown, Josh Willis, and Tito Dal Canton.
      <span class="lastupdated">Last updated on Oct 20, 2021.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>