#!/usr/bin/python

# Copyright 2016 Thomas Dent, Alex Nitz, Gareth Cabourn Davies
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.


import sys, h5py, argparse, logging, pycbc.version, numpy
from pycbc.events import triggers, fits_combination as fc
from pycbc import init_logging


parser = argparse.ArgumentParser(usage="",
    description="Smooth (regress) the dependence of coefficients describing "
                "single-ifo background trigger distributions on a template "
                "parameter, to suppress random noise in the resulting "
                "background model.")

pycbc.add_common_pycbc_options(parser)
parser.add_argument("--version", action=pycbc.version.Version)
parser.add_argument("--template-fit-file", required=True,
                    help="hdf5 file containing fit coefficients for each"
                         " individual template. Required")
parser.add_argument("--bank-file", required=True,
                    help="hdf file containing template parameters. Required")
parser.add_argument("--output", required=True,
                    help="Location for output file containing smoothed fit "
                         "coefficients. Required")
parser.add_argument("--fit-param", nargs='+',
                    help="Parameter(s) over which to regress the background "
                         "fit coefficients. Required. Either read from "
                         "template fit file or choose from mchirp, mtotal, "
                         "chi_eff, eta, tau_0, tau_3, template_duration, "
                         "a frequency cutoff in pnutils or a frequency function"
                         "in LALSimulation. To regress the background over "
                         "multiple parameters, provide them as a list.")
parser.add_argument("--approximant", default="SEOBNRv4",
                    help="Approximant for template duration. Default SEOBNRv4")
parser.add_argument("--f-lower", type=float,
                    help="Start frequency for calculating template duration.")
parser.add_argument("--min-duration", type=float, default=0.,
                    help="Fudge factor for templates with tiny or negative "
                         "values of template_duration: add to duration values"
                         " before fitting. Units seconds.")
parser.add_argument("--log-param", nargs='+',
                    help="Take the log of the fit param before smoothing. "
                         "Must be a list corresponding to fit params.")
parser.add_argument("--smoothing-width", type=float, nargs='+', required=True,
                    help="Distance in the space of fit param values (or their"
                         " logs) to smooth over. Required. Must be a list "
                         "corresponding to fit params.")
parser.add_argument("--smoothing-method", default="smooth_tophat",
                    choices = fc._smooth_dist_func.keys(),
                    help="Method used to smooth the fit parameters; "
                         "'smooth_tophat' (default) finds all templates within "
                         "unit distance from the template of interest "
                         "(distance normalised by --smoothing-width). "
                         "'n_closest' adds the closest templates to "
                         "the smoothing until 500 triggers are reached. "
                         "'distance_weighted' weights the closest templates "
                         "with a normal distribution of width smoothing-width "
                         "truncated at three smoothing-widths.")
parser.add_argument("--smoothing-keywords", nargs='*',
                    help="Keywords for the smoothing function, supplied "
                         "as key:value pairs, e.g. total_trigs:500 to define "
                         "the number of templates for n_closest smoothing.")
parser.add_argument("--output-fits-by-template", action='store_true',
                    help="If given, will output the input file fits to "
                         "fit_by_template group.")
args = parser.parse_args()

init_logging(args.verbose)

smooth_kwargs = fc.digest_smoothing_kwargs(args, parser)

with h5py.File(args.template_fit_file, 'r') as fits:
    # get template id and template parameter values
    tid = fits['template_id'][:]
    nabove = fits['count_above_thresh'][:]
    ntotal = fits['count_in_template'][:]
    alpha = fits['fit_coeff'][:]
    # get the ifo from the template-level fit
    ifo = fits.attrs['ifo']
    try:
        median_sigma = fits['median_sigma'][:]
    except KeyError:
        logging.info('Median_sigma dataset not present in input file')
    stat_threshold = fits.attrs['stat_threshold']
    if 'analysis_time' in fits.attrs:
        analysis_time = fits.attrs['analysis_time']
    else:
        analysis_time = None
        

logging.info('Calculating template parameter values')
bank = h5py.File(args.bank_file, 'r')
m1, m2, s1z, s2z = triggers.get_mass_spin(bank, tid)

parvals = []
for param in smooth_kwargs['fit_param']:
    data = triggers.get_param(param, args, m1, m2, s1z, s2z)
    parvals.append(smooth_kwargs[f'{param}_func'](data))

# For an exponential fit 1/alpha is linear in the trigger statistic values
# so calculating weighted sums or averages of 1/alpha is appropriate
invalpha = 1. / alpha
invalphan = invalpha * nabove

nabove_smoothed = []
alpha_smoothed = []
ntotal_smoothed = []
rang = numpy.arange(0, len(nabove))

# Handle the one-dimensional case of tophat smoothing separately
# as it is easier to optimize computational performance.
if len(parvals) == 1 and args.smoothing_method == 'smooth_tophat':
    smooth_function = fc.oned_tophat
else:
    smooth_function = fc.smooth_samples

nabove_smoothed, alpha_smoothed, ntotal_smoothed = \
    smooth_function(
        parvals,
        smooth_kwargs,
        nabove,
        invalphan,
        ntotal,
    )

logging.info("Writing output")
with h5py.File(args.output, 'w') as outfile:
    outfile['template_id'] = tid
    outfile['count_above_thresh'] = nabove_smoothed
    outfile['fit_coeff'] = alpha_smoothed
    outfile['count_in_template'] = ntotal_smoothed
    outfile['median_sigma'] = median_sigma

    for param, vals, slog in zip(args.fit_param, parvals, args.log_param):
        if slog in ['false', 'False', 'FALSE']:
            outfile[param] = vals
        elif slog in ['true', 'True', 'TRUE']:
            outfile[param] = numpy.exp(vals)

    if args.output_fits_by_template:
        outfile.create_group('fit_by_template')
        with h5py.File(args.template_fit_file, 'r') as fits:
            for k in ['count_above_thresh', 'fit_coeff', 'count_in_template']:
                outfile['fit_by_template'][k] = fits[k][:]
            

    # Add metadata, some is inherited from template level fit
    outfile.attrs['ifo'] = ifo
    outfile.attrs['stat_threshold'] = stat_threshold
    if analysis_time is not None:
        outfile.attrs['analysis_time'] = analysis_time
        
    # Add a magic file attribute so that coinc_findtrigs can parse it
    outfile.attrs['stat'] = ifo + '-fit_coeffs'

logging.info('Done!')
