#!/usr/bin/env /usr/bin/pytho

# Copyright (C) 2014 Alex Nitz
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

import time

time_init = time.time()

import logging
from collections import defaultdict
import argparse
from pycbc import vetoes, psd, waveform, events, strain, scheme, fft, DYN_RANGE_FAC
from pycbc.filter import MatchedFilterControl
from pycbc.types import TimeSeries, zeros, float32, complex64
from pycbc.types import MultiDetOptionAction
import pycbc.detector
import numpy as np

parser = argparse.ArgumentParser(usage='',
    description="Find multiple detector gravitational-wave triggers.")
parser.add_argument("-V", "--verbose", action="store_true",
                  help="print extra debugging information", default=False )
parser.add_argument("--output", type=str)
parser.add_argument("--instruments", nargs="+", type=str, required=True,
                    help="List of instruments to analyze.")
parser.add_argument("--bank-file", type=str)
parser.add_argument("--snr-threshold",
                  help="SNR threshold for trigger generation", type=float)
parser.add_argument("--newsnr-threshold", type=float, metavar='THRESHOLD',
                    help="Cut triggers with NewSNR less than THRESHOLD")
parser.add_argument("--low-frequency-cutoff", type=float,
                  help="The low frequency cutoff to use for filtering (Hz)")

# add approximant arg
waveform.bank.add_approximant_arg(parser)
parser.add_argument("--order", type=str,
                  help="The integer half-PN order at which to generate"
                       " the approximant.")
taper_choices = ["start","end","startend"]
parser.add_argument("--taper-template", choices=taper_choices,
                  help="For time-domain approximants, taper the start and/or "
                       "end of the waveform before FFTing.")
parser.add_argument("--cluster-method", choices=["template", "window"])
parser.add_argument("--cluster-window", type=float, default = -1,
                  help="Length of clustering window in seconds")

parser.add_argument("--bank-veto-bank-file", type=str)

parser.add_argument("--chisq-bins", default=0)
parser.add_argument("--chisq-threshold", type=float, default=0)
parser.add_argument("--chisq-delta", type=float, default=0)

parser.add_argument("--autochi-number-points", type=int, default=0)
parser.add_argument("--autochi-stride", type=int, default=0)
parser.add_argument("--autochi-onesided", action='store_true', default=False)
parser.add_argument("--downsample-factor", type=int, default=1,
                    help="Factor that determines the interval between the "
                         "initial SNR sampling. If not set (or 1) no sparse "
                         "sample is created, and the standard full SNR is "
                         "calculated.")
parser.add_argument("--upsample-threshold", type=float,
                    help="The fraction of the SNR threshold to check the "
                         "sparse SNR sample.")
parser.add_argument("--upsample-method", choices=["pruned_fft"],
                    default='pruned_fft',
                    help="The method to find the SNR points between the "
                         "sparse SNR sample.")
parser.add_argument("--user-tag", type=str, metavar="TAG", help="""
                    This is used to identify FULL_DATA jobs for 
                    compatibility with pipedown post-processing. 
                    Option will be removed when no longer needed.""")

# Arguments added for the coherent stuff
parser.add_argument("--longitude", type=float)
parser.add_argument("--latitude", type=float)
parser.add_argument("--coinc-threshold", type=float, default=0.0, help="""
                    Triggers with coincident/coherent snr below this value with be discarded""")
parser.add_argument("--null-min", type=float, default=5.25, help="""
                    Triggers with null_snr above this value with be discarded""")
parser.add_argument("--null-grad", type=float, default=0.2, help="""
                    The gradient of the line defining the null cut after the null step""")
parser.add_argument("--null-step", type=float, default=20., help="""Triggers with coherent snr 
                    above null_step will be cut according to the null_grad and null_min""")

# Add options groups
strain.insert_strain_option_group_multi_ifo(parser)
strain.StrainSegments.insert_segment_option_group_multi_ifo(parser)
psd.insert_psd_option_group_multi_ifo(parser)
scheme.insert_processing_option_group(parser)
fft.insert_fft_option_group(parser)

#Adding these to see if it lets me use the gating options
from pycbc.vetoes.sgchisq import SingleDetSGChisq
pycbc.opt.insert_optimization_option_group(parser)
pycbc.weave.insert_weave_option_group(parser)
pycbc.inject.insert_injfilterrejector_option_group(parser)
SingleDetSGChisq.insert_option_group(parser)
opt = parser.parse_args()
########################

"""
These need to be added as arguments 
"""
"""
longitude = 6.103652
latitude = 0.9999715
t_gps = 1169088610.0
pol = 1.21771
"""


coinc_threshold = opt.coinc_threshold
generate_histograms = False
generate_snr_plots = False
generate_chi2_plots = False
pol = 1.21771
t_gps = opt.trig_start_time[0] + 100

"""
#bns options
longitude = 3.446131227771
latitude = -0.40812483499946
t_gps = 1187008884
"""

"""
#glitch options
longitude = 3.446131227771
latitude = -0.40812483499946
t_gps = 1185938872
"""
ra = opt.longitude 
dec = opt.latitude

opt = parser.parse_args()

strain.verify_strain_options_multi_ifo(opt, parser, opt.instruments)
strain.StrainSegments.verify_segment_options_multi_ifo(opt, parser,
                                                       opt.instruments)
psd.verify_psd_options_multi_ifo(opt, parser, opt.instruments)
scheme.verify_processing_options(opt, parser)
fft.verify_fft_options(opt,parser)

if opt.verbose:
    log_level = logging.DEBUG
else:
    log_level = logging.WARN
logging.basicConfig(format='%(asctime)s : %(message)s', level=log_level)

ctx = scheme.from_cli(opt)


def get_weighted_antenna_patterns(Fp_dict,Fc_dict,sigma_dict):
    """
    Output: wp: 1 x nifo of the weighted antenna response fuctions to plus polarisation\
                 for each ifo
            wc: 1 x nifo of the weighted antenna response fuctions to cross polarisation\
                 for each ifo
    Input:  Fp_dict: Dictionary of the antenna response fuctions to plus polarisation\
                     for each ifo
            Fc_dict: Dictionary of the antenna response fuctions to cross polarisation\
                     for each ifo
           sigma_dict: Sigma dictionary for each ifo (sensitivity of each ifo)
    """
    wp = np.zeros(len(opt.instruments))
    wc = np.zeros(len(opt.instruments))
    for i,ifo in enumerate(opt.instruments):
        wp[i] = sigma_dict[ifo]*Fp_dict[ifo]
        wc[i] = sigma_dict[ifo]*Fc_dict[ifo]
    return wp,wc

def get_projection_matrix(wp,wc):
    """
    Output: projection_matrix: Projects the data onto the signal space
    Input:  wp,wc: The weighted antenna response fuctions to plus and cross\
                   polarisations respectively
    """
    denominator = np.dot(wp,wp) * np.dot(wc,wc) - np.dot(wp,wc)**2
    projection_matrix = (np.dot(wc,wc)*np.outer(wp,wp)+ np.dot(wp,wp)*np.outer(wc,wc)\
                    - np.dot(wp,wc)*(np.outer(wp,wc) + np.outer(wc,wp))) / denominator
    return projection_matrix


def coherent_snr(snr_triggers,index,threshold,projection_matrix,coinc_snr=[]):
    """
    Output: roh_coh: an array of the coherent snr for the detector network
            index  : Indexes that survive cuts
            snrv   : Dictionary of individual ifo triggers that survive cuts
            coinc_snr: The coincident snr value for triggers surviving the coherent cut
    Inputs: snr_triggers: is a dictionary of the normalised complex snr time series for 
                      each ifo. The keys are the ifos (e.g. 'L1','H1', and 'V1')
            index  : An array of the indexes you want to analyse. Not used for 
                     calculations, just for book keeping
            threshold: Triggers with roh_coh<threshold are cut
            projection_matrix 
            coinc_snr: Optional- The coincident snr for each trigger. 
    """
    #Calculate roh_roh
    snr_array = np.array([snr_triggers[ifo] for ifo in opt.instruments])
    x = np.inner(snr_array.conj().transpose(),projection_matrix)
    roh_coh2 = sum(x.transpose()*snr_array)
    roh_coh = np.sqrt(roh_coh2)
    #Apply thresholds
    index = index[roh_coh>threshold]
    if len(coinc_snr)!=0:
        coinc_snr = coinc_snr[roh_coh>threshold]
    snrv = {}
    for ifo in opt.instruments:
        snrv[ifo] = snr_triggers[ifo][roh_coh>threshold]
    roh_coh = roh_coh[roh_coh>threshold]
    return roh_coh,index,snrv,coinc_snr

def coincident_snr(snr_dict,index,threshold):
    """
    Output: roh_coinc: Coincident snr triggers
            index    : The subset of input index that survive the cuts
            coinc_triggers: Dictionary of individual detector SNRs at
                            indexes that survive cuts
    Input: snr_dict: Dictionary of individual detector SNRs in geocent time
           index   : Geocent indexes you want to find coinc SNR for
           threshold: Indexes with coinc SNR below this threshold are cut
    """
    #Restrict the snr timeseries to just the interesting points
    coinc_triggers = {}
    for ifo in snr_dict.keys():
        coinc_triggers[ifo] = snr[ifo][index]
    #Calculate the coincident snr
    snr_array = np.array([coinc_triggers[ifo] for ifo in coinc_triggers.keys()])
    roh_coinc = np.sqrt(np.sum(snr_array*snr_array.conj(),axis=0))
    #Apply threshold
    index = index[roh_coinc>coinc_threshold]
    for ifo in snr_dict.keys():
        coinc_triggers[ifo] = snr[ifo][index]
    roh_coinc = roh_coinc[roh_coinc>threshold]
    return roh_coinc, index, coinc_triggers

def null_snr(roh_coh,roh_coinc,null_min=5.25,null_grad=0.2,null_step=20.,index=[],snrv=[]):
    """
    Output: null: null snr for surviving triggers
            roh_coh: Coherent snr for surviving triggers
            roh_coinc: Coincident snr for suviving triggers
            index: Indexes for surviving triggers
            snrv: Single detector snr for surviving triggers
    Input:  roh_coh: Numpy array of coherent snr triggers
            roh_coinc: Numpy array of coincident snr triggers
            null_min: Any trigger with null snr below this is cut
            null_grad: Any trigger with null snr<(null_grad*roh_coh+null_min) is cut
            null_step: The value for required for coherent snr to start increasing the null threshold
            index: Optional- Indexes of triggers. If given, will remove triggers that fail cuts
            snrv: Optional- Individual ifo snr for triggers. If given will remove triggers that fail cut
    """
    null2 = roh_coinc**2 - roh_coh**2
    #Numerical errors may make this negative and break the sqrt, so set negaitive values to 0
    null2[null2<0] = 0 
    null = null2**0.5
    # Make cut on null
    keep1 = np.logical_and(null<null_min,roh_coh<=null_step)
    keep2 = np.logical_and(null<(roh_coh*null_grad + null_min), roh_coh>null_step)
    keep = np.logical_or(keep1,keep2)
    index = index[keep]
    roh_coh  = roh_coh[keep] 
    for ifo in opt.instruments:
        snrv[ifo] = snrv[ifo][keep]
    roh_coinc = roh_coinc[keep] 
    null = null[keep]
    return null, roh_coh, roh_coinc, index, snrv

def get_coinc_indexes(idx_dict,time_delay_idx):
    """
    Output: coinc_idx: list of indexes for triggers in geocent time that\
                       appear in multiple detectors 
    Input: idx_dict: Dictionary of indexes of triggers above threshold in each detector
           time_delay_idx: Dictionary giving time delay index (time_delay*sample_rate) for each ifo 
    """
    coinc_list = np.array([],dtype=int)
    for ifo in opt.instruments:
        #Create list of indexes above threshold in single detector in 
        #geocent time. Can then search for triggers that appear in multiple 
        #detectors later.
        if len(idx_dict[ifo]) != 0:
             coinc_list = np.hstack([coinc_list,idx_dict[ifo] - time_delay_idx[ifo]])
    #Search through coinc_idx for repeated indexes. These must have
    #been loud in at least 2 detectors.
    coinc_idx = np.unique(coinc_list,return_counts=True)[0]\
                   [np.unique(coinc_list,return_counts=True)[1]>1]
    return coinc_idx


strain_dict = strain.from_cli_multi_ifos(opt, opt.instruments, 
                                         dyn_range_fac=DYN_RANGE_FAC)
strain_segments_dict = strain.StrainSegments.from_cli_multi_ifos(opt, 
  				         strain_dict, opt.instruments)
with ctx:
    fft.from_cli(opt)

    # Set some often used variables for easy access
    flow = opt.low_frequency_cutoff
    flow_dict = defaultdict(lambda : flow)
    for count, ifo in enumerate(opt.instruments):
	if count == 0:
	    sample_rate = strain_dict[ifo].sample_rate
	    sample_rate_dict = defaultdict(lambda : sample_rate)
	    flen = strain_segments_dict[ifo].freq_len
	    flen_dict = defaultdict(lambda : flen)
	    tlen = strain_segments_dict[ifo].time_len
	    tlen_dict = defaultdict(lambda : tlen)
	    delta_f = strain_segments_dict[ifo].delta_f
	    delta_f_dict = defaultdict(lambda : delta_f)            
	else:
	    try:
		assert(sample_rate == strain_dict[ifo].sample_rate)
		assert(flen == strain_segments_dict[ifo].freq_len)
		assert(tlen == strain_segments_dict[ifo].time_len)
		assert(delta_f == strain_segments_dict[ifo].delta_f)
	    except:
		err_msg = "Sample rate, frequency length and time length "
		err_msg += "must all be consistent across ifos."
		raise ValueError(err_msg)

    logging.info("Making frequency-domain data segments")
    segments = {}
    for ifo in opt.instruments:
	segments[ifo] = strain_segments_dict[ifo].fourier_segments()
	del strain_segments_dict[ifo]
    """
    logging.info("Computing noise PSD")
    psds = psd.from_cli_multi_ifos(opt, flen_dict, delta_f_dict, flow_dict,
				  opt.instruments, strain_dict=strain_dict, 
				  dyn_range_factor=DYN_RANGE_FAC)
    for ifo in opt.instruments:
	psds[ifo] = psds[ifo].astype(float32)
    """
    psd.associate_psds_to_multi_ifo_segments(opt, segments, strain_dict, flen,
	    delta_f, flow, opt.instruments, dyn_range_factor=DYN_RANGE_FAC,
	    precision='single')
    
    # Currently we are using the same matched-filter parameters for all ifos.
    # Therefore only one MatchedFilterControl needed. Maybe this can change if
    # needed. Segments is only used to get tlen etc. which is same for all
    # ifos, so just send the first ifo
    template_mem = zeros(tlen, dtype=complex64)
    if opt.cluster_window == 0:
	use_cluster = False
    else:
	use_cluster = True
    
    #Calculate time delay to each detector
    time_delay_idx = {}
    for ifo in opt.instruments:
	time_delay_idx[ifo] =  int(round(pycbc.detector.Detector(ifo).\
             time_delay_from_earth_center(ra,dec,t_gps) * sample_rate))
    
    #Matched filter each ifo
    matched_filter = {}
    for ifo in opt.instruments:
	matched_filter[ifo] = MatchedFilterControl(opt.low_frequency_cutoff, None,
				   opt.snr_threshold, tlen, delta_f, complex64,
				   segments[ifo], template_mem,
				   use_cluster,
				   downsample_factor=opt.downsample_factor,
				   upsample_threshold=opt.upsample_threshold,
				   upsample_method=opt.upsample_method,
				   cluster_function='symmetric')

    logging.info("Initializing signal-based vetoes.")
    # The existing SingleDetPowerChisq can calculate the single detector
    # chisq for multiple ifos, so just use that directly.
    power_chisq = vetoes.SingleDetPowerChisq(opt.chisq_bins)
    # The existing SingleDetBankVeto can calculate the single detector
    # bank veto for multiple ifos, so we just use it directly.
    bank_chisq = vetoes.SingleDetBankVeto(opt.bank_veto_bank_file, flen,
					  delta_f, flow, complex64,
					  phase_order=opt.order,
					  approximant=opt.approximant)
    # Same here
    autochisq = vetoes.SingleDetAutoChisq(opt.autochi_stride,
					 opt.autochi_number_points,
					 onesided=opt.autochi_onesided)

    logging.info("Overwhitening frequency-domain data segments")
    for ifo in opt.instruments:
	for seg in segments[ifo]:
            #seg /= psds[ifo]
            seg /= seg.psd
    ifo_out_types = {
	'time_index'     : int,
	'ifo'            : int, # IFO is stored as an int internally!
        'snr'            : complex64,
	'chisq'          : float32,
	'chisq_dof'      : int,
	'bank_chisq'     : float32,
	'bank_chisq_dof' : int,
	'cont_chisq'     : float32,
		}
    ifo_out_vals = {
	'time_index'     : None,
	'ifo'            : None,
        'snr'            : None,
	'chisq'          : None,
	'chisq_dof'      : None,
	'bank_chisq'     : None,
	'bank_chisq_dof' : None,
	'cont_chisq'     : None,
	       }
    ifo_names = sorted(ifo_out_vals.keys())

    network_out_types = {
        'latitude'      : float32,
        'longitude'     : float32,
	'time_index'    : int,
	'network_snr'   : float32,
        'null_snr'      : float32,
        'nifo'          : int
               }
    network_out_vals = {
        'latitude'      : None,
        'longitude'     : None,
	'time_index'    : None,
	'network_snr'   : None,
        'null_snr'      : None,
        'nifo'          : None
               }
    network_names = sorted(network_out_vals.keys())

    event_mgr = events.EventManagerCoherent(opt, opt.instruments, ifo_names,
					[ifo_out_types[n] for n in ifo_names], network_names, [network_out_types[n] for n in network_names])

    logging.info("Read in template bank")
    bank = waveform.FilterBank(opt.bank_file, flen, delta_f, complex64,
			       low_frequency_cutoff=flow, phase_order=opt.order,
			       taper=opt.taper_template,
			       approximant=opt.approximant, out=template_mem)
    roh_coh_dict = {}
    roh_coinc_dict={}
    null_dict = {}
    triggers = {}
    coinc_idx = {}
    Fp = {} #Antenna patterns
    Fc = {}
    for ifo in opt.instruments:
        Fp[ifo], Fc[ifo] = pycbc.detector.Detector(ifo).antenna_pattern(\
                                                     ra, dec, pol, t_gps)
    #Keep list of templates and segments with triggers in
    coh_snr_list = []
    for t_num, template in enumerate(bank):
    #for t_num, template in enumerate(bank,start=201954):
        """
	if t_num == 201955: #use small sample set for development
            t_num-=1
            break
        """
	roh_coh_dict[t_num] = {}
	roh_coinc_dict[t_num] = {}
        null_dict[t_num] = {}
        coinc_idx[t_num] = {}

	for ifo in opt.instruments:
	    if opt.cluster_method == "window":
		cluster_window = int(opt.cluster_window * sample_rate)
	    elif opt.cluster_method == "template":
		cluster_window = int(template.chirp_length * sample_rate)
	    elif opt.cluster_window == 0:
		 cluster_window = int(0)

	for s_num,stilde in enumerate(segments[opt.instruments[0]]): #Loop over segments
            """
	    if s_num==1:
		break
            """
            #Find detector sensitivities (sigma) and make array of normalised 
	    sigmasq = {}
	    sigma = {}
            snrv_dict = {}
            norm_dict = {}
            corr_dict = {}
	    for ifo in opt.instruments:
	        sigmasq[ifo] = template.sigmasq(segments[ifo][s_num].psd)
	        sigma[ifo] = np.sqrt(sigmasq[ifo])
	    event_mgr.new_template(tmplt=template.params, sigmasq=sigmasq)
	    snr={} 
	    idx_dict={}
            coinc_idx[t_num][s_num] = np.array([])
            stilde = {}
            ifo_list = opt.instruments
	    for ifo in opt.instruments:
		stilde[ifo] = segments[ifo][s_num]
		logging.info("Filtering template %d/%d ifo %s segment %d/%d" % \
			     (t_num + 1, len(bank), ifo, s_num + 1,
			      len(segments[ifo])))       
                #The correlation vector is the FFT of the snr (so inverse FFT it to get the snr)
		snr_ts, norm, corr, idx, snrv_dict[ifo] = \
			matched_filter[ifo].matched_filter_and_cluster(s_num,
			    template.sigmasq(stilde[ifo].psd), window=cluster_window)

                #List of ifos with triggers
                if len(idx) == 0:
                    ifo_list.remove(ifo)
                #Save norm values to dict
                norm_dict[ifo] = norm
                corr_dict[ifo] = corr

                #Find the data we need to analyse
		analyse_data = matched_filter[ifo].segments[s_num].analyze

                #Restrict the snr timeseries to just this section
		snr[ifo] = snr_ts[analyse_data] * norm_dict[ifo]
               
                #Save the indexes of triggers (if we have any)
                #Even if we have none, need to keep an empty dictionary.
                #Only do this is idx doesn't get time shifted out of the time
                #we are looking at.
                if len(idx)!=0:
                    idx_dict[ifo] = idx[np.logical_and(idx > time_delay_idx[ifo],\
                                   idx - time_delay_idx[ifo] < len(snr[ifo]))]

            #Find triggers that are coincident (in geocent time) in multiple ifos.
            #If only one detector has a trigger, just use the indexes from that ifo.
            if len(ifo_list)>1:
                coinc_idx[t_num][s_num] = get_coinc_indexes(idx_dict,time_delay_idx)
            else:
                coinc_idx[t_num][s_num] = idx_dict[ifo_list[0]] - time_delay_idx[ifo_list[0]]
            print "Number of coincident indexes: " + str(len(coinc_idx[t_num][s_num]))

            nifo = len(ifo_list)
            
            for ifo in opt.instruments:
                # Move to next segment if this segment has no data 
                if snr[ifo] == []:
                    continue
                #Apply time delay
		snr[ifo].roll(-time_delay_idx[ifo])
       

	    #Calculate coherent snr roh_coh
	    #Check we have data before we try to compute the coherent snr
            if len(coinc_idx[t_num][s_num]) != 0 and nifo > 1:
                #Find coinc snr at trigger times and apply coinc snr threshold 
                roh_coinc_dict[t_num][s_num], coinc_idx[t_num][s_num], coinc_triggers =\
                                           coincident_snr(snr,coinc_idx[t_num][s_num],coinc_threshold)
                print "Points above threshold: " + str(len(coinc_idx[t_num][s_num]))
                if len(coinc_idx[t_num][s_num]) != 0:
                    print "max coincident snr" + str(max(roh_coinc_dict[t_num][s_num]))
            #If there is only one ifo, then coinc_triggers is just the triggers from ifo
            elif len(coinc_idx[t_num][s_num]) != 0 and nifo==1:
                coinc_triggers = {}
                coinc_triggers[ifo_list[0]] = snr[ifo_list[0]][coinc_idx[t_num][s_num]]
            else:
                coinc_triggers = {}
                print("No triggers above threshold")
            #If we have triggers above coinc threshold and more than 2 ifos 
            # then calculate the coherent statistics 
            if len(coinc_idx[t_num][s_num]) != 0 and nifo > 2:
                wp,wc=get_weighted_antenna_patterns(Fp,Fc,sigma)
                projection_matrix = get_projection_matrix(wp,wc)
                roh_coh_dict[t_num][s_num],coinc_idx[t_num][s_num],coinc_triggers,\
                        roh_coinc_dict[t_num][s_num] = coherent_snr(coinc_triggers,\
                          coinc_idx[t_num][s_num],coinc_threshold,projection_matrix,\
                                                      roh_coinc_dict[t_num][s_num])
                print("Number of points above coherent threshold: " + str(len(roh_coh_dict[t_num][s_num])))
                if len(coinc_idx[t_num][s_num]) != 0:
                    print "max coherent snr" + str(max(roh_coh_dict[t_num][s_num]))
                
                    coh_snr_list.append(max(roh_coh_dict[t_num][s_num]))
 
                    #Find the null snr
                    null_dict[t_num][s_num],roh_coh_dict[t_num][s_num],\
                        roh_coinc_dict[t_num][s_num], coinc_idx[t_num][s_num],\
                         coinc_triggers = null_snr(roh_coh_dict[t_num][s_num],\
                         roh_coinc_dict[t_num][s_num],snrv=coinc_triggers,\
                                                            index=coinc_idx[t_num][s_num])
                    if len(coinc_idx[t_num][s_num]) != 0:
                        print "max null snr" + str(max(null_dict[t_num][s_num]))
            print("Number of points above null threshold: " + str(len(null_dict[t_num][s_num])))
            #We are now going to find the individual detector chi2 values. To do this it
            #is useful to find the indexes of coinc triggers in the detector frame.
            #We do this by overwriting the dictionary of all single detector triggers
            #with just those of coinc triggers
            if len(coinc_idx[t_num][s_num]) != 0:
                for ifo in opt.instruments:
                    idx_dict[ifo] = coinc_idx[t_num][s_num] + time_delay_idx[ifo]
                #calculate the power and auto chi2 values for the coinc indexes (this uses the snr time series before the time delay, so we need to undo it. Same for normalisation)
                power_chisq_ts = {}
                power_chisq_dof = {}
                auto_chisq = {} 
                bank_chisq_ts = {}
                bank_chisq_dof = {}
                for ifo in opt.instruments:
		    bank_chisq_ts[ifo], bank_chisq_dof[ifo] = \
			bank_chisq.values(template, stilde[ifo].psd, stilde[ifo], snrv_dict[ifo],norm_dict[ifo], idx_dict[ifo]+stilde[ifo].analyze.start)
                    power_chisq_ts[ifo],power_chisq_dof[ifo] = power_chisq.values(corr_dict[ifo], coinc_triggers[ifo]/norm_dict[ifo], norm_dict[ifo], stilde[ifo].psd,idx_dict[ifo]+stilde[ifo].analyze.start, template)
                    auto_chisq[ifo] = autochisq.values(snr[ifo],idx_dict[ifo]+stilde[ifo].analyze.start, template, stilde[ifo].psd, norm_dict[ifo],stilde=stilde[ifo], low_frequency_cutoff=flow)
                
		    ifo_out_vals['bank_chisq'], ifo_out_vals['bank_chisq_dof'] = \
			bank_chisq.values(template, stilde[ifo].psd, stilde[ifo], snrv_dict[ifo],
					  norm_dict[ifo], idx_dict[ifo]+stilde[ifo].analyze.start)


		    ifo_out_vals['cont_chisq'] = autochisq.values(snr[ifo],
			idx_dict[ifo]+stilde[ifo].analyze.start, template, stilde[ifo].psd, norm_dict[ifo],
			stilde=stilde[ifo], low_frequency_cutoff=flow)
		    ifo_out_vals['chisq'], ifo_out_vals['chisq_dof'] =\
			power_chisq.values(corr_dict[ifo], coinc_triggers[ifo]/norm_dict[ifo], norm_dict[ifo], stilde[ifo].psd,idx_dict[ifo]+stilde[ifo].analyze.start, template)
		    ifo_out_vals['time_index'] = idx_dict[ifo]+stilde[ifo].cumulative_index
                    ifo_out_vals['snr'] = snr[ifo][coinc_idx[t_num][s_num]]
		    snrv_dict[ifo]=snrv_dict[ifo]*norm_dict[ifo]
		    # IFO is stored as an int
		    ifo_out_vals['ifo'] = event_mgr.ifo_dict[ifo]
		    event_mgr.add_template_events_to_ifo(ifo, ifo_names,
			[ifo_out_vals[n] for n in ifo_names])
                if nifo>2:
                    network_out_vals['network_snr'] = np.real(roh_coh_dict[t_num][s_num])
                    network_out_vals['null_snr'] = np.real(null_dict[t_num][s_num])
                elif nifo==2:
                    network_out_vals['network_snr'] = np.real(roh_coinc_dict[t_num][s_num])
                else:
                    network_out_vals['network_snr'] = abs(snr[ifo_list[0]][coinc_idx[t_num][s_num]])
                network_out_vals['time_index'] = idx_dict[ifo]+stilde[ifo].cumulative_index
                network_out_vals['nifo'] = [nifo]
                network_out_vals['latitude'] = [opt.latitude]
                network_out_vals['longitude'] = [opt.longitude]
                event_mgr.add_template_events_to_network( network_names,
		        	[network_out_vals[n] for n in network_names])

	        #event_mgr.cluster_template_events_single_ifo("time_index",
                #					    "snr", cluster_window, ifo)
event_mgr.finalize_template_events()
event_mgr.write_events(opt.output)


print "Time to complete analysis: " + str(time.time() - time_init)

"""
#FIXME This stuff doesn't work for more than 2 detectors.
logging.info("Found %s triggers" % str(len(event_mgr.events)))
if opt.chisq_threshold and opt.chisq_bins:
    logging.info("Removing triggers with poor chisq")
    event_mgr.chisq_threshold(opt.chisq_threshold, opt.chisq_bins,opt.chisq_delta)
    logging.info("%d remaining triggers" % len(event_mgr.events))

if opt.newsnr_threshold and opt.chisq_bins:
    logging.info("Removing triggers with NewSNR below threshold")
    event_mgr.newsnr_threshold(opt.newsnr_threshold)
    logging.info("%d remaining triggers" % len(event_mgr.events))
logging.info("Writing out triggers")
event_mgr.write_events(opt.output)

if opt.fftw_output_float_wisdom_file:
    fft.fftw.export_single_wisdom_to_filename(opt.fftw_output_float_wisdom_file)

if opt.fftw_output_double_wisdom_file:
    fft.fftw.export_double_wisdom_to_filename(opt.fftw_output_double_wisdom_file)
"""
np.save('roh_coh.npy',roh_coh_dict)
np.save('roh_coinc.npy',roh_coinc_dict)

logging.info("Finished")


if generate_snr_plots == True or generate_histograms == True:
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt

if generate_snr_plots == True:
    print "Generating network SNR plots..."
    plot_tnum = 0
    plot_snum = 0
    plt.figure()
    try:
        plt.plot(coinc_idx[plot_tnum][plot_snum],roh_coinc_dict[plot_tnum][plot_snum]\
        [roh_coinc_dict[plot_tnum][plot_snum]>coinc_threshold],'b.',label='coinc snr')
    except KeyError:
        print "Cannot plot this template/segment"
    try:
        plt.plot(coinc_idx[plot_tnum][plot_snum],roh_coh_dict[plot_tnum][plot_snum],'rx',label='coh snr')
        plt.plot(coinc_idx[plot_tnum][plot_snum],null_dict[plot_tnum][plot_snum],'mx',label='null snr')
    except KeyError:
        print "Key Error when calculating coherent statistics.\n \
                  This is normal if using less than 3 detector"
    plt.legend(loc="best")
    plt.xlabel("Trigger idx")
    plt.savefig("/home/c1551011/public_html/coh_snr_vs_coinc_snr.png")

    print "Generating network SNR plots..."
    plt.figure()
    coinc_snr,_,_ = coincident_snr(snr,np.arange(len(snr[ifo])),0)
    plt.plot(np.array(range(len(coinc_snr)))/float(sample_rate),coinc_snr,'b.',label='coinc snr')
    try:
        roh_coh,_,_,_ = coherent_snr(snr,np.arange(len(snr[ifo])),0,projection_matrix)
        plt.plot(np.array(range(len(coinc_snr)))/float(sample_rate),roh_coh,'rx',label='coh snr')
        plt.plot(np.array(range(len(coinc_snr)))/float(sample_rate),(coinc_snr**2-roh_coh**2)**0.5,'mx',label='null snr')
    except NameError:
        print "Name Error when calculating coherent statistics.\n \
                  This is normal if using less than 3 detector"
    plt.legend(loc="best")
    plt.xlabel("Time (seconds)")
    plt.savefig("/home/c1551011/public_html/coh_snr_vs_coinc_snr_whole_segment.png")
    print "Done"

    plt.figure()
    for ifo in opt.instruments:
        plt.plot((snr[ifo]*snr[ifo].conj())**0.5,'x',label=ifo)
        plt.plot(np.argmax((snr[ifo]*snr[ifo].conj())**0.5),max((snr[ifo]*snr[ifo].conj())**0.5),'*',label=ifo)
    plt.legend()
    plt.savefig("/home/c1551011/public_html/ifo_snr.png")
   
    plt.figure()
    snr2={} 
    for ifo in opt.instruments:
        snr2[ifo] = snr[ifo]*snr[ifo].conj()
        plt.plot((snr2[ifo][np.argmax(coinc_snr)-200:np.argmax(coinc_snr)+200].data)**0.5,'x',label=ifo)
    plt.savefig("/home/c1551011/public_html/ifo_snr_max.png")




if generate_histograms == True:
    print "Generating Historgrams..."
    from scipy.stats import chi2
    plt.figure()
    x = np.linspace(0, 20, 100)
    df = 4
    y = chi2.pdf(x, df)
    plt.plot(x,y,'r')
    roh_coh_for_hist = coherent_snr(snr,np.arange(len(snr[ifo])),0,projection_matrix)
    plt.hist(roh_coh_for_hist.real**2,bins=100,normed=True)
    plt.title("roh_coh2")
    plt.savefig("/home/c1551011/public_html/coh_snr2_histogram.png")
    plt.xlim(0,10)
    for ifo in opt.instruments:
        plt.figure()
        x = np.linspace(0, 20, 100)
        df = 2
        y = chi2.pdf(x, df)
        plt.plot(x,y,'r')
        data = (snr[ifo].conj()*snr[ifo]).data
        plt.hist(data.real,bins=100,normed=True)
        plt.xlim(0,10)
        plt.title(ifo + " snr2")
        plt.savefig("/home/c1551011/public_html/" + ifo + "_snr2_histogram.png")
    print "Done"



"""
#Original chi2 test for comparison 
idx_gc = idx - time_delay_idx[ifo]
snrv = []
for i in range(len(idx_gc)):
    if idx_gc[i] in coinc_idx[0][0]:
        snrv.append(snrv_dict[ifo][i])
snrv = np.array(snrv)
ifo_out_vals['chisq'], ifo_out_vals['chisq_dof'] =\
power_chisq.values(corr_dict[ifo], snrv, norm_dict[ifo], stilde[ifo].psd, coinc_idx[0][0]+time_delay_idx[ifo]+stilde[ifo].analyze.start, template)
"""
if generate_chi2_plots == True:
    #Plot the chi2                
    for ifo in opt.instruments:
        plt.figure()
        plt.plot(coinc_idx[0][0],power_chisq_ts[ifo]/power_chisq_dof[ifo])
        plt.xlabel("Trigger idx")
        plt.ylabel("chi2 per DOF")
        plt.savefig("/home/c1551011/public_html/"+ifo+"chi2.png")

"""
plt.figure()
plt.plot(ifo_out_vals['chisq'])
plt.savefig("/home/c1551011/public_html/old_chi2.png")

plt.figure()
plt.plot(snr[ifo][coinc_idx[t_num][s_num]]/norm_dict[ifo])
plt.plot(snrv)
plt.savefig("/home/c1551011/public_html/snrv_vs_snr.png")
"""
