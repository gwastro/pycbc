#!/usr/bin/env /usr/bin/python

# Copyright (C) 2014 Alex Nitz
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

import logging, sys, numpy, argparse
from pycbc import vetoes, psd, waveform, events, strain, scheme, fft, DYN_RANGE_FAC
from pycbc.filter import  matched_filter_core, sigmasq, make_frequency_series
from pycbc.types import TimeSeries, FrequencySeries, zeros, float32, complex64

parser = argparse.ArgumentParser(
    description = "Find single detector gravitational-wave triggers." )

parser.add_argument("-V", "--verbose", action="store_true", 
                  help="print extra debugging information", default=False )
parser.add_argument("--output", type=str)

parser.add_argument("--bank-file", type=str)
parser.add_argument("--snr-threshold", 
                  help="The the minimum snr threshold", type=float)
parser.add_argument("--low-frequency-cutoff", type=float,
                  help="The low frequency cutoff to use for filtering (Hz)")
                  
parser.add_argument("--approximant", type=str,
                  help="The name of the approximant use for filtering")
parser.add_argument("--order", type=str,
                  help="The integer half-PN order at which to generate the approximant.")

parser.add_argument("--cluster-method", choices=["template", "window"])
parser.add_argument("--cluster-window", type=int, default = -1,
                  help="Length of clustering window in seconds")
parser.add_argument("--maximization-interval", type=int, default=0,
                  help="Maximize triggers over the template bank (ms)")

parser.add_argument("--bank-veto-bank-file", type=str)

parser.add_argument("--chisq-bins", type=int, default=0)
parser.add_argument("--chisq-threshold", type=float, default=0)
parser.add_argument("--chisq-delta", type=float, default=0)

parser.add_argument("--user-tag", type=str, metavar="TAG",
                  help="""This is used to tell pipedown if this is a FULL_DATA
                          job. It will be removed at some point, but for now is
                          needed for pycbc/pipedown compatibility""")

# Add options groups
psd.insert_psd_option_group(parser)
strain.insert_strain_option_group(parser)
strain.StrainSegments.insert_segment_option_group(parser)
scheme.insert_processing_option_group(parser)
fft.insert_fft_option_group(parser)

opt = parser.parse_args()

# Check that the values returned for the options make sense
psd.verify_psd_options(opt, parser)
strain.verify_strain_options(opt, parser)
strain.StrainSegments.verify_segment_options(opt, parser)
scheme.verify_processing_options(opt, parser)
fft.verify_fft_options(opt,parser)

if opt.verbose:
    log_level = logging.DEBUG
else:
    log_level = logging.WARN
logging.basicConfig(format='%(asctime)s : %(message)s', level=log_level)

ctx = scheme.from_cli(opt)
gwstrain = strain.from_cli(opt)
strain_segments = strain.StrainSegments.from_cli(opt, gwstrain)

with ctx:
    fft.from_cli(opt)

    if opt.fftw_input_float_wisdom_file is not None:
        fft.fftw.import_single_wisdom_from_filename(opt.fftw_input_float_wisdom_file)

    if opt.fftw_input_double_wisdom_file is not None:
        fft.fftw.import_double_wisdom_from_filename(opt.fftw_input_double_wisdom_file)
                          
    flow = opt.low_frequency_cutoff                                                               
    flen = strain_segments.freq_len
    tlen = strain_segments.time_len
    delta_f = strain_segments.delta_f

    logging.info("Making frequency-domain data segments")
    segments = strain_segments.fourier_segments()

    logging.info("Computing noise PSD")
    psd = psd.from_cli(opt, flen, delta_f, flow, gwstrain, DYN_RANGE_FAC)
    psd = psd.astype(float32)                              
    bank_chisq = vetoes.SingleDetBankVeto(opt.bank_veto_bank_file, 
                                          opt.approximant, psd, segments, flow, 
                                          phase_order=opt.order)                                       
    power_chisq = vetoes.SingleDetPowerChisq(opt.chisq_bins)
  
    logging.info("Overwhitening frequency-domain data segments")
    for seg in segments:
        seg /= psd

    names =  ['time_index', 'snr', 'chisq', 'bank_chisq']
    event_mgr = events.EventManager(opt, names,
                         [int, complex64, float32, float32, float32], psd=psd)

    logging.info("Read in template bank")
    bank = waveform.FilterBank(opt.bank_file, opt.approximant, flen, delta_f, 
                    flow, dtype=complex64, psd=psd, phase_order=opt.order, 
                    out=zeros(tlen, dtype=complex64))  

    snr_mem = zeros(tlen, dtype=complex64)
    corr_mem = zeros(tlen, dtype=complex64)
    
    for t_num, template in enumerate(bank):  
        event_mgr.new_template(tmplt=template.params, sigmasq=template.sigmasq)   
                                                                                                 
        for s_num, stilde in enumerate(segments):                 
            logging.info("Filtering template %d/%d segment %d/%d" % \
                         (t_num + 1, len(bank), s_num + 1, len(segments)))       
            snr, corr, norm = matched_filter_core(template, stilde, 
                                                  h_norm=template.sigmasq, 
                                                  low_frequency_cutoff=flow, 
                                                  out=snr_mem, 
                                                  corr_out=corr_mem)                                         
            idx, snrv = events.threshold(snr[stilde.analyze], 
                                         opt.snr_threshold / norm)            
            if len(idx) == 0:
                continue                 
                
            logging.info("%s points above threshold" % str(len(idx)))
            bank_chisqv = bank_chisq.values(template, s_num, snr, norm, 
                                            idx+stilde.analyze.start)
            power_chisqv = power_chisq.values(corr, snr, norm, psd, 
                                            idx+stilde.analyze.start, 
                                            template, bank, flow)         
            snrv *= norm
            idx += stilde.cumulative_index           
            vals = [idx, snrv, power_chisqv, bank_chisqv]
            event_mgr.add_template_events(names, vals)

        if opt.cluster_method == "window":
            cluster_window = opt.cluster_window * gwstrain.sample_rate
        elif opt.cluster_method == "template":
            cluster_window = template.length_in_time * gwstrain.sample_rate
            
        event_mgr.cluster_template_events("time_index", "snr", cluster_window) 
        event_mgr.finalize_template_events()   
        
logging.info("Found %s triggers" % str(len(event_mgr.events)))

if opt.chisq_threshold and opt.chisq_bins:
    logging.info("Removing triggers with poor chisq")
    event_mgr.chisq_threshold(opt.chisq_threshold, opt.chisq_bins, 
                              opt.chisq_delta)
    logging.info("%s remaining triggers" % str(len(event_mgr.events)))

if opt.maximization_interval:       
    logging.info("Maximizing triggers over %s ms window" % opt.maximization_interval)
    window = opt.maximization_interval * gwstrain.sample_rate / 1000
    event_mgr.maximize_over_bank("time_index", "snr", window)
    logging.info("%s remaining triggers" % str(len(event_mgr.events)))

logging.info("Writing out triggers")
event_mgr.write_events(opt.output)


if opt.fftw_output_float_wisdom_file:
    fft.fftw.export_single_wisdom_to_filename(opt.fftw_output_float_wisdom_file)

if opt.fftw_output_double_wisdom_file:
    fft.fftw.export_double_wisdom_to_filename(opt.fftw_output_double_wisdom_file)

logging.info("Finished")
