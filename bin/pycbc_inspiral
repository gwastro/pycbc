#!/usr/bin/env /usr/bin/python

# Imports #####################################################################
from optparse import OptionParser
import logging

import numpy
import pycbc.vetoes
import pycbc.psd
import pycbc.waveform
import pycbc.events
from pycbc.filter import resample_to_delta_t, highpass, make_frequency_series
from pycbc.filter import  matched_filter_core, sigmasq
from pycbc.scheme import CUDAScheme, CPUScheme, OpenCLScheme
from pycbc.types import TimeSeries, float32, complex64, zeros, FrequencySeries
from pycbc.frame import read_frame

# Option Parsing ##############################################################

parser = OptionParser(
    usage   = "%prog [OPTIONS]",
    description = "Find single detector gravitational-wave triggers." )

parser.add_option("-V", "--verbose", action="store_true", help="print extra debugging information", default=False )
parser.add_option("--bank-file", type=str)
parser.add_option("--bank-veto-bank-file", type=str)
parser.add_option("--injection-file", type=str)
parser.add_option("--trig-start-time", type=int, default=0)
parser.add_option("--trig-end-time", type=int, default=0)
parser.add_option("--ifo-tag", type=str)
parser.add_option("--approximant", help="Approximant to use for filtering.", type=str)
parser.add_option("--order", type=str)
parser.add_option("--enable-output", type=str)
parser.add_option("--strain-high-pass-freq")
parser.add_option("--strain-high-pass-atten")
parser.add_option("--strain-high-pass-order")
parser.add_option("--high-pass-order")
parser.add_option("--calibrated-data")
parser.add_option("--enable-filter-inj-only", action="store_true")
parser.add_option("--resample-filter")
parser.add_option("--write-compress")
parser.add_option("--disable-rsq-veto", action="store_true")
parser.add_option("--dynamic-range-exponent", type=str)
parser.add_option("--gps-start-time", help="The gps start time of the data", type=int)
parser.add_option("--gps-end-time", help="The gps end time of the data", type=int)
parser.add_option("--channel-name", help="The channel that contains the gravitational strain data", type=str)
parser.add_option("--frame-cache", help="Either a set of frame files or a cache file that points to the frame file locations.", type=str)
parser.add_option("--snr-threshold", help="The the minimum snr threshold", type=float)
parser.add_option("--enable-high-pass", type=float)
parser.add_option("--high-pass-attenuation", type=float)
parser.add_option("--chisq-bins", type=int, default=0)
parser.add_option("--chisq-threshold", type=float)
parser.add_option("--chisq-delta", type=float, default=0)
parser.add_option("--low-frequency-cutoff", help="The low frequency cutoff to use for filtering (Hz)", type=float)
parser.add_option("--pad-data", help="Extra padding to remove highpass corruption (s)", type=int)
parser.add_option("--sample-rate", help="The sample rate to use for filtering (Hz)", type=int)
parser.add_option("--segment-overlap", type=int)
parser.add_option("--number-of-segments", help="Number of segments to split the data into", type=int)
parser.add_option("--segment-length", type=int)
parser.add_option("--spectrum-type", type=str)
parser.add_option("--inverse-spec-length", type=int)
parser.add_option("--cluster-method", choices=["template", "window"])
parser.add_option("--cluster-window", type=int, help="Length of clustering window in seconds")
parser.add_option("--maximization-interval", type=float)
parser.add_option("--user-tag", type=str)
parser.add_option("--processing-scheme", help="The processing scheme to use", choices=["cpu", "cuda"], default="cpu")
parser.add_option("--processing-device-id", help="ID of gpu to use for accelerated processing", default=0, type=int)
opt, argv = parser.parse_args()

if opt.verbose:
    log_level = logging.DEBUG
else:
    log_level = logging.WARN
    
logging.basicConfig(format='%(asctime)s : %(message)s', level=log_level)

if opt.processing_scheme == "cuda":
    logging.info("Running with CUDA support")
    ctx = CUDAScheme(opt.processing_device_id)
else:
    logging.info("Running with CPU support only")
    ctx = CPUScheme()

duration = opt.gps_end_time - opt.gps_start_time

# Data Preconditioning ########################################################

logging.info("Reading Frames")
strain = read_frame(opt.frame_cache, opt.channel_name, start_time=opt.gps_start_time-opt.pad_data, duration=duration+opt.pad_data*2)

logging.info("Highpass Filtering")
strain = highpass(strain, frequency=opt.enable_high_pass)

logging.info("Converting to float32")
strain *= pycbc.DYN_RANGE_FAC
strain = TimeSeries(strain, delta_t=strain.delta_t, epoch=strain.start_time, dtype=float32)

logging.info("Resampling data")
strain = resample_to_delta_t(strain, 1.0/opt.sample_rate)
strain = strain[opt.pad_data*opt.sample_rate:len(strain)-opt.sample_rate*opt.pad_data]

with ctx:
    logging.info("Estimating PSD")
    psd = pycbc.psd.welch(strain, seg_len=opt.segment_length, 
                          seg_stride=(opt.segment_length - opt.segment_overlap))

    logging.info("Interpolating PSD")
    psd = pycbc.psd.interpolate(psd, float(opt.sample_rate)/opt.segment_length)

    logging.info("Truncating Inverse PSD spectrum")
    psd = pycbc.psd.inverse_spectrum_truncation(psd, opt.sample_rate*opt.inverse_spec_length,  low_frequency_cutoff=opt.low_frequency_cutoff)

    logging.info("Strain to stilde")
    segments = []
    for j in range(opt.number_of_segments):
        seg_start = j * (opt.segment_length - opt.segment_overlap) 
        seg_end = seg_start + opt.segment_length
        segments.append(make_frequency_series(strain[seg_start:seg_end]))
    
    logging.info("overwhiten stilde")
    for seg in segments:
        seg /= psd
    
    if pycbc.waveform.waveform_precondition_exists(opt.approximant):
        logging.info("Preconditioning Stilde for template")
        prec_fac = pycbc.waveform.get_waveform_filter_precondition(opt.approximant,  len(segments[0]), segments[0].delta_f)
        for seg in segments:
            seg *= prec_fac.astype(complex64)          
        bank_psd = psd / (prec_fac.astype(complex64) ** 2.0) 
    else:
        bank_psd = psd
            
    template_work_mem = zeros((len(segments[0])-1)*2, dtype=complex64)
    snr_work_mem = zeros((len(segments[0])-1)*2, dtype=complex64)
    corr_work_mem = zeros((len(segments[0])-1)*2, dtype=complex64)

    logging.info("Read in template bank")
    bank = pycbc.waveform.TemplateBank(opt.bank_file, opt.approximant, len(segments[0]),  
                                       segments[0].delta_f, opt.low_frequency_cutoff, 
                                       dtype=complex64, 
                                       phase_order=opt.order,
                                       out=template_work_mem)  
    if opt.bank_veto_bank_file:
        # Read in the bank veto bank
        bank_veto_bank = pycbc.waveform.TemplateBank(opt.bank_veto_bank_file,\
                opt.approximant, len(segments[0]),segments[0].delta_f,\
                opt.low_frequency_cutoff,dtype=complex64,phase_order=opt.order)
        # The following command actually generates all the templates and 
        # stores them as a list of frequency series
        bank_veto_bank = list(bank_veto_bank)
        # Count the templates
        num_bank_veto_templates = len(bank_veto_bank)
        # Create memory for storing the bank veto filter time series
        bank_veto_snr_work_mem = []
        for i in range(num_bank_veto_templates):
            bank_veto_snr_work_mem.append(\
                    zeros((len(segments[0])-1)*2, dtype=complex64))
        # Actually generate the templates
        bank_veto_gen_templates = []
        for bank_template in bank_veto_bank:
          bank_veto_gen_templates.append(bank_template)
    else:
        num_bank_veto_templates = 0

    hnorm_vec = None
    if pycbc.waveform.waveform_norm_exists(opt.approximant):
        logging.info("Precalculating template normalizations")
        hnorm_vec = pycbc.waveform.get_waveform_filter_norm(opt.approximant, psd, len(segments[0]), 
                                                            segments[0].delta_f, opt.low_frequency_cutoff)      
    i = 0    
    event_mgr = pycbc.events.EventManager(opt, ['time_index', 'snr', 'chisq','bank_chisq'], [int, complex64, float32, float32],num_bank_templates=num_bank_veto_templates)

    cumulative_index = opt.segment_length / 4
    for segNum,stilde in enumerate(segments):
        # First we want to generate the overlaps between the bank veto templates
        # and the current segment
        if opt.bank_veto_bank_file:
            bank_snrs = []
            bank_norms = []
            for kk,bank_template in enumerate(bank_veto_bank):
                # For every bank veto template compute overlap between template
                # and the data
                if hnorm_vec is not None:
                    k_end = int(bank_template.end_frequency / bank_template.delta_f)
                    bank_hnorm = hnorm_vec[k_end]
                else:
                    bank_hnorm = sigmasq(bank_template, psd, \
                            low_frequency_cutoff=opt.low_frequency_cutoff)
                curr_bank_snr,_,curr_bank_norm = matched_filter_core(\
                        bank_template,stilde,h_norm=bank_hnorm,\
                        low_frequency_cutoff=opt.low_frequency_cutoff,\
                        out=bank_veto_snr_work_mem[kk], corr_out=corr_work_mem)
                # SNR time series stored here
                bank_snrs.append(curr_bank_snr)
                # Template normalization factor stored here
                bank_norms.append(curr_bank_norm)
 
        for template in bank:   
            # We need to calculate the overlap between the search template
            # and every bank_veto_template
            if opt.bank_veto_bank_file:
                bank_veto_curr_overlaps = []
                for bank_template in bank_veto_bank:
                    bank_veto_curr_overlaps.append(pycbc.filter.overlap_cplx(\
                            template,bank_template,psd=bank_psd,\
                            low_frequency_cutoff=opt.low_frequency_cutoff))
                        
            if hnorm_vec is not None:
                k_end = int(template.end_frequency / template.delta_f)
                h_norm = hnorm_vec[k_end]
                if opt.chisq_bins != 0:
                    chisq_bins = pycbc.vetoes.power_chisq_bins_from_sigmasq_series(hnorm_vec, opt.chisq_bins,
                                     int(opt.low_frequency_cutoff / template.delta_f), k_end)
            else:
                h_norm = sigmasq(template, psd, low_frequency_cutoff=opt.low_frequency_cutoff)
                if opt.chisq_bins != 0:
                    chisq_bins = pycbc.vetoes.power_chisq_bins(template, opt.chisq_bins, psd, opt.low_frequency_cutoff)
       
            logging.info("Filtering " + str(i+1)+"/"+str(len(bank)*len(segments)) )       
        
            snr, corr, norm = matched_filter_core(template, stilde, h_norm=h_norm, 
                                       low_frequency_cutoff=opt.low_frequency_cutoff, 
                                       out=snr_work_mem, corr_out=corr_work_mem)

            # This only needs to be added once
            # FIXME: Alex to rethink this around the new ordering and add
            # details of what this actually is doing
            event_mgr.new_template(tmplt=template.params,
                                 sigmasq=h_norm,
                                 template_amplitude_norm=template.amplitude_norm)
            event_mgr.add_template_params(snr_norm=norm)
                                       
            snr_start = opt.segment_length / 4
            snr_end  =  opt.segment_length * 3 / 4 
            seg_width = snr_end - snr_start 

            if opt.trig_start_time:
                seg_start = cumulative_index/opt.sample_rate + opt.gps_start_time
                if seg_start < opt.trig_start_time:
                    snr_start = (opt.trig_start_time - seg_start) * opt.sample_rate + snr_start
            
            if opt.trig_end_time:
                seg_end = (cumulative_index + seg_width)/opt.sample_rate +  opt.gps_start_time
                if seg_end > opt.trig_end_time:
                    snr_end = snr_end - (seg_end - opt.trig_end_time) * opt.sample_rate 
                    
            if snr_start < snr_end:
                segment_events = pycbc.events.threshold(snr[snr_start:snr_end], opt.snr_threshold / norm)                 

                bank_vetov = None
                if (len(segment_events) > 0) and (opt.bank_veto_bank_file):
                    bank_veto = pycbc.vetoes.bank_chisq_from_filters(snr,norm,\
                            bank_snrs,bank_norms,bank_veto_curr_overlaps)
                    bank_vetov = bank_veto.take(segment_events['loc']+snr_start).numpy()

                chisqv = None
                if (len(segment_events) > 0) and (opt.chisq_bins != 0):
                    chisq = pycbc.vetoes.power_chisq_from_precomputed(corr, snr, chisq_bins, norm)
                    chisqv = chisq.take(segment_events['loc']+snr_start).numpy()
                    
                if (len(segment_events) > 0):
                    idx = segment_events['loc']
                    snrv = segment_events['val']
                    idx += cumulative_index
                    event_mgr.add_template_events(["snr", "time_index", "chisq", "bank_chisq"], [snrv, idx, chisqv, bank_vetov])
       
            if opt.cluster_method == "window":
                cluster_window = opt.cluster_window * opt.sample_rate
            elif opt.cluster_method == "template":
                cluster_window = template.length_in_time * opt.sample_rate
        
            event_mgr.cluster_template_events("time_index", "snr", cluster_window) 
            event_mgr.finalize_template_events()
            i+=1
        cumulative_index += seg_width
        
if opt.maximization_interval:
    window_size = int(opt.maximization_interval * opt.sample_rate / 1000)
    event_mgr.maximize_over_bank("time_index", "snr", window_size)
    
if opt.chisq_threshold:
    event_mgr.chisq_threshold(opt.chisq_threshold, opt.chisq_bins, opt.chisq_delta)
    
logging.info("Writing out triggers")
event_mgr.write_events()

logging.info("Finished")
