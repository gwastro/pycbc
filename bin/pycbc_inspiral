#!/usr/bin/env /usr/bin/python

# Copyright (C) 2014 Alex Nitz
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

import logging
import argparse
from pycbc import vetoes, psd, waveform, events, strain, scheme, fft, DYN_RANGE_FAC, filter
from pycbc.filter import MatchedFilterControl, sigmasq, make_frequency_series
from pycbc.types import TimeSeries, FrequencySeries, zeros, float32, complex64
import pycbc.fft.fftw

parser = argparse.ArgumentParser(usage='',
    description="Find single detector gravitational-wave triggers.")

parser.add_argument("-V", "--verbose", action="store_true", 
                  help="print extra debugging information", default=False )
parser.add_argument("--output", type=str, help="FIXME: ADD")
parser.add_argument("--bank-file", type=str, help="FIXME: ADD")
parser.add_argument("--snr-threshold", 
                  help="SNR threshold for trigger generation", type=float)
parser.add_argument("--newsnr-threshold", type=float, metavar='THRESHOLD',
                    help="Cut triggers with NewSNR less than THRESHOLD")
parser.add_argument("--low-frequency-cutoff", type=float,
                  help="The low frequency cutoff to use for filtering (Hz)")
                  
parser.add_argument("--approximant", type=str,
                  help="The name of the approximant to use for filtering")
parser.add_argument("--order", type=str,
                  help="The integer half-PN order at which to generate"
                       " the approximant.")
taper_choices = ["start","end","startend"]
parser.add_argument("--taper-template", choices=taper_choices,
                  help="For time-domain approximants, taper the start and/or "
                       "end of the waveform before FFTing.")

parser.add_argument("--cluster-method", choices=["template", "window"],
                    help="FIXME: ADD")
parser.add_argument("--cluster-window", type=float, default = -1,
                  help="Length of clustering window in seconds")
parser.add_argument("--maximization-interval", type=float, default=0,
                  help="Maximize triggers over the template bank (ms)")

parser.add_argument("--bank-veto-bank-file", type=str, help="FIXME: ADD")

parser.add_argument("--chisq-bins", type=int, default=0, help="FIXME: ADD")
parser.add_argument("--chisq-threshold", type=float, default=0,
                    help="FIXME: ADD")
parser.add_argument("--chisq-delta", type=float, default=0, help="FIXME: ADD")

parser.add_argument("--autochi-number-points", type=int, default=0)
parser.add_argument("--autochi-stride", type=int, default=0)
parser.add_argument("--autochi-onesided", action='store_true', default=False)
parser.add_argument("--downsample-factor", type=int, 
                    help="Factor that determines the interval between the "
                         "initial SNR sampling. If not set (or 1) no sparse sample " 
                         "is created, and the standard full SNR is calculated.", default=1)
parser.add_argument("--upsample-threshold", type=float, 
                    help="The fraction of the SNR threshold to check the sparse SNR sample.")
parser.add_argument("--upsample-method", choices=["pruned_fft"],
                    help="The method to find the SNR points between the sparse SNR sample.", default='pruned_fft')

parser.add_argument("--user-tag", type=str, metavar="TAG", help="""
                    This is used to identify FULL_DATA jobs for 
                    compatibility with pipedown post-processing. 
                    Option will be removed when no longer needed.""")

# Add options groups
psd.insert_psd_option_group(parser)
strain.insert_strain_option_group(parser)
strain.StrainSegments.insert_segment_option_group(parser)
scheme.insert_processing_option_group(parser)
fft.insert_fft_option_group(parser)

opt = parser.parse_args()

# Check that the values returned for the options make sense
psd.verify_psd_options(opt, parser)
strain.verify_strain_options(opt, parser)
strain.StrainSegments.verify_segment_options(opt, parser)
scheme.verify_processing_options(opt, parser)
fft.verify_fft_options(opt,parser)

if opt.verbose:
    log_level = logging.DEBUG
else:
    log_level = logging.WARN
logging.basicConfig(format='%(asctime)s : %(message)s', level=log_level)

ctx = scheme.from_cli(opt)
gwstrain = strain.from_cli(opt, DYN_RANGE_FAC)
strain_segments = strain.StrainSegments.from_cli(opt, gwstrain)

with ctx:
    fft.from_cli(opt)

    flow = opt.low_frequency_cutoff                                                               
    flen = strain_segments.freq_len
    tlen = strain_segments.time_len
    delta_f = strain_segments.delta_f

    logging.info("Making frequency-domain data segments")
    segments = strain_segments.fourier_segments()

    logging.info("Computing noise PSD")
    psd = psd.from_cli(opt, flen, delta_f, flow, gwstrain, DYN_RANGE_FAC)
    psd = psd.astype(float32)                              

    matched_filter = MatchedFilterControl(opt.low_frequency_cutoff, None,
                                   opt.snr_threshold, segments,
                                   downsample_factor=opt.downsample_factor,
                                   upsample_threshold=opt.upsample_threshold,
                                   upsample_method=opt.upsample_method)
                               
    bank_chisq = vetoes.SingleDetBankVeto(opt.bank_veto_bank_file,
                                          opt.approximant, psd, segments, flow,
                                          phase_order=opt.order)

    power_chisq = vetoes.SingleDetPowerChisq(opt.chisq_bins)
    autochisq = vetoes.SingleDetAutoChisq(opt.autochi_stride, opt.snr_threshold,
                               opt.autochi_number_points, opt.autochi_onesided)

    logging.info("Overwhitening frequency-domain data segments")
    for seg in segments:
        seg /= psd

    names =  ['time_index', 'snr', 'chisq', 'bank_chisq', 'cont_chisq']
    event_mgr = events.EventManager(opt, names,
                         [int, complex64, float32, float32, float32, float32], psd=psd)

    logging.info("Read in template bank")
    bank = waveform.FilterBank(opt.bank_file, opt.approximant, flen, delta_f, 
                    flow, dtype=complex64, psd=psd, phase_order=opt.order,
                    taper=opt.taper_template, out=zeros(tlen, dtype=complex64))

    for t_num, template in enumerate(bank):  
        event_mgr.new_template(tmplt=template.params, sigmasq=template.sigmasq)  
        if opt.cluster_method == "window":
            cluster_window = int(opt.cluster_window * gwstrain.sample_rate)
        elif opt.cluster_method == "template":
            cluster_window = int(template.chirp_length * gwstrain.sample_rate)

        for s_num, stilde in enumerate(segments):                 
            logging.info("Filtering template %d/%d segment %d/%d" % \
                         (t_num + 1, len(bank), s_num + 1, len(segments)))  
                         
            snr, norm, corr, idx, snrv = \
                    matched_filter.matched_filter_and_cluster(template, stilde, cluster_window)

            if not len(idx):
                continue

            bank_chisqv = bank_chisq.values(template, s_num, snr, norm,
                                            idx+stilde.analyze.start)
            power_chisqv = power_chisq.values(corr, snrv, norm, psd,
                                            idx+stilde.analyze.start,
                                            template, bank, flow)
                                            
            snrv *= norm
            
            if opt.autochi_number_points:
                auto_chisqv = autochisq.values(snr*norm, corr, hautocorr=None, 
                    indices=idx+stilde.analyze.start, template=template, psd=psd, 
                    low_frequency_cutoff=flow)

            idx += stilde.cumulative_index

            if (opt.autochi_number_points):
               vals = [idx, snrv, power_chisqv, bank_chisqv, auto_chisqv[:, 2]]
            else:
               vals = [idx, snrv, power_chisqv, bank_chisqv, None]

            event_mgr.add_template_events(names, vals)

        event_mgr.cluster_template_events("time_index", "snr", cluster_window) 
        event_mgr.finalize_template_events()   
        
logging.info("Found %s triggers" % str(len(event_mgr.events)))

if opt.chisq_threshold and opt.chisq_bins:
    logging.info("Removing triggers with poor chisq")
    event_mgr.chisq_threshold(opt.chisq_threshold, opt.chisq_bins, 
                              opt.chisq_delta)
    logging.info("%d remaining triggers" % len(event_mgr.events))

if opt.newsnr_threshold and opt.chisq_bins:
    logging.info("Removing triggers with NewSNR below threshold")
    event_mgr.newsnr_threshold(opt.newsnr_threshold)
    logging.info("%d remaining triggers" % len(event_mgr.events))

if opt.maximization_interval:       
    logging.info("Maximizing triggers over %s ms window" % opt.maximization_interval)
    window = int(opt.maximization_interval * gwstrain.sample_rate / 1000)
    event_mgr.maximize_over_bank("time_index", "snr", window)
    logging.info("%d remaining triggers" % len(event_mgr.events))

logging.info("Writing out triggers")
event_mgr.write_events(opt.output)


if opt.fftw_output_float_wisdom_file:
    fft.fftw.export_single_wisdom_to_filename(opt.fftw_output_float_wisdom_file)

if opt.fftw_output_double_wisdom_file:
    fft.fftw.export_double_wisdom_to_filename(opt.fftw_output_double_wisdom_file)

logging.info("Finished")
