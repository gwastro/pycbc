#!/usr/bin/python
""" Make table of the foreground coincident events
"""
import argparse, h5py, numpy, logging, types
from glue.ligolw import ligolw, table, lsctables, utils as ligolw_utils
from glue import segments
import os.path

# dummy class needed for loading LIGOLW files
class LIGOLWContentHandler(ligolw.LIGOLWContentHandler):
    pass
lsctables.use_in(LIGOLWContentHandler)

def in1d(ar1, ar2, assume_unique=False, invert=False):
    """Stolen from numpy, please kill me and upgrade numpy....
    """
    import numpy as np
    # Ravel both arrays, behavior for the first array could be different
    ar1 = np.asarray(ar1).ravel()
    ar2 = np.asarray(ar2).ravel()

    # This code is significantly faster when the condition is satisfied.
    if len(ar2) < 10 * len(ar1) ** 0.145:
        if invert:
            mask = np.ones(len(ar1), dtype=np.bool)
            for a in ar2:
                mask &= (ar1 != a)
        else:
            mask = np.zeros(len(ar1), dtype=np.bool)
            for a in ar2:
                mask |= (ar1 == a)
        return mask

    # Otherwise use sorting
    if not assume_unique:
        ar1, rev_idx = np.unique(ar1, return_inverse=True)
        ar2 = np.unique(ar2)

    ar = np.concatenate( (ar1, ar2) )
    # We need this to be a stable sort, so always use 'mergesort'
    # here. The values from the first array should always come before
    # the values from the second array.
    order = ar.argsort(kind='mergesort')
    sar = ar[order]
    if invert:
        bool_ar = (sar[1:] != sar[:-1])
    else:
        bool_ar = (sar[1:] == sar[:-1])
    flag = np.concatenate( (bool_ar, [invert]) )
    indx = order.argsort(kind='mergesort')[:len( ar1 )]

    if assume_unique:
        return flag[indx]
    else:
        return flag[indx][rev_idx]

numpy.in1d = in1d

def hdf_append(f, key, value):
    if key in f:
        tmp = numpy.concatenate([f[key][:], value])
        del f[key]
        f[key] = tmp
    else:
        f[key] = value
       
h5py.File.append = types.MethodType(hdf_append, h5py.File)

def veto_indices(times, ifo, veto_files):
    """ Return the list of indices that should be vetoed by the segments in the
    lsit of veto_files.
    """
    time_sorting = numpy.argsort(times)
    times = times[time_sorting]
    indices = numpy.array([], dtype=numpy.uint32)
   
    for veto_file in veto_files:
        indoc = ligolw_utils.load_filename(veto_file, False, contenthandler=LIGOLWContentHandler)
        segment_table  = table.get_table(indoc, lsctables.SegmentTable.tableName)
        
        seg_def_table = table.get_table(indoc, lsctables.SegmentDefTable.tableName)
        def_ifos = seg_def_table.getColumnByName('ifos')
        def_ids = seg_def_table.getColumnByName('segment_def_id')
        ifo_map =  {}
        for def_ifo, def_id in zip(def_ifos, def_ids):
            ifo_map[def_id] = def_ifo
        
        start = numpy.array(segment_table.getColumnByName('start_time')) + numpy.array(segment_table.getColumnByName('start_time_ns')) * 1e-9
        end = numpy.array(segment_table.getColumnByName('end_time')) + numpy.array(segment_table.getColumnByName('end_time_ns')) * 1e-9
        ifos = [ifo_map[v] for v in segment_table.getColumnByName('segment_def_id')]
        
        veto_segs = segments.segmentlist()
        for s, e, ifo_row in zip(start, end, ifos):
            if ifo != ifo_row:
                continue
                
            veto_segs += [segments.segment(s, e)]

        veto_segs.coalesce()        

        left = numpy.searchsorted(times, start, side='left')
        right = numpy.searchsorted(times, end, side='right')
        for li, ri, ifo_row in zip(left, right, ifos):
            if ifo != ifo_row:
                continue
                
            seg_indices = numpy.arange(li, ri, 1).astype(numpy.uint32)
            indices=numpy.union1d(seg_indices, indices)  
    return time_sorting[indices], veto_segs

def keep_ind(times, start, end):
    """ Return the list of indices within the list of start and end times
    """
    time_sorting = times.argsort()
    times = times[time_sorting]
    indices = numpy.array([], dtype=numpy.uint32)
    left = numpy.searchsorted(times, start, side='left')
    right = numpy.searchsorted(times, end, side='right')
    
    for li, ri in zip(left, right):
        seg_indices = numpy.arange(li, ri, 1).astype(numpy.uint32)
        indices=numpy.union1d(seg_indices, indices)  
    return time_sorting[indices] 

def xml_to_hdf(table, hdf_file, hdf_key, columns):
    """ Save xml columns as hdf columns, only float32 supported atm.
    """
    for col in columns:
        key = os.path.join(hdf_key, col) 
        hdf_append(hdf_file, key, numpy.array(table.get_column(col), 
                                        dtype=numpy.float32))
     
parser = argparse.ArgumentParser()
parser.add_argument('--trigger-files', nargs='+')
parser.add_argument('--injection-files', nargs='+')
parser.add_argument('--veto-file')
parser.add_argument('--injection-window', type=float)
parser.add_argument('--verbose', action='count')
parser.add_argument('--output-file')
args = parser.parse_args()

if args.verbose:
    log_level = logging.INFO
    logging.basicConfig(format='%(asctime)s : %(message)s', level=log_level)

fo = h5py.File(args.output_file, 'w')
injection_index = 0
for trigger_file, injection_file in zip(args.trigger_files, args.injection_files):   
    logging.info('Read in the coinc data: %s' % trigger_file)
    f = h5py.File(trigger_file, 'r')

    template_id = f['foreground/template_id'][:]
    stat = f['foreground/stat'][:]
    ifar = f['foreground/ifar'][:]
    time1 = f['foreground/time1'][:]
    time2 = f['foreground/time2'][:]
    ana_start = f['foreground/analyzed_start'][:]
    ana_end = f['foreground/analyzed_end'][:]
    time = 0.5 * (time1 + time2)
    time_sorting = time.argsort()

    logging.info('Read in the injection file')
    indoc = ligolw_utils.load_filename(injection_file, False, contenthandler=LIGOLWContentHandler)
    sim_table = table.get_table(indoc, lsctables.SimInspiralTable.tableName)
    inj_time = numpy.array(sim_table.get_column('geocent_end_time') + 1e-9 * sim_table.get_column('geocent_end_time_ns'), dtype=numpy.float64)

    logging.info('Determined the found injections by time')
    left = numpy.searchsorted(time[time_sorting], inj_time - args.injection_window, side='left')
    right = numpy.searchsorted(time[time_sorting], inj_time + args.injection_window, side='right')
    found = numpy.where((right-left) == 1)[0]
    missed = numpy.where((right-left) == 0)[0]
    ambiguous = numpy.where((right-left) > 1)[0]
    missed = numpy.concatenate([missed, ambiguous])
    logging.info('Found: %s, Missed: %s Ambiguous: %s' % (len(found), len(missed), len(ambiguous)))

    if len(ambiguous) > 0:
        logging.warn('More than one coinc trigger found associated to injection') 
        print inj_time[ambiguous]
        am = numpy.arange(0, len(inj_time), 1)[left[ambiguous]]
        bm = numpy.arange(0, len(inj_time), 1)[right[ambiguous]]
        print time[time_sorting][am]
        print am, bm

    logging.info('Removing injections outside of analyzed time')
    ki = keep_ind(inj_time, ana_start, ana_end)
    found_within_time = numpy.intersect1d(ki, found)
    missed_within_time = numpy.intersect1d(ki, missed)
    logging.info('Found: %s, Missed: %s' % (len(found_within_time), len(missed_within_time)))

    logging.info('Removing injections in vetoed time')
    i1, v1 = veto_indices(inj_time, 'H1', [args.veto_file])
    i2, v2 = veto_indices(inj_time, 'L1', [args.veto_file])
    vi = numpy.concatenate([i1, i2])
    found_after_vetoes = numpy.delete(found_within_time, numpy.in1d(found_within_time, vi))
    missed_after_vetoes = numpy.delete(missed_within_time, numpy.in1d(missed_within_time, vi))
    logging.info('Found: %s, Missed: %s' % (len(found_after_vetoes), len(missed_after_vetoes)))

    found_fore = numpy.arange(0, len(inj_time), 1)[left[found]]
    found_fore_v = numpy.arange(0, len(inj_time), 1)[left[found_after_vetoes]]

    logging.info('Saving injection information')
    columns = ['mass1', 'mass2', 'spin1x', 'spin1y', 
               'spin1z', 'spin2x', 'spin2y', 'spin2z',
               'eff_dist_l', 'eff_dist_h', 'eff_dist_v', 
               'inclination', 'polarization', 'coa_phase', 
               'latitude', 'longitude', 'distance']
    xml_to_hdf(sim_table, fo, 'injections', columns)
    hdf_append(fo, 'injections/end_time', inj_time)
    fo.attrs['detector_1'] = f.attrs['detector_1']
    fo.attrs['detector_2'] = f.attrs['detector_2']
    hdf_append(fo, 'missed/all', missed + injection_index)
    hdf_append(fo, 'missed/within_analysis', missed_within_time + injection_index)
    hdf_append(fo, 'missed/after_vetoes', missed_after_vetoes + injection_index)

    hdf_append(fo, 'found/template_id', template_id[time_sorting][found_fore])
    hdf_append(fo, 'found/injection_index', found + injection_index)
    hdf_append(fo, 'found/stat', stat[time_sorting][found_fore])
    hdf_append(fo, 'found/time1', time1[time_sorting][found_fore])
    hdf_append(fo, 'found/time2', time2[time_sorting][found_fore])
    hdf_append(fo, 'found/ifar', ifar[time_sorting][found_fore])

    hdf_append(fo, 'found_after_vetoes/template_id', template_id[time_sorting][found_fore_v])
    hdf_append(fo, 'found_after_vetoes/injection_index', found_after_vetoes + injection_index)
    hdf_append(fo, 'found_after_vetoes/stat', stat[time_sorting][found_fore_v])
    hdf_append(fo, 'found_after_vetoes/time1', time1[time_sorting][found_fore_v])
    hdf_append(fo, 'found_after_vetoes/time2', time2[time_sorting][found_fore_v])
    hdf_append(fo, 'found_after_vetoes/ifar', ifar[time_sorting][found_fore_v])
    
    injection_index += len(sim_table)
