#!/bin/env python
# Copyright (C) 2015 Alexander Harvey Nitz
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
""" Followup foreground events
"""
import os, argparse, logging, h5py, pycbc.workflow as wf
from pycbc.results import layout
from pycbc.types import MultiDetOptionAction
import pycbc.workflow.minifollowups as mini
import pycbc.workflow.pegasus_workflow as wdax
import pycbc.version

def to_file(path, ifo=None):
    fil = wdax.File(os.path.basename(path))
    fil.ifo = ifo
    fil.PFN(path, 'local')
    return fil

parser = argparse.ArgumentParser(description=__doc__[1:])
parser.add_argument('--version', action='version', version=pycbc.version.git_verbose_msg) 
parser.add_argument('--workflow-name', default='my_unamed_run')
parser.add_argument("-d", "--output-dir", default=None,
                    help="Path to output directory.")
parser.add_argument('--bank-file',
                    help="HDF format template bank file")
parser.add_argument('--statmap-file',
                    help="HDF format clustered coincident trigger result file")
parser.add_argument('--single-detector-triggers', nargs='+', action=MultiDetOptionAction,
                    help="HDF format merged single detector trigger files")
parser.add_argument('--inspiral-segments', nargs='+', action=MultiDetOptionAction,
                    help="xml segment files containing the inspiral analysis times")
parser.add_argument('--inspiral-segment-name',
                    help="Name of inspiral segmentlist to read from segment files")
parser.add_argument('--output-map')
parser.add_argument('--output-file')
parser.add_argument('--tags', nargs='+', default=[])
wf.add_workflow_command_line_group(parser)
args = parser.parse_args()

logging.basicConfig(format='%(asctime)s:%(levelname)s : %(message)s', 
                    level=logging.INFO)

workflow = wf.Workflow(args, args.workflow_name)

wf.makedir(args.output_dir)
             
# create a FileList that will contain all output files
layouts = []

tmpltbank_file = to_file(args.bank_file)
coinc_file = to_file(args.statmap_file)

single_triggers = []
for ifo in args.single_detector_triggers:
    fname = args.single_detector_triggers[ifo]
    single_triggers.append(to_file(fname, ifo=ifo))
    
insp_segs = {}
for ifo in args.inspiral_segments:
    fname = args.inspiral_segments[ifo]
    insp_segs[ifo] = to_file(fname, ifo=ifo)

num_events = int(workflow.cp.get_opt_tags('workflow-minifollowups', 'num-events', ''))
f = h5py.File(args.statmap_file, 'r')
stat = f['foreground/stat'][:]

sorting = stat.argsort()[::-1]

if len(stat) < num_events:
    num_events = len(stat)

stat = stat[sorting][0:num_events]

times = {f.attrs['detector_1']: f['foreground/time1'][:][sorting][0:num_events],
         f.attrs['detector_2']: f['foreground/time2'][:][sorting][0:num_events],
        }
tids = {f.attrs['detector_1']: f['foreground/trigger_id1'][:][sorting][0:num_events],
         f.attrs['detector_2']: f['foreground/trigger_id2'][:][sorting][0:num_events],
        }

bank_data = h5py.File(args.bank_file, 'r')

# loop over number of loudest events to be followed up
for num_event in range(num_events):
    files = wf.FileList([])
    
    ifo_times = '%s:%s %s:%s' % (times.keys()[0], times[times.keys()[0]][num_event],
                                 times.keys()[1], times[times.keys()[1]][num_event])

    ifo_tids = '%s:%s %s:%s' % (tids.keys()[0], tids[tids.keys()[0]][num_event],
                                 tids.keys()[1], tids[tids.keys()[1]][num_event])
    
    bank_id = f['foreground/template_id'][:][sorting][num_event]
    
    layouts += (mini.make_coinc_info(workflow, single_triggers, tmpltbank_file,
                              coinc_file, num_event, 
                              args.output_dir, tags=args.tags + [str(num_event)]),)        
    files += mini.make_trigger_timeseries(workflow, single_triggers,
                              ifo_times, args.output_dir, special_tids=ifo_tids,
                              tags=args.tags + [str(num_event)])
    
    params = {}                          
    for ifo in times:
        params['%s_end_time' % ifo] = times[ifo][num_event]

    params['mass1'] = bank_data['mass1'][bank_id]
    params['mass2'] = bank_data['mass2'][bank_id]
    params['spin1z'] = bank_data['spin1z'][bank_id]
    params['spin2z'] = bank_data['spin2z'][bank_id]
    files += mini.make_single_template_plots(workflow, insp_segs,
                                    args.inspiral_segment_name, params,
                                    args.output_dir, tags=args.tags + [str(num_event)])
    
    for single in single_triggers:
        time = times[single.ifo][num_event]
        files += mini.make_singles_timefreq(workflow, single, tmpltbank_file, 
                                time - 10, time + 10, args.output_dir,
                                tags=args.tags + [str(num_event)])
    
    layouts += list(layout.grouper(files, 2))
    num_event += 1

workflow.save(filename=args.output_file, output_map=args.output_map)
layout.two_column_layout(args.output_dir, layouts)
