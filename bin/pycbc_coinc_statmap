#!/bin/env  python
"""
The program combines coincident output files generated
by pycbc_coinc_findtrigs to generated a mapping between SNR and FAP, along
with producing the combined foreground and background triggers
"""
import argparse, h5py, numpy, logging     
    
def load_coincs(coinc_files):
    stat1 = []
    stat2 = []
    time1 = []
    time2 = []
    timeslide_id = []
    template_id = []
    for cfile in coinc_files:
        print cfile
        f = h5py.File(cfile, "r")
        stat1.append(f['coinc/stat1'])
        stat2.append(f['coinc/stat2'])
        time1.append(f['coinc/time1'])
        time2.append(f['coinc/time2'])
        timeslide_id.append(f['coinc/timeslide_id'])
        template_id.append(f['coinc/template_id'])
    return (numpy.concatenate(stat1),
           numpy.concatenate(stat2),
           numpy.concatenate(time1),
           numpy.concatenate(time2),
           numpy.concatenate(timeslide_id),
           numpy.concatenate(template_id), 
           f.attrs['timeslide_interval'])
    
def cluster_coincs(stat1, stat2, time1, time2, 
                   timeslide_id, timeslide_interval, window):
    """Cluster coincident events for each timeslide separately, across 
    templates, based on the loudest network statistic (stat1**2 + stat2**2). 
    Return the set of indices corresponding to the surviving coincidences.
    """
    indices = []
    nstatsq = stat1**2.0 + stat2**2.0
    time = (time2 + (time1 + timeslide_id * timeslide_interval)) / 2 
    
    trig = {}
    for t, s, sid in zip(time, nstatsq, timeslide_id):
        if sid not in trig:
            trig[sid] = [[t], [s]]
        else:
            trig[sid] = [trig[sid][0]+[t], trig[sid][1]+[s]]
            
    for i, (t, s, sid) in enumerate(zip(time, nstatsq, timeslide_id)):
        clustered_away = False
        for t_other, s_other in zip(*trig[sid]):
            if t_other != t and abs(t_other - t) <= window and s_other > s:
                clustered_away = True
                break
                
        if clustered_away:
            continue
        else:  
            indices.append(i)  
    
    return numpy.array(indices, dtype=numpy.uint32)

if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    # General required options
    parser.add_argument('--coinc-files', nargs='+')
    parser.add_argument('--verbose', action='count')
    parser.add_argument('--cluster-window', type=float)
    parser.add_argument('--output-file')
    parser.add_argument('--save-background')
    parser.add_argument('--save-fap')
    args = parser.parse_args()

    if args.verbose:
        log_level = logging.INFO
        logging.basicConfig(format='%(asctime)s : %(message)s', 
                            
                                level=log_level)
    
    logging.info("Loading coinc triggers")    
    s1, s2, t1, t2, sid, tid, timeslide_interval = load_coincs(args.coinc_files)    
    logging.info("We have %s triggers" % len(s1))

    logging.info("Clustering coinc triggers")
    cid = cluster_coincs(s1, s2, t1, t2, sid, 
                         timeslide_interval, 
                         args.cluster_window)
                         
    s1, s2, t1, t2, sid, tid = s1[cid], s2[cid], t1[cid], t2[cid], sid[cid], tid[cid]
    logging.info("We now have %s triggers" % len(s1))
    
    logging.info("Dumping foreground triggers")
    f = h5py.File(args.output_file, "w")
    fore_locs = sid == 0
    f['foreground/stat1'] = s1[fore_locs]
    f['foreground/stat2'] = s2[fore_locs]
    f['foreground/time1'] = t1[fore_locs]
    f['foreground/time2'] = t2[fore_locs]
    f['foreground/template_id'] = tid[fore_locs]
      
    logging.info("Dumping background tirggers")
    back_locs = sid != 0
    f['background/stat1'] = s1[back_locs]
    f['background/stat2'] = s2[back_locs]
    f['background/time1'] = t1[back_locs]
    f['background/time2'] = t2[back_locs]
    f['background/timeslide_id'] = sid[back_locs]
    f['background/template_id'] = tid[back_locs]
    
    logging.info("Making FAP to STAT mapping")

    logging.info("Done") 
    
