#!/bin/env  python
"""
The program combines coincident output files generated
by pycbc_coinc_findtrigs to generated a mapping between SNR and FAP, along
with producing the combined foreground and background triggers
"""
import argparse, h5py, numpy, logging, itertools  
    
def load_coincs(coinc_files):
    stat1 = []
    stat2 = []
    time1 = []
    time2 = []
    timeslide_id = []
    template_id = []
    for cfile in coinc_files:
        f = h5py.File(cfile, "r")
        stat1.append(f['coinc/stat1'])
        stat2.append(f['coinc/stat2'])
        time1.append(f['coinc/time1'])
        time2.append(f['coinc/time2'])
        timeslide_id.append(f['coinc/timeslide_id'])
        template_id.append(f['coinc/template_id'])
    return (numpy.concatenate(stat1),
           numpy.concatenate(stat2),
           numpy.concatenate(time1),
           numpy.concatenate(time2),
           numpy.concatenate(timeslide_id),
           numpy.concatenate(template_id), 
           f.attrs['timeslide_interval'])
  
def changed(arr):
    return arr[:-1] != arr[1:]
  
def cluster_coincs(stat1, stat2, time1, time2, 
                   timeslide_id, timeslide_interval, window):
    """Cluster coincident events for each timeslide separately, across 
    templates, based on the loudest network statistic (stat1**2 + stat2**2). 
    Return the set of indices corresponding to the surviving coincidences.
    """
    
    logging.info('clustering coinc triggers over %ss window' % window)
    
    indices = []
    nstatsq = stat1**2.0 + stat2**2.0
    if numpy.isfinite(timeslide_interval):
        time = (time2 + (time1 + timeslide_id * timeslide_interval)) / 2
    else:
        time = 0.5 * (time2 + time1)
        
    time_sorting = time.argsort()
    nstatsq = nstatsq[time_sorting]
    time = time[time_sorting]
    slide = timeslide_id[time_sorting]
    
    ledge = time - window
    redge = time + window
    lbin = numpy.searchsorted(time, ledge, side='left')
    rbin = numpy.searchsorted(time, redge, side='right')
    
    bin_edges = numpy.where(changed(lbin) + changed(rbin))
    grouped_lbin = lbin[bin_edges]
    grouped_rbin = rbin[bin_edges]  
    
    for l, r in itertools.izip(grouped_lbin, grouped_rbin):  
        unique_slides = numpy.unique(slide[l:r])    
        for slide_id in unique_slides:
            slide_locs = numpy.where(slide[l:r] == slide_id)[0]        
            indices.append(slide_locs[nstatsq[l:r][slide_locs].argmax()] + l)
       
    return numpy.unique(numpy.array(time_sorting[indices], dtype=numpy.uint32))

if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    # General required options
    parser.add_argument('--coinc-files', nargs='+')
    parser.add_argument('--verbose', action='count')
    parser.add_argument('--cluster-window', type=float, default=0)
    parser.add_argument('--output-file')
    args = parser.parse_args()

    if args.verbose:
        log_level = logging.INFO
        logging.basicConfig(format='%(asctime)s : %(message)s', 
                                level=log_level)
    
    logging.info("Loading coinc triggers")    
    s1, s2, t1, t2, sid, tid, timeslide_interval = load_coincs(args.coinc_files)    
    logging.info("We have %s triggers" % len(s1))

    if args.cluster_window != 0:
        logging.info("Clustering coinc triggers")
        cid = cluster_coincs(s1, s2, t1, t2, sid, 
                             timeslide_interval, 
                             args.cluster_window)
                         
    s1, s2, t1, t2, sid, tid = s1[cid], s2[cid], t1[cid], t2[cid], sid[cid], tid[cid]
    logging.info("We now have %s triggers" % len(s1))
    
    logging.info("Dumping foreground triggers")
    f = h5py.File(args.output_file, "w")
    fore_locs = sid == 0
    f['foreground/stat1'] = s1[fore_locs]
    f['foreground/stat2'] = s2[fore_locs]
    f['foreground/time1'] = t1[fore_locs]
    f['foreground/time2'] = t2[fore_locs]
    f['foreground/template_id'] = tid[fore_locs]
       
    logging.info("Dumping background tirggers")
    back_locs = sid != 0
    if len(back_locs) > 0:
        f['background/stat1'] = s1[back_locs]
        f['background/stat2'] = s2[back_locs]
        f['background/time1'] = t1[back_locs]
        f['background/time2'] = t2[back_locs]
        f['background/timeslide_id'] = sid[back_locs]
        f['background/template_id'] = tid[back_locs]
    else:
        pass
    
    logging.info("Making FAP to STAT mapping")

    logging.info("Done") 
    
