#!/usr/bin/env python
"""
The program combines coincident output files generated
by pycbc_coinc_findtrigs to generated a mapping between SNR and FAP, along
with producing the combined foreground and background triggers. It also has 
the capability of doing hierarchical removal of foreground triggers that are 
louder than all of the background triggers. We use this to properly assess 
the FANs of any other gravitational waves in the dataset.
"""
import sys
import argparse, h5py, logging, itertools, numpy
import lal
import copy
import numpy as np
from pycbc.events import veto, coinc
import pycbc.version, pycbc.pnutils, pycbc.io

def sec_to_year(sec):
    return sec / lal.YRJUL_SI

class fw(object):
    def __init__(self, name):
        self.f = h5py.File(name, 'w')
        self.attrs = self.f.attrs

    def __setitem__(self, name, data):
        # Make a new item if isn't in the hdf file
        if not name in self.f:
            self.f.create_dataset(name, data=data, compression="gzip",
                                  compression_opts=9, shuffle=True,
                                  maxshape=data.shape)
        # Else re-size that section and reassign values
        else:
            self.f[name].resize(data.shape)
            self.f[name][:] = data

    def __getitem__(self, *args):
        return self.f.__getitem__(*args)

    def close(self):
        self.f.close()

parser = argparse.ArgumentParser()
# General required options
parser.add_argument('--version', action='version', 
                    version=pycbc.version.git_verbose_msg)
parser.add_argument('--coinc-files', nargs='+', 
                    help='List of coincidence files used to calculate the '
                         'FAP, FAR, etc.')
parser.add_argument('--verbose', action='count')
parser.add_argument('--cluster-window', type=float, default=10,
                    help='Length of time window in seconds to cluster coinc '
                         'events, [default=10s]')
parser.add_argument('--veto-window', type=float, default=.1,
                    help='Time around each zerolag trigger to window out, '
                         '[default=.1s]')
parser.add_argument('--veto-window-hierarch', type=float, default=1.0,
                    help='Time around each trigger to window out for a very '
                         'louder trigger in the hierarchical removal '
                         'procedure.')
parser.add_argument('--cont-hier-removal', action='store_true',
                    default='store_false', 
                    help='Use this option to do continuous hierarchical '
                         'removal without any cutoff number of hierarchical '
                         'removals to stop at. [default=false]')
parser.add_argument('--max-hier-removal', type=int, default=0,
                    help='Maximum amount of hierarchical removals to carry '
                         'out when hierarchical removal is desired. Choose '
                         '0 for no hierarchical removal. Choose 1 for do at '
                         'most 1 hierarchical removal, and so on. The code '
                         'will write the triggers out for whatever comes '
                         'first: that there are no more hierarchical removals '
                         'to do or write the triggers for the max '
                         'hierarchical removal stage selected. [default=0] ')
parser.add_argument('--output-file')
args = parser.parse_args()
pycbc.init_logging(args.verbose)

# Require that the user does not input negative number of iterations to
# hierarchically remove foreground triggers. This is required for a later
# hack in the while loop if the user wants to do continuous hierarchical
# removal.
if args.max_hier_removal < 0:
   logging.warn('ERROR: Cannot hierarchically remove triggers %s '
                'times.' % args.max_hier_removal)
   logging.warn('Exiting.')
   sys.exit()

# Set an index to keep track of how many hiearrchical removals we want to do.
# This number will be used to keep track of which inclusive background we are
# writing to file
h_iterations = 0

logging.info("Loading coinc triggers")    
all_trigs = pycbc.io.StatmapData(files=args.coinc_files)

logging.info("We have %s triggers" % len(all_trigs.stat))
fore_locs = all_trigs.timeslide_id == 0

# array of foreground trigger times for ifo 
fore_time1 = all_trigs.time1[fore_locs]
fore_time2 = all_trigs.time2[fore_locs]

# array of average times of triggers from ifo1 and ifo2
ave_fore_time = (fore_time1 + fore_time2) / 2.0

# veto start and end time around every average foreground trigger time to
# window around.
veto_start_time = ave_fore_time - args.veto_window
veto_end_time = ave_fore_time + args.veto_window

# The time contained between segments around the times contained
# between each element of veto_start_time and veto_end_time

veto_time = abs(veto.start_end_to_segments(veto_start_time,
                                           veto_end_time).coalesce())

# Veto indices from list of triggers for times in ifo 1 around the 
# window times
veto_indices1 = veto.indices_within_times(all_trigs.time1, veto_start_time,
                                          veto_end_time) 

# Remove any zerolag triggers and get all exclusive background triggers
exc_zero_trigs = all_trigs.remove(veto_indices1)

# Veto indices from list of triggers for times in ifo 1 around the 
# window gps times
veto_indices2 = veto.indices_within_times(exc_zero_trigs.time2,
                                          veto_start_time, veto_end_time)

# Remove any coincident trigger pairs from the data set that could be in
# coincidence with other coincident triggers (by the light travel time +
# some padding indicated by veto-window) from ifo1 to average ifo.
exc_zero_trigs = exc_zero_trigs.remove(veto_indices2)

logging.info("Clustering coinc triggers (inclusive of zerolag)")
all_trigs = all_trigs.cluster(args.cluster_window)

# Return an array of true or false if the trigger has not been
# time-slid
fore_locs = all_trigs.timeslide_id == 0
logging.info("%s clustered foreground triggers" % fore_locs.sum())

logging.info("Clustering coinc triggers (exclusive of zerolag)")
exc_zero_trigs = exc_zero_trigs.cluster(args.cluster_window)

# If a particular index of all_trigs.timeslide_id isn't 0, evaluate true.
# So this returns an array of Booleans.
back_locs = all_trigs.timeslide_id != 0

logging.info("Dumping foreground triggers")
f = fw(args.output_file)
f.attrs['detector_1'] = all_trigs.attrs['detector_1']
f.attrs['detector_2'] = all_trigs.attrs['detector_2']
f.attrs['timeslide_interval'] = all_trigs.attrs['timeslide_interval']

# Parse h_iterations to a string so we can use it later
h_iter_string = str(h_iterations)
# Copy over the segment for coincs and singles
for key in all_trigs.seg.keys():
    f['segments_h_iter' + h_iter_string + '/%s/start' % key] = all_trigs.seg[key]['start'][:]
    f['segments_h_iter' + h_iter_string + '/%s/end' % key] = all_trigs.seg[key]['end'][:]

if fore_locs.sum() > 0:
    f['segments_h_iter' + h_iter_string + '/foreground_veto/start'] = veto_start_time
    f['segments_h_iter' + h_iter_string + '/foreground_veto/end'] = veto_end_time
    for k in all_trigs.data:
        f['foreground_h_iter' + h_iter_string + '/' + k] = all_trigs.data[k][fore_locs]
else:
    # Put SOMETHING in here to avoid failures later
    f['segments_h_iter' + h_iter_string + '/foreground_veto/start'] = numpy.array([0])
    f['segments_h_iter' + h_iter_string + '/foreground_veto/end'] = numpy.array([0])
    for k in all_trigs.data:
        f['foreground_h_iter/' + k] = numpy.array([], dtype=all_trigs.data[k].dtype)

# If the sum of all Booleans in the array (1 = True, 0 = False) is False,
# then there aren't any background triggers. So leave!
if (back_locs.sum()) == 0:
    logging.warn("There were no background events, so we could not assign "
                 "any statistic values")
    sys.exit()

logging.info("Dumping background triggers (inclusive of zerolag)")
for k in all_trigs.data:
    f['background_h_iter' + h_iter_string + '/' + k] = all_trigs.data[k][back_locs]
    
logging.info("Dumping background triggers (exclusive of zerolag)")   
for k in exc_zero_trigs.data:
    f['background_exc/' + k] = exc_zero_trigs.data[k]

maxtime = max(all_trigs.attrs['foreground_time1'], all_trigs.attrs['foreground_time2'])
mintime = min(all_trigs.attrs['foreground_time1'], all_trigs.attrs['foreground_time2'])

maxtime_exc = maxtime - veto_time
mintime_exc = mintime - veto_time

background_time = int(maxtime / all_trigs.attrs['timeslide_interval']) * mintime
coinc_time = float(all_trigs.attrs['coinc_time'])

background_time_exc = int(maxtime_exc / all_trigs.attrs['timeslide_interval']) * mintime_exc
coinc_time_exc = coinc_time - veto_time

logging.info("Making mapping from FAN to the combined statistic")

# Assign vars to arrays of ranking statistics for back_locs and fore_locs?
back_stat = all_trigs.stat[back_locs]
fore_stat = all_trigs.stat[fore_locs]

# Write the cumulative array of inclusive background triggers and the number
# of inclusive background triggers above each foreground trigger.
back_cnum, fnlouder = coinc.calculate_n_louder(back_stat, fore_stat, 
                                               all_trigs.decimation_factor[back_locs])

# Write the cumulative array of exclusive background triggers and the number
# of exclusive background triggers above each foreground trigger.
back_cnum_exc, fnlouder_exc = coinc.calculate_n_louder(exc_zero_trigs.stat,
                                                       fore_stat,
                                                       exc_zero_trigs.decimation_factor)

f['background_h_iter' + h_iter_string + '/ifar'] = sec_to_year(background_time / (back_cnum + 1))  
f['background_exc/ifar'] = sec_to_year(background_time_exc / (back_cnum_exc + 1))

f.attrs['background_time_h_iter' + h_iter_string] = background_time

f.attrs['foreground_time_h_iter' + h_iter_string] = coinc_time
f.attrs['background_time_exc'] = background_time_exc
f.attrs['foreground_time_exc'] = coinc_time_exc

logging.info("calculating ifar/fap values")

if fore_locs.sum() > 0:
    ifar = background_time / (fnlouder + 1)
    fap = 1 - numpy.exp(- coinc_time / ifar)
    f['foreground_h_iter' + h_iter_string + '/ifar'] = sec_to_year(ifar)
    f['foreground_h_iter' + h_iter_string + '/fap'] = fap

    ifar_exc = background_time_exc / (fnlouder_exc + 1)
    fap_exc = 1 - numpy.exp(- coinc_time_exc / ifar_exc)
    f['foreground/ifar_exc'] = sec_to_year(ifar_exc)
    f['foreground/fap_exc'] = fap_exc
else:
    f['foreground_h_iter' + h_iter_string + '/ifar'] = numpy.array([])
    f['foreground_h_iter' + h_iter_string + '/fap'] = numpy.array([])
    f['foreground_h_iter' + h_iter_string + '/ifar_exc'] = numpy.array([])
    f['foreground_h_iter' + h_iter_string + '/fap_exc'] = numpy.array([])

if 'name' in all_trigs.attrs:
    f.attrs['name'] = all_trigs.attrs['name']

# Incorporate hierarchical removal for any other loud triggers
logging.info("Beginning hierarchical removal of foreground triggers, "
             "if necessary.")

# Step 1: Check to see if there are triggers that are louder
#         then all of the inclusive background.

# fnlouder is the number of background events that are louder than
# the foreground trigger. So if a trigger is louder than all of
# the background, fnlouder = 0.

loud_t_ind = []
for i in range(0, len(fnlouder)):
    if fnlouder[i] == 0:
        loud_t_ind.append(i)

# Create arrays to save far and fap of hierarchically removed
# foreground triggers

save_ifar_fore_trig = np.array([], dtype=float)
save_fap_fore_trig = np.array([], dtype=float)
save_these_fore_ind = np.array([], dtype=int)

# Use a copy of the original triggers befpre hierarchical removal
# to regenerate hierarchically removed foreground triggers
copy_trigs = pycbc.io.StatmapData(all_trigs.data, all_trigs.seg,
                                  all_trigs.attrs)

# Step 2 : Loop until we don't have to hierarchically remove
#          anymore.

while len(loud_t_ind) > 0:
    # If the user wants to stop doing hierarchical removals after a set
    # number of iterations then break when the h_iterations gets to that
    # number

    if (args.cont_hier_removal == 'store_false' and
        h_iterations == args.max_hier_removal): 
        logging.warn("Hierarchical removal can continue but user has set"
                     "--max-hier-removal too low!")
        break

    # We've done a hierarchical removal so add the iteration number to the
    # next one. Parse that to a string for later use too.
    h_iterations += 1
    h_iter_string = str(h_iterations)

    # Find the loudest of these triggers, its index, its newsnr
    # We know that the IFARs of these triggers are all louder
    # than the inclusive background
    max_ifar_ind = loud_t_ind[0]
    for i in range(0, len(loud_t_ind)):
        # Check to see which of these louder than all of the background
        # foreground triggers has the greatest snr. We will assign this
        # location the "max_ifar_ind" and remove that trigger first.
        if fore_stat[loud_t_ind[i]] > fore_stat[max_ifar_ind]:
            max_ifar_ind = loud_t_ind[i]

    # Step 3: Remove that trigger from the list of zerolag triggers

    # Store where the loud foreground trigger that I want to remove next in the
    # list of all of the triggers located is at
    where_is_fore_t = np.where(all_trigs.stat[:] == fore_stat[max_ifar_ind])

    # FIXME:
    # In the RARE case that there are two equally loud
    # louder-than-the-background foreground triggers give preference
    # to the one with the earliest GPS time, just for documenting purposes
    if len(where_is_fore_t[0]) > 1:
        # where_is_fore_t[0] = np.argsort(all_trigs.time1[where_is_fore_t[0][:]])
        logging.warn("WARNING: There is more than one foreground trigger "
                     " that is louder than the background and have the same "
                     "ranking statistic. This code may operate strangely in"
                     "this condition.")

    # This is the foreground trigger index in the all_trigs array that we
    # want to remove
    my_loudest_ind = where_is_fore_t[0][0]

    # Store any foreground trigger's information that we want to
    # hierarchically remove. Below save the ifar.

    save_ifar_fore_trig = np.append(save_ifar_fore_trig, ifar[max_ifar_ind])
    # The following equation should be safe bcause coinc_time
    # will only be reassigned after we remove this trigger for the
    # next quietest louder-than-the-inclusive-background foreground
    # trigger.
    save_fap_fore_trig = np.append(save_fap_fore_trig, \
                                   1 - numpy.exp(- coinc_time / ifar[max_ifar_ind]))

    # Save the location in the foreground trigger array too
    save_these_fore_ind = np.append(save_these_fore_ind, max_ifar_ind)

    logging.info("Removing foreground trigger that is louder than the inclusive background.")

    # Remove this foreground trigger from the list of loud foreground triggers
    loud_t_ind.remove(max_ifar_ind)

    # Remove the foreground trigger AND all of the inclusive background
    # triggers that are associated with it via the timeslides.

    ind_to_rm_ifo1 = veto.indices_within_times(all_trigs.time1, \
                              [all_trigs.time1[my_loudest_ind] - args.veto_window_hierarch], \
                              [all_trigs.time1[my_loudest_ind] + args.veto_window_hierarch])
    ind_to_rm_ifo2 = veto.indices_within_times(all_trigs.time2, \
                              [all_trigs.time2[my_loudest_ind] - args.veto_window_hierarch], \
                              [all_trigs.time2[my_loudest_ind] + args.veto_window_hierarch])
    indices_to_rm = np.concatenate([ind_to_rm_ifo1, ind_to_rm_ifo2])

    all_trigs = all_trigs.remove(indices_to_rm)

    fore_locs = all_trigs.timeslide_id == 0

    # Calculate the change to foreground trigger time and vetoed out time
    fore_time1 = all_trigs.time1[fore_locs]
    fore_time2 = all_trigs.time2[fore_locs]

    ave_fore_time = (fore_time1 + fore_time2) / 2.0

    veto_start_time = ave_fore_time - args.veto_window
    veto_end_time = ave_fore_time + args.veto_window

    logging.info("We have %s triggers after hierarchical removal." % len(all_trigs.stat))

    # Step 4: Re cluster the triggers and calculate the far/ifar/fap
    #         inclusive and exclusive.
    #         The following lines are uncommented because they are copy paste
    #         from above.
    logging.info("Clustering coinc triggers (inclusive of zerolag)")
    all_trigs = all_trigs.cluster(args.cluster_window)
    
    fore_locs = all_trigs.timeslide_id == 0

    logging.info("%s clustered foreground triggers" % fore_locs.sum())

    logging.info("%s hierarchically removed foreground trigger"
                  % len(save_these_fore_ind))

    back_locs = all_trigs.timeslide_id != 0 

    logging.info("Dumping foreground triggers")

    for key in all_trigs.seg.keys():
        f['segments_h_iter' + h_iter_string + '/%s/start' % key] = all_trigs.seg[key]['start'][:]
        f['segments_h_iter' + h_iter_string + '/%s/end' % key] = all_trigs.seg[key]['end'][:]

    if fore_locs.sum() > 0:
        f['segments_h_iter' + h_iter_string + '/foreground_veto/start'] = veto_start_time
        f['segments_h_iter' + h_iter_string + '/foreground_veto/end'] = veto_end_time
        for k in all_trigs.data:
            f['foreground_h_iter' + h_iter_string + '/' + k] = all_trigs.data[k][fore_locs]
    else:
         f['segments_h_iter' + h_iter_string + '/foreground_veto/start'] = numpy.array([0])
         f['segments_h_iter' + h_iter_string + '/foreground_veto/end'] = numpy.array([0])
         for k in all_trigs.data:
             f['foreground_h_iter' + h_iter_string + '/' + k] = numpy.array([], dtype=all_trigs.data[k].dtype)

    if (back_locs.sum()) == 0:
         logging.warn("There were no background events, so we could not assign "
                      "any statistic values")
         sys.exit()

    logging.info("Dumping background triggers (inclusive of zerolag)")
    for k in all_trigs.data:
         f['background_h_iter' + h_iter_string + '/' + k] = all_trigs.data[k][back_locs]

    maxtime = max(all_trigs.attrs['foreground_time1'], all_trigs.attrs['foreground_time2'])
    mintime = min(all_trigs.attrs['foreground_time1'], all_trigs.attrs['foreground_time2'])

    background_time = int(maxtime / all_trigs.attrs['timeslide_interval']) * mintime
    coinc_time = float(all_trigs.attrs['coinc_time'])

    logging.info("Making mapping from FAN to the combined statistic")

    back_stat = all_trigs.stat[back_locs]
    fore_stat = all_trigs.stat[fore_locs]

    back_cnum, fnlouder = coinc.calculate_n_louder(back_stat, fore_stat, 
                                                   all_trigs.decimation_factor[back_locs])

    logging.info("Calculating ifar/fap values")

    f['background_h_iter' + h_iter_string + '/ifar'] = sec_to_year(background_time / (back_cnum + 1))
    f.attrs['background_time_h_iter' + h_iter_string] = background_time
    f.attrs['foreground_time_h_iter' + h_iter_string] = coinc_time

    if fore_locs.sum() > 0:
        ifar = background_time / (fnlouder + 1)
        fap = 1 - numpy.exp(- coinc_time / ifar)

        f['foreground_h_iter' + h_iter_string + '/ifar'] = sec_to_year(ifar)
        f['foreground_h_iter' + h_iter_string + '/fap'] = fap

    # Repopulate the list of foreground indices for the loudest events 
    loud_t_ind = []
    for i in range(0, len(fnlouder)):
        if fnlouder[i] == 0:
            loud_t_ind.append(i)

# End of the while loop, now take all of the information and write it back in
# to file the way that other codes downstream know how to read.
logging.info("Writing final calculations to file")

for key in all_trigs.seg.keys():
    f['segments/%s/start' % key] = f['segments_h_iter0/%s/start' % key]
    f['segments/%s/end' % key] = f['segments_h_iter0/%s/end' % key]

# If there were hierarchically removed foreground triggers, please  write
# them back into the file with the correct statistics.
if len(save_these_fore_ind) > 0:
#   CONTROVERSIAL: Which one do I write here? It won't match if I write the background
#   back for the last iteration. I don't know what to use.
    f['segments/foreground_veto/start'] = f['segments_h_iter0/foreground_veto/start']
    f['segments/foreground_veto/end'] =  f['segments_h_iter0/foreground_veto/end']
    for k in copy_trigs.data:
        f['foreground/' + k] = f['foreground_h_iter0/' + k]
 
    # We won't run into trouble inserting the foreground triggers back in
    # if we insert them in from least to greatest. Otherwise we could really
    # mess up the ordering of assigning the proper ifar to every foreground
    # trigger. So we need to preserve the original ordering!
    sort_like_this = numpy.argsort(save_these_fore_ind)
    save_these_fore_ind = save_these_fore_ind[sort_like_this]
    save_ifar_fore_trig = save_ifar_fore_trig[sort_like_this]
    save_fap_fore_trig = save_fap_fore_trig[sort_like_this]

    for i in range(0, len(save_these_fore_ind)):
        # Handle the edge case that you have to add to the end of the list
        # if your array of ifar has gotten too small
        if save_these_fore_ind[i] > len(ifar):
            ifar = np.append(ifar, save_ifar_fore_trig[i])
        else :
            ifar = np.insert(ifar, save_these_fore_ind[i] + i, save_ifar_fore_trig[i])
        if save_these_fore_ind[i] > len(fap):
            fap = np.append(fap, save_fap_fore_trig[i])
        else :
            fap = np.insert(fap, save_these_fore_ind[i] + i, save_fap_fore_trig[i])

    f['foreground/ifar'] = sec_to_year(ifar)
    f['foreground/fap'] = fap

# If we didn't do any hierarchical removal write out the foreground information
# This also works in the case that there were not any foreground triggers.
else :
    f['segments/foreground_veto/start'] = f['segments_h_iter0/foreground_veto/start']
    f['segments/foreground_veto/end'] =  f['segments_h_iter0/foreground_veto/end']
    for k in all_trigs.data:
        f['foreground/' + k] = f['foreground_h_iter0/' + k]
    f['foreground/ifar'] = f['foreground_h_iter0/ifar']
    f['foreground/fap'] = f['foreground_h_iter0/fap']

# Write the values of the last h_iteration for the background and everything else too.
# CONTROVERSIAL: Which one do I write to file?
for k in all_trigs.data:
    f['background/' + k] = f['background_h_iter' + h_iter_string + '/' +k]

f['background/ifar'] = f['background_h_iter' + h_iter_string + '/ifar']
f.attrs['background_time'] = f.attrs['background_time_h_iter' + h_iter_string]

# This is controversial, if all of the foreground times are put back in
# I have write the coinc_time from h_iterations = 0.
f.attrs['foreground_time'] = f.attrs['foreground_time_h_iter0']

# Write to file how many hierarchical removals were implemented, this number
# will be used in the plotting code downstream.

f['hierarchical_removal_iterations'] = np.array([h_iterations])

f.close()
logging.info("Done") 
