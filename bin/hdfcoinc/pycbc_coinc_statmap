#!/usr/bin/env python
"""
The program combines coincident output files generated
by pycbc_coinc_findtrigs to generated a mapping between SNR and FAP, along
with producing the combined foreground and background triggers. It also has 
the capability of doing hierarchical removal of foreground triggers that are 
louder than all of the background triggers. We use this to properly assess 
the FANs of any other gravitational waves in the dataset.
"""
import sys
import argparse, h5py, logging, itertools, numpy
import lal
import numpy as np
from pycbc.events import veto, coinc
import pycbc.version, pycbc.pnutils, pycbc.io

def sec_to_year(sec):
    return sec / lal.YRJUL_SI

class fw(object):
    def __init__(self, name):
        self.f = h5py.File(name, 'w')
        self.attrs = self.f.attrs

    def __setitem__(self, name, data):
        # Make a new item if isn't in the hdf file
        if not name in self.f:
            self.f.create_dataset(name, data=data, compression="gzip",
                                  compression_opts=9, shuffle=True,
                                  maxshape=data.shape)
        # Else re-size that section and reassign values
        else:
            self.f[name].resize(data.shape)
            self.f[name][:] = data

    def __getitem__(self, *args):
        return self.f.__getitem__(*args)

    def close(self):
        self.f.close()

parser = argparse.ArgumentParser()
# General required options
parser.add_argument('--version', action='version', 
                    version=pycbc.version.git_verbose_msg)
parser.add_argument('--coinc-files', nargs='+', 
                    help='List of coincidence files used to calculate the '
                         'FAP, FAR, etc.')
parser.add_argument('--verbose', action='count')
parser.add_argument('--cluster-window', type=float, default=10,
                    help='Length of time window in seconds to cluster coinc '
                         'events, [default=10s]')
parser.add_argument('--veto-window', type=float, default=.1,
                    help='Time around each zerolag trigger to window out, '
                         '[default=.1s]')
parser.add_argument('--veto-window-hierarch', type=float, default=1.0,
                    help='Time around each trigger to window out for a very '
                         'louder trigger in the hierarchical removal '
                         'procedure.')
parser.add_argument('--max-hier-removal', type=int, default=0,
                    help='Maximum amount of hierarchical removals to carry '
                         'out when hierarchical removal is desired. Choose '
                         '0 for no hierarchical removal. Choose 1 for do at '
                         'most 1 hierarchical removal, and so on. The code '
                         'will write the triggers out for whatever comes '
                         'first: that there are no more hierarchical removals '
                         'to do or write the triggers for the max '
                         'hierarchical removal stage selected. [default=0] ')
parser.add_argument('--output-file')
args = parser.parse_args()
pycbc.init_logging(args.verbose)

logging.info("Loading coinc triggers")    
all_trigs = pycbc.io.StatmapData(files=args.coinc_files)
logging.info("We have %s triggers" % len(all_trigs.stat))
fore_locs = all_trigs.timeslide_id == 0

# array of foreground trigger times for ifo 
fore_time1 = all_trigs.time1[fore_locs]
fore_time2 = all_trigs.time2[fore_locs]

# array of average times of triggers from ifo1 and ifo2
ave_fore_time = (fore_time1 + fore_time2) / 2.0

# veto start and end time around every average foreground trigger time to
# window around.
veto_start_time = ave_fore_time - args.veto_window
veto_end_time = ave_fore_time + args.veto_window

# The time contained between segments around the times contained
# between each element of veto_start_time and veto_end_time

veto_time = abs(veto.start_end_to_segments(veto_start_time,
                                           veto_end_time).coalesce())

# Veto indices from list of triggers for times in ifo 1 around the 
# window times
veto_indices1 = veto.indices_within_times(all_trigs.time1, veto_start_time,
                                          veto_end_time) 

# Remove any zerolag triggers and get all exclusive background triggers
exc_zero_trigs = all_trigs.remove(veto_indices1)

# Veto indices from list of triggers for times in ifo 1 around the 
# window gps times
veto_indices2 = veto.indices_within_times(exc_zero_trigs.time2,
                                          veto_start_time, veto_end_time)

# Remove any coincident trigger pairs from the data set that could be in
# coincidence with other coincident triggers (by the light travel time +
# some padding indicated by veto-window) from ifo1 to average ifo.
exc_zero_trigs = exc_zero_trigs.remove(veto_indices2)

logging.info("Clustering coinc triggers (inclusive of zerolag)")
all_trigs = all_trigs.cluster(args.cluster_window)

# Return an array of true or false if the trigger has not been
# time-slid
fore_locs = all_trigs.timeslide_id == 0
logging.info("%s clustered foreground triggers" % fore_locs.sum())

logging.info("Clustering coinc triggers (exclusive of zerolag)")
exc_zero_trigs = exc_zero_trigs.cluster(args.cluster_window)

# If a particular index of all_trigs.timeslide_id isn't 0, evaluate true.
# So this returns an array of Booleans.
back_locs = all_trigs.timeslide_id != 0

logging.info("Dumping foreground triggers")
f = fw(args.output_file)
f.attrs['detector_1'] = all_trigs.attrs['detector_1']
f.attrs['detector_2'] = all_trigs.attrs['detector_2']
f.attrs['timeslide_interval'] = all_trigs.attrs['timeslide_interval']

# Copy over the segment for coincs and singles
for key in all_trigs.seg.keys():
    f['segments/%s/start' % key] = all_trigs.seg[key]['start'][:]
    f['segments/%s/end' % key] = all_trigs.seg[key]['end'][:]

if fore_locs.sum() > 0:
    f['segments/foreground_veto/start'] = veto_start_time
    f['segments/foreground_veto/end'] = veto_end_time
    for k in all_trigs.data:
        f['foreground/' + k] = all_trigs.data[k][fore_locs]
else:
    # Put SOMETHING in here to avoid failures later
    f['segments/foreground_veto/start'] = numpy.array([0])
    f['segments/foreground_veto/end'] = numpy.array([0])
    for k in all_trigs.data:
        f['foreground/' + k] = numpy.array([], dtype=all_trigs.data[k].dtype)

# If the sum of all Booleans in the array (1 = True, 0 = False) is False,
# then there aren't any background triggers. So leave!
if (back_locs.sum()) == 0:
    logging.warn("There were no background events, so we could not assign "
                 "any statistic values")
    sys.exit()

logging.info("Dumping background triggers (inclusive of zerolag)")
for k in all_trigs.data:
    f['background/' + k] = all_trigs.data[k][back_locs]
    
logging.info("Dumping background triggers (exclusive of zerolag)")   
for k in exc_zero_trigs.data:
    f['background_exc/' + k] = exc_zero_trigs.data[k]

maxtime = max(all_trigs.attrs['foreground_time1'], all_trigs.attrs['foreground_time2'])
mintime = min(all_trigs.attrs['foreground_time1'], all_trigs.attrs['foreground_time2'])

maxtime_exc = maxtime - veto_time
mintime_exc = mintime - veto_time

background_time = int(maxtime / all_trigs.attrs['timeslide_interval']) * mintime
coinc_time = float(all_trigs.attrs['coinc_time'])

background_time_exc = int(maxtime_exc / all_trigs.attrs['timeslide_interval']) * mintime_exc
coinc_time_exc = coinc_time - veto_time

logging.info("Making mapping from FAN to the combined statistic")

# Assign vars to arrays of ranking statistics for back_locs and fore_locs?
back_stat = all_trigs.stat[back_locs]
fore_stat = all_trigs.stat[fore_locs]

# Write the cumulative array of inclusive background triggers and the number
# of inclusive background triggers above each foreground trigger.
back_cnum, fnlouder = coinc.calculate_n_louder(back_stat, fore_stat, 
                                               all_trigs.decimation_factor[back_locs])

# Write the cumulative array of exclusive background triggers and the number
# of exclusive background triggers above each foreground trigger.
back_cnum_exc, fnlouder_exc = coinc.calculate_n_louder(exc_zero_trigs.stat,
                                                       fore_stat,
                                                       exc_zero_trigs.decimation_factor)

f['background/ifar'] = sec_to_year(background_time / (back_cnum + 1))  
f['background_exc/ifar'] = sec_to_year(background_time_exc / (back_cnum_exc + 1))

f.attrs['background_time'] = background_time
f.attrs['foreground_time'] = coinc_time
f.attrs['background_time_exc'] = background_time_exc
f.attrs['foreground_time_exc'] = coinc_time_exc

logging.info("calculating ifar/fap values")

if fore_locs.sum() > 0:
    ifar = background_time / (fnlouder + 1)
    fap = 1 - numpy.exp(- coinc_time / ifar)
    f['foreground/ifar'] = sec_to_year(ifar)
    f['foreground/fap'] = fap

    ifar_exc = background_time_exc / (fnlouder_exc + 1)
    fap_exc = 1 - numpy.exp(- coinc_time_exc / ifar_exc)
    f['foreground/ifar_exc'] = sec_to_year(ifar_exc)
    f['foreground/fap_exc'] = fap_exc
else:
    f['foreground/ifar'] = numpy.array([])
    f['foreground/fap'] = numpy.array([])
    f['foreground/ifar_exc'] = numpy.array([])
    f['foreground/fap_exc'] = numpy.array([])

if 'name' in all_trigs.attrs:
    f.attrs['name'] = all_trigs.attrs['name']

# Incorporate hierarchical removal for any other loud triggers
logging.info("Instantiating hierarchical removal.")

# Step 1: Check to see if the trigger with the largest FAR is
#         louder than all of the background.
# fnlouder is the number of background events that are louder than
# the foreground trigger. So if a trigger is louder than all of
# the background, fnlouder = 0.

loud_t_ind = []
count_ind = -1
for i in range(0, len(fnlouder)):
    if fnlouder[i] == 0:
        loud_t_ind.append(i)
        count_ind += 1

# Step 2 : Loop until we don't have to hierarchically remove
#          anymore.
iter = 1
while len(loud_t_ind) > 0 and iter <= args.max_hier_removal :
    # find the loudest of these triggers, its index, its newsnr
    # and its ifar
    max_ifar = 0
    max_ifar_ind = 0
    max_rank_stat = 0
    for i in range(0, len(loud_t_ind)):
         # Check for the largest ifar
         if ifar[loud_t_ind[i]] >= max_ifar:
           # Check to see if they have equal ifar, then check largest
           # ranking statistic
              if ifar[loud_t_ind[i]] == max_ifar:
                   if back_stat[loud_t_ind[i]] >= \
                      back_stat[loud_t_ind[max_ifar_ind]] :
                        max_ifar_ind = loud_t_ind[i]
                        max_rank_stat = back_stat[loud_t_ind[i]]
                   else :
                        max_rank_stat = back_stat[max_ifar_ind]
                        
              else :
                   max_ifar = ifar[loud_t_ind[i]]
                   max_ifar_ind = loud_t_ind[i]
    # Step 3: Remove that trigger from the list of zerolag triggers

    # FIXME:If the trigger is really the loudest trigger in the bin, then it's
    # ranking statistic is the largest and also unique (I think).
    where_is_fore_t = np.where(all_trigs.stat[:] == fore_stat[max_ifar_ind])

    if len(where_is_fore_t[0]) > 1:
         print "The author of this hierarchical removal is not a good ", \
               "programmer. He is looking for a mapping from loudest ", \
               "foreground trigger to the array of all triggers and ", \
               "he assumes that there's only one matching SNR trigger ", \
               "so this code's going to break."

    my_loudest_ind = where_is_fore_t[0][0]

    logging.info("Removing foreground trigger that is louder than the inclusive background.")
    loud_t_ind.remove(max_ifar_ind)

    # Remove the foreground trigger AND all of the inclusive background
    # triggers that are associated with it via the timeslides.

    ind_to_rm_ifo1 = veto.indices_within_times(all_trigs.time1, \
                              [all_trigs.time1[my_loudest_ind] - args.veto_window_hierarch], \
                              [all_trigs.time1[my_loudest_ind] + args.veto_window_hierarch])
    ind_to_rm_ifo2 = veto.indices_within_times(all_trigs.time2, \
                              [all_trigs.time2[my_loudest_ind] - args.veto_window_hierarch], \
                              [all_trigs.time2[my_loudest_ind] + args.veto_window_hierarch])
    indices_to_rm = np.concatenate([ind_to_rm_ifo1, ind_to_rm_ifo2])

    all_trigs = all_trigs.remove(indices_to_rm)

    logging.info("We have %s triggers after hierarchical removal." % len(all_trigs.stat))

# Step 4: Re cluster the triggers and calculate the far/ifar/fap
#         inclusive and exclusive.
#         The following lines are uncommented because they are copy paste
#         from above.
    logging.info("Clustering coinc triggers (inclusive of zerolag)")
    all_trigs = all_trigs.cluster(args.cluster_window)
    
    fore_locs = all_trigs.timeslide_id == 0

    logging.info("%s clustered foreground triggers" % fore_locs.sum())

    back_locs = all_trigs.timeslide_id != 0 

    logging.info("Dumping foreground triggers")

    for key in all_trigs.seg.keys():
         f['segments/%s/start' % key] = all_trigs.seg[key]['start'][:]
         f['segments/%s/end' % key] = all_trigs.seg[key]['end'][:]

    if fore_locs.sum() > 0:
         for k in all_trigs.data:
              f['foreground/' + k] = all_trigs.data[k][fore_locs]
    else:
         f['segments/foreground_veto/start'] = numpy.array([0])
         f['segments/foreground_veto/end'] = numpy.array([0])
         for k in all_trigs.data:
             f['foreground/' + k] = numpy.array([], dtype=all_trigs.data[k].dtype)

    if (back_locs.sum()) == 0:
         logging.warn("There were no background events, so we could not assign "
                      "any statistic values")
         sys.exit()

    logging.info("Dumping background triggers (inclusive of zerolag)")
    for k in all_trigs.data:
         f['background/' + k] = all_trigs.data[k][back_locs]


    maxtime = max(all_trigs.attrs['foreground_time1'], all_trigs.attrs['foreground_time2'])
    mintime = min(all_trigs.attrs['foreground_time1'], all_trigs.attrs['foreground_time2'])

    background_time = int(maxtime / all_trigs.attrs['timeslide_interval']) * mintime
    coinc_time = float(all_trigs.attrs['coinc_time'])

    logging.info("Making mapping from FAN to the combined statistic")

    back_stat = all_trigs.stat[back_locs]
    fore_stat = all_trigs.stat[fore_locs]

    back_cnum, fnlouder = coinc.calculate_n_louder(back_stat, fore_stat, 
                                                   all_trigs.decimation_factor[back_locs])

    logging.info("Calculating ifar/fap values")

    f['background/ifar'] = sec_to_year(background_time / (back_cnum + 1))

    f.attrs['background_time'] = background_time
    f.attrs['foreground_time'] = coinc_time

    if fore_locs.sum() > 0:
        ifar = background_time / (fnlouder + 1)
        fap = 1 - numpy.exp(- coinc_time / ifar)

        f['foreground/ifar'] = sec_to_year(ifar)
        f['foreground/fap'] = fap

    # Repopulate the list of foreground indices for the loudest events 
    loud_t_ind = []
    count_ind = -1
    for i in range(0, len(fnlouder)):
        if fnlouder[i] == 0:
            loud_t_ind.append(i)
            count_ind += 1

    # We've done a hierarchical removal so add the iteration number to the
    # next one.
    iter += 1

f.close()
logging.info("Done") 
