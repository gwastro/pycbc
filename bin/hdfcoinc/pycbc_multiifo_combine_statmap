#!/bin/env python
""" Apply a naive mass binning, assuming that each bin is fully independent, which 
is a conservative estimate. This clusters to find the most significant foreground, but
leaves the background triggers alone. """

import h5py, numpy, argparse, logging, pycbc, pycbc.events, lal
import pycbc.version
import matplotlib as mpl
mpl.use('agg')
import matplotlib.pyplot as plt

def com(f, files, group):
    """ Combine the same column from multiple files and save to a third"""
    f[group] = numpy.concatenate([fi[group][:] if group in fi else numpy.array([], dtype=numpy.uint32) for fi in files])

def all_keys_set(files):
    key_set = []
    for f in files:
        for k in f.keys():
            if isinstance(f[k], h5py.Dataset):
                key_set.append(k)
            else:
                key_set += get_all_subkeys(f,k)
    return set(key_set)

def get_all_subkeys(f,k):
    subkey_set = []
    for sk in f[k].keys():
        if isinstance(f[k+'/'+sk], h5py.Dataset):
            subkey_set.append(k+'/'+sk)
        else:
            subkey_set += get_all_subkeys(f,k+'/'+sk)
    return subkey_set

parser = argparse.ArgumentParser()
parser.add_argument("--version", action="version", version=pycbc.version.git_verbose_msg)
parser.add_argument('--verbose', action='store_true')
parser.add_argument('--statmap-files', nargs='+',
                    help="List of coinc files to be redistributed")
parser.add_argument('--cluster-window', type=float)
parser.add_argument('--output-file', help="name of output file")
parser.add_argument('--ifos',nargs='+', 
                    help="Interferometers")
parser.add_argument('--plot-output')
args = parser.parse_args()

pycbc.init_logging(args.verbose)

# We apply a dumb factor of the number of bins only, nothing smart for now, 
# no clustering of the background
files = [h5py.File(n,'r') for n in args.statmap_files]

fac = len(args.statmap_files)

# copy over the standard data that is constant
#TODO: This is no longer constant between files
f = h5py.File(args.output_file, "w")
f.attrs['pivot'] = files[0].attrs['pivot']
f.attrs['fixed'] = files[0].attrs['fixed']
f.attrs['timeslide_interval'] = files[0].attrs['timeslide_interval']

f.attrs['background_time'] = files[0].attrs['background_time']
f.attrs['foreground_time'] = files[0].attrs['foreground_time']
f.attrs['background_time_exc'] = files[0].attrs['background_time_exc']
f.attrs['foreground_time_exc'] = files[0].attrs['foreground_time_exc']


# combine times that are foreground vetoed as they may differ between bins
#TODO: apply logic similar to foreground triggers below for the segments (may be able to make this modular)
for key in files[0]['segments']:
    f['segments/%s/start' % key] = files[0]['segments/%s/start' % key][:]
    f['segments/%s/end' % key] = files[0]['segments/%s/end' % key][:]

key_set = all_keys_set(files)
# copy over all the columns in the foreground group from all files /except/ the IFO groups, we recalculate ifar/fap later
for key in key_set:
    if key.startswith('foreground') and not any([ifo in key for ifo in args.ifos]):
        com(f, files, key)


#for the ifo-specific groups, copy them over into the new file - if the ifo is not present for each coincident trigger, indicate by including a -1 in the combined file
trigger_list = []
all_trig_times = {}
all_trig_ids = {}
for ifo in args.ifos:
    all_trig_times[ifo] = numpy.array([], dtype=numpy.uint32)
    all_trig_ids[ifo] = numpy.array([], dtype=numpy.uint32)
# for each file, take the ifos list and see which ifos are present in the file or not
for f_in in files:
    for ifo in args.ifos:
        if ifo in ifo in f_in['foreground']:
            all_trig_times[ifo] = numpy.concatenate([all_trig_times[ifo], f_in['foreground/{}/time'.format(ifo)][:]])
            all_trig_ids[ifo] = numpy.concatenate([all_trig_ids[ifo], f_in['foreground/{}/trigger_id'.format(ifo)][:]])
        else:
            all_trig_times[ifo] = numpy.concatenate([all_trig_times[ifo], -1*numpy.ones_like(f_in['foreground/fap'][:], dtype=numpy.uint32)])
            all_trig_ids[ifo] = numpy.concatenate([all_trig_ids[ifo], -1*numpy.ones_like(f_in['foreground/fap'][:], dtype=numpy.uint32)])

for ifo in args.ifos:
    f['foreground/{}/time'.format(ifo)] = all_trig_times[ifo]
    f['foreground/{}/trigger_id'.format(ifo)] = all_trig_ids[ifo]

# recalculate ifar/fap for the foreground triggers by 
#  applying a trials factor = num_files(num_bins)
ifars = []
ifars_exc = []
faps = []
faps_exc = []
for f_in in files:
    ifar = f_in['foreground/ifar'][:] / fac
    coinc_time = f_in.attrs['foreground_time'] / lal.YRJUL_SI
    ifars = numpy.concatenate([ifars, ifar])
    faps = numpy.concatenate([faps, 1 - numpy.exp( - coinc_time / ifar)])

    ifar_exc = f_in['foreground/ifar_exc'][:] / fac
    coinc_time_exc = f_in.attrs['foreground_time_exc'] / lal.YRJUL_SI
    ifars_exc = numpy.concatenate([ifars_exc, ifar_exc])
    faps_exc = numpy.concatenate([faps_exc, 1 - numpy.exp( - coinc_time_exc / ifar_exc)])

f['foreground/ifar'][:] = ifars
f['foreground/ifar_exc'][:] = ifars_exc
f['foreground/fap'][:] = faps
f['foreground/fap_exc'][:] = faps_exc



# cluster for the loudest ifar value 

def argmax(v):
    return numpy.argsort(v)[-1]

stat = numpy.core.records.fromarrays([f['foreground/ifar'][:], 
                                      f['foreground/stat'][:]],
                                      names='ifar,stat')
cidx = pycbc.events.cluster_coincs(stat,
                                   f['foreground/%s/time' % f.attrs['pivot']][:], 
                                   f['foreground/%s/time' % f.attrs['fixed']][:], 
                                   numpy.zeros(len(ifars)),
                                   0, args.cluster_window, argmax=argmax)

# downsample the foreground columns to only the loudest ifar between the multiple files
for key in f['foreground'].keys():
    if key not in args.ifos:
        print(f['foreground/%s' % key])
        dset = f['foreground/%s' % key][:][cidx]
        del f['foreground/%s' % key]
        f['foreground/%s' % key] = dset
    else:
        for k in  f['foreground/%s' % key].keys():
            print(f['foreground/{}/{}'.format(key,k)])
            dset = f['foreground/{}/{}'.format(key,k)][:][cidx]
            del f['foreground/{}/{}'.format(key,k)]
            f['foreground/{}/{}'.format(key,k)] = dset

# If there is a background set (full_data as opposed to injection run), then recalculate 
# the values for its triggers as well
if 'background' in files[0]:  
    for key in all_keys:
        if key.startswith('background') or key.startswith('background_exc'):
            com(f, files, key)
     
    f['background/ifar'][:] =  f['background/ifar'][:] / fac
    f['background_exc/ifar'][:] = f['background_exc/ifar'][:] / fac

    com(f, files, 'segments/foreground_veto/start')
    com(f, files, 'segments/foreground_veto/end')


f.close()
