#!/bin/env python
""" Apply a trials factor based on the number of available detector combinations at the
time of coincidence. This clusters to find the most significant foreground, but
leaves the background triggers alone. """

import h5py, numpy, argparse, logging, pycbc, pycbc.events, pycbc.io, lal
import pycbc.version


def name_all_datasets(files):
    datasets= []
    for fi in files:
        for k in fi.keys():
            if isinstance(fi[k], h5py.Dataset):
                datasets.append(k)
            else:
                datasets += get_all_subkeys(fi,k)
    return set(datasets)

def get_all_subkeys(fi,k):
    subkey_list = []
    for sk in fi[k].keys():
        if isinstance(fi[k+'/'+sk], h5py.Dataset):
            subkey_list.append(k+'/'+sk)
        else:
            subkey_list += get_all_subkeys(fi,k+'/'+sk)
    # this will return an empty list if there is no dataset or subgroup within the group
    return subkey_list

parser = argparse.ArgumentParser()
parser.add_argument("--version", action="version", version=pycbc.version.git_verbose_msg)
parser.add_argument('--verbose', action='store_true')
parser.add_argument('--statmap-files', nargs='+',
                    help="List of coinc files to be redistributed")
parser.add_argument('--cluster-window', type=float)
parser.add_argument('--output-file', help="name of output file")
parser.add_argument('--ifos',nargs='+', 
                    help="list of interferometers in the input files" )
args = parser.parse_args()

pycbc.init_logging(args.verbose)

files = [h5py.File(n,'r') for n in args.statmap_files]

# move segments information into the final file - remove some duplication in earlier files

f = h5py.File(args.output_file, "w")

for fi in files:
    ifos_in_file = [ifo for ifo in args.ifos if ifo in fi['segments']]
    ifo_to_get = 'segments/{}'.format(ifos_in_file[0])
    ifosstring = ''.join(ifos_in_file)
    group_to_save = 'segments/{}'.format(ifosstring)
    f[group_to_save + '/end'] = fi[ifo_to_get + '/end'][:]
    f[group_to_save + '/start'] = fi[ifo_to_get + '/start'][:]
    #also move the attributes with the given ifo combination indicator
    f.attrs['pivot/{}'.format(ifosstring)] = fi.attrs['pivot']
    f.attrs['fixed/{}'.format(ifosstring)] = fi.attrs['fixed']
    f.attrs['timeslide_interval/{}'.format(ifosstring)] = fi.attrs['timeslide_interval']
    f.attrs['background_time/{}'.format(ifosstring)] = fi.attrs['background_time']
    f.attrs['foreground_time/{}'.format(ifosstring)] = fi.attrs['foreground_time']
    f.attrs['background_time_exc/{}'.format(ifosstring)] = fi.attrs['background_time_exc']
    f.attrs['foreground_time_exc/{}'.format(ifosstring)] = fi.attrs['foreground_time_exc']

    

key_set = name_all_datasets(files)
# copy and concatenate all the columns in the foreground group 
# from all files /except/ the IFO groups, we recalculate ifar/fap later
for key in key_set:
    if key.startswith('foreground') and not any([ifo in key for ifo in args.ifos]):
        pycbc.io.combine_and_copy(f, files, key)


#for the ifo-specific groups, copy them over into the new file
# - if the ifo is not present for each coincident trigger, 
#  indicate by including a '-1' value in the combined file

trigger_list = []
all_trig_times = {}
all_trig_ids = {}
for ifo in args.ifos:
    all_trig_times[ifo] = numpy.array([], dtype=numpy.uint32)
    all_trig_ids[ifo] = numpy.array([], dtype=numpy.uint32)

# for each file, append the trigger time and id data for each ifo
#   - if it isnt there, then fill with -1 values
for f_in in files:
    for ifo in args.ifos:
        if ifo in f_in['foreground']:
            all_trig_times[ifo] = numpy.concatenate([all_trig_times[ifo], \
                                     f_in['foreground/{}/time'.format(ifo)][:]])
            all_trig_ids[ifo] = numpy.concatenate([all_trig_ids[ifo], 
                                     f_in['foreground/{}/trigger_id'.format(ifo)][:]])
        else:
            all_trig_times[ifo] = numpy.concatenate([all_trig_times[ifo],
                                     -1*numpy.ones_like(f_in['foreground/fap'][:], dtype=numpy.uint32)])
            all_trig_ids[ifo] = numpy.concatenate([all_trig_ids[ifo],
                                     -1*numpy.ones_like(f_in['foreground/fap'][:], dtype=numpy.uint32)])

#cluster the triggers before applying trials factor
for ifo in args.ifos:
    f['foreground/{}/time'.format(ifo)] = all_trig_times[ifo]
    f['foreground/{}/trigger_id'.format(ifo)] = all_trig_ids[ifo]

#cluster for loudest stat value 
def argmax(v):
    return numpy.argsort(v)[-1]

stat = numpy.core.records.fromarrays([f['foreground/ifar'][:],
                                      f['foreground/stat'][:]],
                                      names='ifar,stat')

all_times = ()
for ifo in args.ifos:
    all_times = all_times +  (f['foreground/%s/time' % ifo][:],)

cidx = pycbc.events.cluster_coincs_multiifo(stat, all_times,
                                            numpy.zeros(len(stat)), 0,
                                            args.cluster_window, argmax)

# downsample the foreground columns to only the loudest ifar between the multiple files
for key in f['foreground'].keys():
    if key not in args.ifos:
        dset = f['foreground/%s' % key][:][cidx]
        del f['foreground/%s' % key]
        f['foreground/%s' % key] = dset
    else: # key is an ifo
        for k in  f['foreground/%s' % key].keys():
            dset = f['foreground/{}/{}'.format(key,k)][:][cidx]
            del f['foreground/{}/{}'.format(key,k)]
            f['foreground/{}/{}'.format(key,k)] = dset

#copy across ifar and ifar_exc, etc 
# recalculate ifar/fap for the foreground triggers by 
#  applying a trials factor = num_files(num_bins)

all_times = ()
for ifo in args.ifos:
    all_times = all_times +  (f['foreground/%s/time' % ifo][:],)

# trials factor is how many possible 2+IFO combinations are 'on' at the time of the coincidence
trials_factors = numpy.zeros_like(f['foreground/ifar'][:])
test_times = numpy.array([pycbc.events.mean_if_greater_than_zero(tc)[0] for tc in zip(*all_times)])

for key in f['segments']:
    end_times = numpy.array(f['segments/%s/end' % key][:])
    start_times = numpy.array(f['segments/%s/start' % key][:])
    idx_within_segment = pycbc.events.indices_within_times(test_times, start_times, end_times)
    trials_factors[idx_within_segment] += numpy.ones_like(idx_within_segment)

ifars = [ifar/tf for ifar, tf in zip(f['foreground/ifar'][:], trials_factors)]
ifars_exc = [ifar_e/tf for ifar_e, tf in zip(f['foreground/ifar_exc'][:], trials_factors)]

#TODO: work out how to calculate fap given that coinc_time changes for each detector combination
#      commented out parts here need re-working out

#coinc_times = []
#coinc_times_exc = []
#for fi in files:
#    coinc_times.append(fi.attrs['foreground_time'] / lal.YRJUL_SI * numpy.ones_like(fi['foreground/ifar'][:]))
#    coinc_times_exc.append(fi.attrs['foreground_time_exc'] / lal.YRJUL_SI * numpy.ones_like(fi['foreground/ifar'][:]))

#faps = [1 - numpy.exp( - ct / ifar) for ifar, ct in zip(ifars, coinc_times)]
#faps_exc = [1 - numpy.exp( - ct_exc / ifar_exc) for ifar_exc, ct_exc in zip(ifars_exc, coinc_times_exc)]

f['foreground/ifar'][:] = ifars
f['foreground/ifar_exc'][:] = ifars_exc
#f['foreground/fap'][:] = faps
#f['foreground/fap_exc'][:] = faps_exc


#TODO: add in background combinations
# If there is a background set (full_data as opposed to injection run), then recalculate 
# the values for its triggers as well
#if 'background' in files[0]:  
#    bg_ifar = []
#    bg_exc_ifar = []
#    for key in key_set:
#        if key.startswith('background') or key.startswith('background_exc'):
#            pycbc.io.combine_and_copy(f, files, key)
#    for f_in in files:
#        n_ifos = sum([ifo in f_in['background'] for ifo in args.ifos])
#        fac = sum([comb(n_ifos, i) for i in range(2, n_ifos + 1)])
#        bg_ifar = numpy.concatenate(bg_ifar, f_in['background/ifar'][:] / fac)
#        bg_exc_ifar = numpy.concatenate(bg_exc_ifar,f_in['background_exc/ifar'][:] / fac)

#    f['background/ifar'][:] = bg_ifar
#    f['background_exc/ifar'][:] = bg_exc_ifar

#    pycbc.io.combine_and_copy(f, files, 'segments/foreground_veto/start')
#    pycbc.io.combine_and_copy(f, files, 'segments/foreground_veto/end')

for f_in in files:
    f_in.close()
f.close()
