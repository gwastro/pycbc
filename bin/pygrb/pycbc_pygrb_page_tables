#!/usr/bin/env python

# Copyright (C) 2011 Ian W. Harry
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

# =============================================================================
# Preamble
# =============================================================================

from __future__ import division

import sys
import os
import logging
import numpy as np
from scipy import stats
import pycbc.version
import pycbc.results
from pycbc.results.pygrb_postprocessing_utils import extract_ifos_and_vetoes
from pycbc.results.pygrb_postprocessing_utils import load_xml_table
from pycbc.results.pygrb_postprocessing_utils import load_segment_dict
from pycbc.results.pygrb_postprocessing_utils import find_zero_lag_slide_id
from pycbc.results.pygrb_postprocessing_utils import load_time_slides
from pycbc.results.pygrb_postprocessing_utils import pygrb_plot_opts_parser
from pycbc.results.pygrb_postprocessing_utils import construct_trials
from pycbc.results.pygrb_postprocessing_utils import sort_trigs
from pycbc.results.pygrb_postprocessing_utils import max_median_stat
from glue.ligolw import lsctables

# Deprecated
from pylal import SimInspiralUtils, MultiInspiralUtils
from pylal.coh_PTF_pyutils import readSegFiles, get_bestnr, get_f_resp

__author__ = "Francesco Pannarale <francesco.pannarale@ligo.org>"
__version__ = pycbc.version.git_verbose_msg
__date__ = pycbc.version.date
__program__ = "pycbc_pygrb_plot_stats_distribution"

# =============================================================================
# Main script starts here
# =============================================================================
description = 'Efficiency calculator for the triggered search (PyGRB).'
usage = __program__ + ' [--options]'
opts = pygrb_plot_opts_parser(usage=usage, description=description, version=__version__)

if opts.verbose:
    level = logging.INFO
else:
    level = logging.WARNING
logging.basicConfig(format="%(asctime)s:%(levelname)s : %(message)s",
                    level=level)

# Check options
if opts.offsource_file is None:
    err_msg = "Please specify a path to the offsource trigger file."
    logging.error(err_msg)

if opts.veto_directory and (opts.veto_category is None):
    err_msg = "Must supply veto category if applying vetoes."
    logging.error(err_msg)

if (opts.found_file is None) and (opts.missed_file is None):
    do_injections = False
elif (opts.found_file) and opts.missed_file:
    do_injections = True
else:
    err_msg = "Must provide both found and missed file if running injections."
    logging.error(err_msg)

if not opts.newsnr_threshold:
    opts.newsnr_threshold = opts.snr_threshold

# Store options used multiple times in local variables
outdir = opts.output_path
trig_file = opts.offsource_file
onsource_file = opts.onsource_file
found_file = opts.found_file
missed_file = opts.missed_file
chisq_index = opts.chisq_index
chisq_nhigh = opts.chisq_nhigh
wf_err = opts.waveform_error
cal_errs = {}
cal_errs['H1'] = opts.h1_cal_error
cal_errs['K1'] = opts.k1_cal_error
cal_errs['L1'] = opts.l1_cal_error
cal_errs['V1'] = opts.v1_cal_error
cal_dc_errs = {}
cal_dc_errs['H1'] = opts.h1_dc_cal_error
cal_dc_errs['K1'] = opts.k1_dc_cal_error
cal_dc_errs['L1'] = opts.l1_dc_cal_error
cal_dc_errs['V1'] = opts.v1_dc_cal_error
snr_thresh = opts.snr_threshold
sngl_snr_thresh = opts.sngl_snr_threshold
new_snr_thresh = opts.newsnr_threshold
null_grad_thresh = opts.null_grad_thresh
null_grad_val = opts.null_grad_val
null_thresh = map(float, opts.null_snr_threshold.split(','))
upper_dist = opts.upper_inj_dist
lower_dist = opts.lower_inj_dist
num_bins = opts.num_bins
wav_err = opts.waveform_error
cluster_window = opts.cluster_window
glitch_check_fac = opts.glitch_check_factor
num_mc_injs = opts.num_mc_injections
# Initialize random number generator
np.random.seed(opts.seed)
logging.info("Setting random seed to %d.", opts.seed)

# Set output directory
logging.info("Setting output directory.")
if not os.path.isdir(outdir):
    os.makedirs(outdir)

# Extract IFOs and vetoes
logging.info("Extracting IFOs and vetoes.")
ifos, vetoes = extract_ifos_and_vetoes(trig_file, opts.veto_directory, \
                                       opts.veto_category)

# Load triggers, time-slides, and segment dictionary
logging.info("Loading triggers.")
trigs = load_xml_table(trig_file, lsctables.MultiInspiralTable.tableName)
logging.info("%d triggers loaded.", len(trigs))
logging.info("Loading timeslides.")
slide_dict = load_time_slides(trig_file)
logging.info("Loading segments.")
segment_dict = load_segment_dict(trig_file)

# Identify the zero-lag slide and the number of slides
zero_lag_slide_id = find_zero_lag_slide_id(slide_dict)
num_slides = len(slide_dict)

# Get segments
segs = readSegFiles(opts.segment_dir)

# Construct trials
logging.info("Constructing trials.")
trial_dict = construct_trials(num_slides, segs, segment_dict, ifos, slide_dict, vetoes)

# Sort the triggers into each slide
sorted_trigs = sort_trigs(trial_dict, trigs, num_slides, segment_dict)

total_trials = sum([len(trial_dict[slide_id]) for slide_id in range(num_slides)])

msg = "Segments loaded, triggers sorted, and %d trials generated." % (total_trials)
logging.info(msg)

# Extract basic trigger properties and store as dictionaries
trig_time = {}
trig_snr = {}
trig_bestnr = {}
for slide_id in range(num_slides):
    slide_trigs = sorted_trigs[slide_id]
    trig_time[slide_id] = np.asarray(slide_trigs.get_end()).astype(float)
    trig_snr[slide_id] = np.asarray(slide_trigs.get_column('snr'))
    trig_bestnr[slide_id] = [get_bestnr(t, q=chisq_index, n=chisq_nhigh,\
                                        null_thresh=null_thresh,\
                                        snr_threshold=snr_thresh,\
                                        sngl_snr_threshold=sngl_snr_thresh,\
                                        chisq_threshold=new_snr_thresh,\
                                        null_grad_thresh=null_grad_thresh,\
                                        null_grad_val=null_grad_val) \
                             for t in slide_trigs]
    trig_bestnr[slide_id] = np.array(trig_bestnr[slide_id])
logging.info("Time, SNR, and BestNR of triggers extracted.")

# Calculate SNR and BestNR values and maxima
time_veto_max_snr = {}
time_veto_max_bestnr = {}
for slide_id in range(num_slides):
    num_slide_segs = len(trial_dict[slide_id])
    time_veto_max_snr[slide_id] = np.zeros(num_slide_segs)
    time_veto_max_bestnr[slide_id] = np.zeros(num_slide_segs)

for slide_id in range(num_slides):
    for j, trial in enumerate(trial_dict[slide_id]):
        trial_cut = (trial[0] <= trig_time[slide_id])\
                          & (trig_time[slide_id] < trial[1])
        if not trial_cut.any():
            continue
        # Max SNR
        time_veto_max_snr[slide_id][j] = \
                        max(trig_snr[slide_id][trial_cut])
        # Max BestNR
        time_veto_max_bestnr[slide_id][j] = \
                        max(trig_bestnr[slide_id][trial_cut])
        # Max SNR for triggers passing SBVs
        sbv_cut = trig_bestnr[slide_id] != 0
        if not (trial_cut&sbv_cut).any():
            continue

logging.info("SNR and bestNR maxima calculated.")

# Calculate and print fraction of trials with an event (highest FAP value)
num_events = 0
for slide_id in range(num_slides):
    for trial in range(len(trial_dict[slide_id])):
        if time_veto_max_bestnr[slide_id][trial] > 0:
            num_events += 1
quietest_file = open('%s/quiet_fap_val.txt' % outdir, 'w')
quietest_file.write('%s' % (num_events/total_trials))
quietest_file.close()

# Output details of (at most) 30 loudest offsouce triggers
# TODO: Do we really want this hard-coded 30?
offsource_trigs = []
for slide_id in range(num_slides):
    offsource_trigs.extend(zip(trig_bestnr[slide_id], sorted_trigs[slide_id]))
offsource_trigs.sort(key=lambda element: element[0])
offsource_trigs.reverse()

#TODO: we also want the template spin1z and spin2z. Do this after switch to hdf5
# th: table header
th = ['Trial', 'Slide Num', 'p-value', 'GPS',\
      'Rec. m1', 'Rec. m2', 'Rec. Mc',\
      'Rec. RA', 'Rec. Dec', 'SNR', 'Chi^2', 'Bank veto', 'Auto veto',\
      'Null SNR']
th.extend(['%s SNR' % ifo for ifo in ifos])
th.extend(['%s time shift (s)' % ifo for ifo in ifos])
th.append('BestNR')
# Format of table data
format_strings = ['##.##', '##.##', None, '##.#####',
                  '##.##', '##.##', '##.##',
                  '##.##', '##.##', '##.##', '##.##', '##.##', '##.##',
                  '##.##']
format_strings.extend(['##.##' for ifo in ifos])
format_strings.extend(['##.##' for ifo in ifos])
format_strings.extend(['##.##'])
# td: table data
td = []

# This is in PygrbFilterOutput
ifo_att = {'G1':'g', 'H1':'h1', 'H2':'h2', 'L1':'l', 'V1':'v', 'T1':'t'}

# Gather properties of the loudest offsource triggers 
for i in range(min(len(offsource_trigs), 30)):
    bestnr = offsource_trigs[i][0]
    trig = offsource_trigs[i][1]
    trig_slide_id = int(trig.time_slide_id)

    # Get trial of trigger, triggers with 'No trial' should have been removed!
    for j, trial in enumerate(trial_dict[trig_slide_id]):
        if trig.get_end() in trial:
            chunk_num = j
            break
    else:
        chunk_num = 'No trial'

    # Get FAP of trigger
    num_trials_louder = 0
    for slide_id in range(num_slides):
        for val in time_veto_max_bestnr[slide_id]:
            if val > bestnr:
                num_trials_louder += 1
    fap = num_trials_louder/total_trials
    pval = '< %.3g' % (1./total_trials) if fap == 0 else '%.3g' % fap

    d = [chunk_num, trig_slide_id, pval,\
         trig.get_end(),\
         trig.mass1, trig.mass2, trig.mchirp,\
         (np.degrees(trig.ra)), (np.degrees(trig.dec)),\
         trig.snr, trig.chisq, trig.bank_chisq,\
         trig.cont_chisq, trig.get_null_snr()]
    d.extend([getattr(trig, 'snr_%s' % ifo_att[ifo])\
                     for ifo in ifos])
    d.extend([slide_dict[trig_slide_id][ifo] for ifo in ifos])
    d.append(bestnr)
    td.append(d)

# To ensure desired formatting in the html table:
# 1) "transpose" the data preserving its dtype
# 2) convert the columns to numpy arrays
# This is necessary as the p-values need to be treated as strings,
# as they may contain a '<'
td = zip(*td)
td = [np.asarray(d) for d in td]
html_table = pycbc.results.html_table(td, th,
                                      format_strings=format_strings,
                                      page_size=30)
# Write to html file
html_path = "%s/loudest_offsource_trigs.html" % outdir
kwds = {'title' : "Parameters of loudest offsource triggers",
        'caption' : "Parameters of 30 loudest offsource triggers.",
        'cmd' :' '.join(sys.argv), }
pycbc.results.save_fig_with_metadata(str(html_table), html_path, **kwds)


# ==========================
# Print loudest SNRs to file
# THIS OUTPUT FILE IS CURRENTLY UNUSED - MAYBE DELETE?
# Note: the only new info from above is the median SNR, bestnr
# and loudest SNR, so could just add this to the above's caption.
# ==========================
th = ['', 'SNR', 'BestNR']
td = []

max_snr, median_snr, _ = max_median_stat(num_slides, time_veto_max_snr, trig_snr, total_trials)
max_bestnr, median_bestnr, full_time_veto_max_bestnr = max_median_stat(num_slides, time_veto_max_bestnr, trig_bestnr, total_trials)

d = ['Loudest ', max_snr, max_bestnr]
td.append(d)
d = ['Median ', median_snr, median_bestnr]
td.append(d)
td.append([])

# Write html table with results
html = pycbc.results.dq.redirect_javascript + str(pycbc.results.static_table(td, th))
title = 'Re-weighted SNR and SNR of the loudest and median offsource trigger'
caption = ('Re-weighted SNR and SNR of the loudest and median offsource trigger')
html_path = "%s/loudest_median_offsource.html" % outdir
pycbc.results.save_fig_with_metadata(html, html_path, {},
                                     cmd=' '.join(sys.argv), title=title,
                                     caption=caption)

# Store BestNR and FAP values
np.savetxt('%s/bestnr_vs_fap_numbers.txt' %(outdir),
           full_time_veto_max_bestnr, delimiter='/t')

# =======================
# Load on source triggers
# =======================
if onsource_file:

    # Get trigs
    on_trigs = load_xml_table(onsource_file, "multi_inspiral")
    msg = "%d onsource triggers loaded." % (len(on_trigs))

    # Separate off chirp mass column
    on_mchirp = on_trigs.get_column('mchirp')

    # Record loudest trig by SNR and by BestNR
    bin_trigs = sorted(np.asarray(on_trigs), key=lambda t: t.snr, reverse=True)
    loud_on_snr_trigs = bin_trigs[0]
    loud_on_snr = bin_trigs[0].snr
    bin_trigs.sort(key=lambda t: get_bestnr(t, q=chisq_index, n=chisq_nhigh,\
                                            null_thresh=null_thresh,\
                                            snr_threshold=snr_thresh,\
                                            sngl_snr_threshold=sngl_snr_thresh,\
                                            chisq_threshold=new_snr_thresh,\
                                            null_grad_thresh=null_grad_thresh,\
                                            null_grad_val=null_grad_val),\
                                            reverse=True)
    loud_on_bestnr_trigs = bin_trigs[0]
    loud_on_bestnr = get_bestnr(bin_trigs[0], q=chisq_index,\
                                null_thresh=null_thresh,\
                                snr_threshold=snr_thresh,\
                                sngl_snr_threshold=sngl_snr_thresh,\
                                chisq_threshold=new_snr_thresh,
                                n=chisq_nhigh,\
                                null_grad_thresh=null_grad_thresh,\
                                null_grad_val=null_grad_val)
    # If the loudest event has bestnr = 0, there is no event at all!
    if loud_on_bestnr == 0:
        loud_on_bestnr_trigs = None
        loud_on_bestnr = 0

    logging.info("Onsource analysed.")

    loud_txt = open('%s/loud_numbers.txt' % outdir, 'w')

    # Table header and table data
    # TODO we will want the spins too (easier to deal with after move to hdf5)
    th = ['p-value', 'GPS', 'Rec. m1', 'Rec. m2', 'Rec. Mc', 'Rec. RA',\
          'Rec. Dec', 'SNR', 'Chi^2', 'Bank veto', 'Auto veto', 'Null SNR'] +\
         ['%s SNR' % ifo for ifo in ifos] + ['BestNR']
    td = []

    # Format of table data
    format_strings = [None, '##.#####', '##.##', '##.##', '##.##', '##.##',
                      '##.##', '##.##', '##.##', '##.##', '##.##', '##.##']
    format_strings.extend(['##.##' for ifo in ifos])
    format_strings.extend(['##.##'])

    # Gather data
    loud_on_fap = 1
    if loud_on_bestnr_trigs:
        trig = loud_on_bestnr_trigs
        num_trials_louder = 0
        tot_off_snr = np.array([])
        for slide_id in range(num_slides):
            num_trials_louder += sum(time_veto_max_bestnr[slide_id] > \
                                     loud_on_bestnr)
            tot_off_snr = np.concatenate([tot_off_snr,\
                                          time_veto_max_bestnr[slide_id]])
        fap = num_trials_louder/total_trials
        fap_test = sum(tot_off_snr > loud_on_bestnr)/total_trials
        pval = '< %.3g' % (1./total_trials) if fap == 0 else '%.3g' % fap
        loud_on_fap = fap
        d = [pval, trig.get_end(),\
             trig.mass1, trig.mass2, trig.mchirp,\
             np.degrees(trig.ra), np.degrees(trig.dec),\
             trig.snr, trig.chisq, trig.bank_chisq,\
             trig.cont_chisq, trig.get_null_snr()] + \
             [trig.get_sngl_snr(ifo) for ifo in ifos] + [loud_on_bestnr]
        loud_txt.write('%s\n' % pval.replace('<', '&lt'))
        td.append(d)
    else:
        td.append(["There are no events"] + [0 for number in xrange(11)] + \
                  [0 for ifo in ifos] + [0])
        loud_txt.write('-2\n')
    loud_txt.close()

    # Write to html file
    td = zip(*td)
    td = [np.asarray(d) for d in td]
    html_table = pycbc.results.html_table(td, th,
                                          format_strings=format_strings,
                                          page_size=1)
    html_path = "%s/loudest_events.html" % outdir
    kwds = {'title' : "Loudest event",
            'caption' : "Recovered parameters and statistic values of the loudest trigger.",
            'cmd' :' '.join(sys.argv), }
    pycbc.results.save_fig_with_metadata(str(html_table), html_path, **kwds)
else:
    tot_off_snr = np.array([])
    for slide_id in range(num_slides):
        tot_off_snr = np.concatenate([tot_off_snr,\
                                      time_veto_max_bestnr[slide_id]])
    med_snr = np.median(tot_off_snr)
    fap = sum(tot_off_snr > med_snr)/total_trials

# =======================
# Post-process injections
# =======================
if do_injections:

    sites = [ifo[0] for ifo in ifos]

    # Triggers and injections recovered in some form
    found_trigs_nveto = MultiInspiralUtils.ReadMultiInspiralFromFiles([found_file])
    found_injs_no_veto = SimInspiralUtils.ReadSimInspiralFromFiles([found_file])

    found_trigs = lsctables.New(lsctables.MultiInspiralTable)
    found_injs = lsctables.New(lsctables.SimInspiralTable)

    for trig, sim in zip(found_trigs_nveto, found_injs_no_veto):
        if sim.get_end() not in vetoes.union(vetoes.keys()):
            found_injs.append(sim)
            found_trigs.append(trig)

    logging.info("Missed/found injections/triggers loaded.")

    # Extract columns of found injections and triggers
    found_inj_time = np.asarray(found_injs.get_column('geocent_end_time')) +\
                     np.asarray(found_injs.get_column('geocent_end_time_ns')*\
                                10**-9)
    found_inj_mchirp = np.asarray(found_injs.get_column('mchirp'))
    found_inj_mtot = np.asarray(found_injs.get_column('mtotal'))
    found_inj_m1 = np.asarray(found_injs.get_column('mass1'))
    found_inj_m2 = np.asarray(found_injs.get_column('mass2'))
    found_inj_eff_site_dist =\
        dict((ifo, found_injs.get_column('eff_dist_%s' % ifo.lower()))\
             for ifo in sites)
    found_inj_eff_dist = np.power(np.power(\
                                  np.asarray(found_inj_eff_site_dist.\
                                  values()), -1).sum(0), -1)
    found_inj_ra = np.asarray(found_injs.get_column('longitude'))
    found_inj_dec = np.asarray(found_injs.get_column('latitude'))
    found_inj_dist = np.asarray(found_injs.get_column('distance'))
    found_inj_inc = np.asarray(found_injs.get_column('inclination'))
    found_inj_spin1x = np.asarray(found_injs.get_column('spin1x'))
    found_inj_spin1y = np.asarray(found_injs.get_column('spin1y'))
    found_inj_spin1z = np.asarray(found_injs.get_column('spin1z'))
    found_inj_spin2x = np.asarray(found_injs.get_column('spin2x'))
    found_inj_spin2y = np.asarray(found_injs.get_column('spin2y'))
    found_inj_spin2z = np.asarray(found_injs.get_column('spin2z'))

    # TODO: a lot of this is identical to all the stuff above
    
    found_trig_mchirp = np.asarray(found_trigs.get_column('mchirp'))
    found_trig_m1 = np.asarray(found_trigs.get_column('mass1'))
    found_trig_m2 = np.asarray(found_trigs.get_column('mass2'))
    found_trig_ra = np.asarray(found_trigs.get_column('ra'))
    found_trig_dec = np.asarray(found_trigs.get_column('dec'))
    found_sky_angle = np.arccos(np.cos(found_inj_dec - found_trig_dec) -\
                                np.cos(found_inj_dec)* np.cos(found_trig_dec) *\
                                (1 - np.cos(found_inj_ra - found_trig_ra)))
    found_trig_snr = np.asarray(found_trigs.get_column('snr'))
    found_trig_chisq = np.asarray(found_trigs.get_column('chisq'))
    found_trig_bank = np.asarray(found_trigs.get_column('bank_chisq'))
    found_trig_auto = np.asarray(found_trigs.get_column('cont_chisq'))
    found_trig_null_snr = np.asarray(found_trigs.get_null_snr())
    found_trig_sngl_snr = dict((ifo, np.asarray(found_trigs.get_sngl_snr(ifo)))\
                                for ifo in ifos)

    # Grab values of detection statistic
    found_trig_bestnr = [get_bestnr(t, q=chisq_index, n=chisq_nhigh,\
                             null_thresh=null_thresh,\
                             snr_threshold=snr_thresh,\
                             sngl_snr_threshold=sngl_snr_thresh,\
                             chisq_threshold=new_snr_thresh,\
                             null_grad_thresh=null_grad_thresh,\
                             null_grad_val=null_grad_val) for t in found_trigs]
    found_trig_bestnr = np.asarray(found_trig_bestnr)

    # Construct conditions for injection:
    # 1) found louder than background,
    zero_fap = np.zeros(len(found_injs)).astype(np.bool)
    zero_fap_cut = found_trig_bestnr > max_bestnr
    zero_fap = zero_fap | (zero_fap_cut)

    # 2) found (bestnr > 0) but not louder than background (non-zero FAP)
    nonzero_fap = ~zero_fap & (found_trig_bestnr != 0)

    # 3) missed after being recovered (i.e., vetoed)
    missed = (~zero_fap) & (~nonzero_fap)

    # Separate triggers into:
    # 1) zero_fap 'g_found'
    # 2) nonzero_fap 'g_ifar'
    # 3) missed because of vetoes 'g_missed2'

    # Zero FAP
    g_found_mchirp = found_inj_mchirp[zero_fap]
    g_found_mtot = found_inj_mtot[zero_fap]
    g_found_m1 = found_inj_m1[zero_fap]
    g_found_m2 = found_inj_m2[zero_fap]
    g_found_eff_site_dist = dict((ifo, found_inj_eff_site_dist[ifo][zero_fap])\
                             for ifo in sites)
    g_found_eff_dist = found_inj_eff_dist[zero_fap]
    g_found_det_stat = found_trig_bestnr[zero_fap]
    g_found_dist = found_inj_dist[zero_fap]
    g_found_time = found_inj_time[zero_fap]
    g_found_sky_angle = found_sky_angle[zero_fap]
    g_found_inc = found_inj_inc[zero_fap]
    g_found_spin1x = found_inj_spin1x[zero_fap]
    g_found_spin1y = found_inj_spin1y[zero_fap]
    g_found_spin1z = found_inj_spin1z[zero_fap]
    g_found_spin2x = found_inj_spin2x[zero_fap]
    g_found_spin2y = found_inj_spin2y[zero_fap]
    g_found_spin2z = found_inj_spin2z[zero_fap]

    # Non-zero FAP
    g_ifar_mchirp = found_inj_mchirp[nonzero_fap]
    g_ifar_mtot = found_inj_mtot[nonzero_fap]
    g_ifar_m1 = found_inj_m1[nonzero_fap]
    g_ifar_m2 = found_inj_m2[nonzero_fap]
    g_ifar_eff_site_dist = dict((ifo, found_inj_eff_site_dist[ifo][nonzero_fap])\
                              for ifo in sites)
    g_ifar_eff_dist = found_inj_eff_dist[nonzero_fap]
    g_ifar_det_stat = found_trig_bestnr[nonzero_fap]
    g_ifar_dist = found_inj_dist[nonzero_fap]
    g_ifar_time = found_inj_time[nonzero_fap]
    g_ifar_sky_angle = found_sky_angle[nonzero_fap]
    g_ifar_inc = found_inj_inc[nonzero_fap]
    g_ifar_spin1x = found_inj_spin1x[nonzero_fap]
    g_ifar_spin1y = found_inj_spin1y[nonzero_fap]
    g_ifar_spin1z = found_inj_spin1z[nonzero_fap]
    g_ifar_spin2x = found_inj_spin2x[nonzero_fap]
    g_ifar_spin2y = found_inj_spin2y[nonzero_fap]
    g_ifar_spin2z = found_inj_spin2z[nonzero_fap]
    g_ifar_ra = found_inj_ra[nonzero_fap]
    g_ifar_dec = found_inj_dec[nonzero_fap]

    g_ifar_trig = np.asarray(found_trigs)[nonzero_fap]
    g_ifar_inj = np.asarray(found_injs)[nonzero_fap]

    g_ifar_stat = np.zeros([len(g_ifar_det_stat)])
    for ix, (mc, bestnr) in \
                enumerate(zip(found_trig_mchirp[nonzero_fap], g_ifar_det_stat)):
        g_ifar_stat[ix] = (full_time_veto_max_bestnr > bestnr).sum()
    g_ifar_stat = g_ifar_stat / total_trials
    # Statistics: missed-found
    MF = np.argsort(g_ifar_stat)
    # Statistics: found-missed
    FM = MF[::-1]

    g_ifar_rec_m1 = found_trig_m1[nonzero_fap]
    g_ifar_rec_m2 = found_trig_m2[nonzero_fap]
    g_ifar_rec_mchirp = found_trig_mchirp[nonzero_fap]
    g_ifar_rec_ra = found_trig_ra[nonzero_fap]
    g_ifar_rec_dec = found_trig_dec[nonzero_fap]
    g_ifar_snr = found_trig_snr[nonzero_fap]
    g_ifar_chisq = found_trig_chisq[nonzero_fap]
    g_ifar_bank = found_trig_bank[nonzero_fap]
    g_ifar_auto = found_trig_auto[nonzero_fap]
    g_ifar_null = found_trig_null_snr[nonzero_fap]
    g_ifar_sngl_snr = dict((ifo, found_trig_sngl_snr[ifo][nonzero_fap])\
                            for ifo in ifos)

    # Missed due to vetoes
    g_missed2_mchirp = found_inj_mchirp[missed]
    g_missed2_mtot = found_inj_mtot[missed]
    g_missed2_m1 = found_inj_m1[missed]
    g_missed2_m2 = found_inj_m2[missed]
    g_missed2_eff_site_dist = dict((ifo, found_inj_eff_site_dist[ifo][missed])\
                                   for ifo in sites)
    g_missed2_eff_dist = found_inj_eff_dist[missed]
    g_missed2_det_stat = found_trig_bestnr[missed]
    g_missed2_dist = found_inj_dist[missed]
    g_missed2_time = found_inj_time[missed]
    g_missed2_sky_angle = found_sky_angle[missed]
    g_missed2_inc = found_inj_inc[missed]
    g_missed2_spin1x = found_inj_spin1x[missed]
    g_missed2_spin1y = found_inj_spin1y[missed]
    g_missed2_spin1z = found_inj_spin1z[missed]
    g_missed2_spin2x = found_inj_spin2x[missed]
    g_missed2_spin2y = found_inj_spin2y[missed]
    g_missed2_spin2z = found_inj_spin2z[missed]
    g_missed2_ra = found_inj_ra[missed]
    g_missed2_dec = found_inj_dec[missed]

    g_missed2_trig = np.asarray(found_trigs)[missed]
    g_missed2_inj = np.asarray(found_injs)[missed]

    g_missed2_rec_m1 = found_trig_m1[missed]
    g_missed2_rec_m2 = found_trig_m2[missed]
    g_missed2_rec_mchirp = found_trig_mchirp[missed]
    g_missed2_rec_ra = found_trig_ra[missed]
    g_missed2_rec_dec = found_trig_dec[missed]
    g_missed2_snr = found_trig_snr[missed]
    g_missed2_chisq = found_trig_chisq[missed]
    g_missed2_bank = found_trig_bank[missed]
    g_missed2_auto = found_trig_auto[missed]
    g_missed2_null = found_trig_null_snr[missed]
    g_missed2_sngl_snr = dict((ifo, found_trig_sngl_snr[ifo][missed])\
                              for ifo in ifos)

    # Set the sigma values
    inj_sigma = found_trigs.get_sigmasqs()
    # If the sigmasqs are not populated, we can still do calibration errors,
    # but only in the 1-detector case
    for ifo in ifos:
        if sum(inj_sigma[ifo] == 0):
            logging.info("%s: sigmasq not set for at least one trigger.", ifo)
        if sum(inj_sigma[ifo] != 0) == 0:
            logging.info("%s: sigmasq not set for any trigger.", ifo)
            if len(ifos) == 1:
                msg = "This is a single ifo analysis. "
                msg += "Setting sigmasq to unity for all triggers."
                logging.info(msg)
                inj_sigma[ifo][:] = 1.

    f_resp = dict((ifo, np.asarray([get_f_resp(inj)[ifo] \
                   for inj in found_injs]))  for ifo in ifos)

    inj_sigma_mult = (np.asarray(inj_sigma.values()) *\
                      np.asarray(f_resp.values()))

    inj_sigma_tot = inj_sigma_mult[0, :]
    for i in range(1, len(ifos)):
        inj_sigma_tot += inj_sigma_mult[i, :]

    inj_sigma_mean = {}
    for ifo in ifos:
        inj_sigma_mean[ifo] = ((inj_sigma[ifo]*f_resp[ifo])/inj_sigma_tot).mean()

    logging.info("%d found injections analysed.", len(found_injs))

    # Missed injections (ones not recovered at all)
    missed_injs = SimInspiralUtils.ReadSimInspiralFromFiles([missed_file])\
            .veto(vetoes.union(vetoes.keys()))

    # Process missed injections 'missed_inj'
    missed_inj_mchirp = np.asarray(missed_injs.get_column('mchirp'))
    missed_inj_eff_site_dist =\
        dict((ifo, missed_injs.get_column('eff_dist_%s' % ifo.lower()))\
             for ifo in sites)
    missed_inj_eff_dist = np.power(np.power(\
                                   np.asarray(missed_inj_eff_site_dist.\
                                   values()), -1)\
                                   .sum(0), -1)
    missed_inj_dist = np.asarray(missed_injs.get_column('distance'))
    missed_inj_time = np.asarray(missed_injs.get_column('geocent_end_time') +\
                                 missed_injs.get_column('geocent_end_time_ns') *\
                                 10**-9)
    missed_inj_m1 = np.asarray(missed_injs.get_column('mass1'))
    missed_inj_m2 = np.asarray(missed_injs.get_column('mass2'))
    missed_inj_inc = np.asarray(missed_injs.get_column('inclination'))
    missed_inj_ra = np.asarray(missed_injs.get_column('longitude'))
    missed_inj_dec = np.asarray(missed_injs.get_column('latitude'))

    missed_inj_spin1x = np.asarray(missed_injs.get_column('spin1x'))
    missed_inj_spin1y = np.asarray(missed_injs.get_column('spin1y'))
    missed_inj_spin1z = np.asarray(missed_injs.get_column('spin1z'))
    missed_inj_spin2x = np.asarray(missed_injs.get_column('spin2x'))
    missed_inj_spin2y = np.asarray(missed_injs.get_column('spin2y'))
    missed_inj_spin2z = np.asarray(missed_injs.get_column('spin2z'))

    # Avoids a problem with formatting in the non-static html output file
    #missed_na = ['N/A'] * len(missed_injs)
    missed_na = [-0] * len(missed_injs)

    if missed_inj_m1.size:
        min_missed_inj_m1 = missed_inj_m1.min()
        max_missed_inj_m1 = missed_inj_m1.max()
        min_missed_inj_m2 = missed_inj_m2.min()
        max_missed_inj_m2 = missed_inj_m2.max()
    else:
        min_missed_inj_m1 = 1e3
        max_missed_inj_m1 = 0
        min_missed_inj_m2 = 1e3
        max_missed_inj_m2 = 0

    logging.info("%d missed injections analysed.", len(missed_injs))

    # Write inclination recovery to file
    # GRB start time
    grb_time = segs['on'][1] - 1
    f_incl_txt = open('%s/found_inclinations.txt' % outdir, 'w')
    f_incl_txt.write('GPS time\tTime since %d\tInclination\n\n' % grb_time)
    stacked = np.column_stack([g_found_time,
                               g_found_time - grb_time,
                               g_found_inc])
    np.savetxt(f_incl_txt, stacked, delimiter='\t')
    f_incl_txt.close()
    t_incl_txt = open('%s/total_inclinations.txt' % outdir, 'w')
    t_incl_txt.write('GPS time\tTime since %d\tInclination\n\n' % grb_time)
    stacked = np.column_stack([np.concatenate((found_inj_time, missed_inj_time)),
                               np.concatenate((found_inj_time - grb_time,
                                               missed_inj_time - grb_time)),
                               np.concatenate((found_inj_inc, missed_inj_inc))])
    np.savetxt(t_incl_txt, stacked, delimiter='\t')
    t_incl_txt.close()

    # Create new set of injections for efficiency calculations
    total_injs = len(found_injs) + len(missed_injs)
    long_inj_dist = stats.uniform.rvs(size=total_injs) * (upper_dist-lower_dist) +\
                  upper_dist

    logging.info("%d long distance injections created.", total_injs)

    # Set distance bins and data arrays
    dist_bins = zip(np.arange(lower_dist, upper_dist + (upper_dist-lower_dist),\
                             (upper_dist-lower_dist)/num_bins),\
                   np.arange(lower_dist, upper_dist + (upper_dist-lower_dist),\
                             (upper_dist-lower_dist)/num_bins) +\
                             (upper_dist-lower_dist)/num_bins)

    num_injections = np.zeros([len(dist_bins)+1])
    found_max_bestnr = np.zeros([len(dist_bins)+1])
    found_on_bestnr = np.zeros([len(dist_bins)+1])
    num_injections_no_mc = np.zeros([len(dist_bins)+1])
    found_max_bestnr_no_mc = np.zeros([len(dist_bins)+1])
    found_on_bestnr_no_mc = np.zeros([len(dist_bins)+1])

    # Construct FAP list for all found injections
    inj_fap = np.zeros(len(found_injs))
    inj_fap[nonzero_fap] = g_ifar_stat

    # Calculate the amplitude error
    # Begin by calculating the components from each detector
    cal_error = 0
    for ifo in ifos:
        cal_error += cal_errs[ifo]**2 * inj_sigma_mean[ifo]**2
    cal_error = cal_error**0.5

    max_dc_cal_error = max(cal_dc_errs.values())

    # Calibration phase uncertainties are neglected
    logging.info("Calibration amplitude uncertainty calculated.")

    # Now create the numbers for the efficiency plots; these include calibration
    # and waveform errors. These are incorporated by running over each injection
    # num_mc_injs times, where each time we draw a random value of distance

    # Distribute injections
    found_inj_dist_mc = np.ndarray((num_mc_injs+1, len(found_injs)))
    found_inj_dist_mc[0, :] = found_inj_dist
    missed_inj_dist_mc = np.ndarray((num_mc_injs+1, len(missed_injs)))
    missed_inj_dist_mc[0, :] = missed_inj_dist
    long_inj_dist_mc = np.ndarray((num_mc_injs+1, total_injs))
    long_inj_dist_mc[0, :] = long_inj_dist
    for i in range(num_mc_injs):
        # TODO: these is a copy and paste of 3 lines of code
        cal_dist_red = stats.norm.rvs(size=len(found_injs)) * cal_error
        wav_dist_red = np.abs(stats.norm.rvs(size=len(found_injs)) * wav_err)
        found_inj_dist_mc[i+1, :] = found_inj_dist / (max_dc_cal_error * \
                                     (1 + cal_dist_red) * (1 + wav_dist_red))
        cal_dist_red = stats.norm.rvs(size=len(missed_injs)) * cal_error
        wav_dist_red = np.abs(stats.norm.rvs(size=len(missed_injs)) * wav_err)
        missed_inj_dist_mc[i+1, :] = missed_inj_dist / (max_dc_cal_error *\
                                     (1 + cal_dist_red) * (1 + wav_dist_red))
        cal_dist_red = stats.norm.rvs(size=total_injs) * cal_error
        wav_dist_red = np.abs(stats.norm.rvs(size=total_injs) * wav_err)
        long_inj_dist_mc[i+1, :] = long_inj_dist / (max_dc_cal_error *\
                                     (1 + cal_dist_red) * (1 + wav_dist_red))

    logging.info("MC injection set distributed with %d iterations.",\
                 num_mc_injs)

    # Check injections against on source
    more_sig_than_onsource = np.ndarray(len(found_injs))
    if onsource_file:
        more_sig_than_onsource = (inj_fap <= loud_on_fap)
    else:
        more_sig_than_onsource = (inj_fap <= 0.5)
    more_sig_than_onsource = more_sig_than_onsource.all(0)

    distance_count = np.zeros(len(dist_bins))

    found_trig_max_bestnr = np.zeros([len(found_trig_mchirp)])
    for ix, mc in enumerate(found_trig_mchirp):
        found_trig_max_bestnr[ix] = max_bestnr

    max_bestnr_cut = (found_trig_bestnr > found_trig_max_bestnr)

    # Check louder than on source
    if onsource_file:
        # TODO: basically the same code as above
        found_trig_loud_on_bestnr = np.zeros([len(found_trig_mchirp)])
        for ix, mc in enumerate(found_trig_mchirp):
            found_trig_loud_on_bestnr[ix] = loud_on_bestnr
    else:
        found_trig_loud_on_bestnr = np.zeros([len(found_trig_mchirp)])
        for ix, mc in enumerate(found_trig_mchirp):
            found_trig_loud_on_bestnr[ix] = med_snr
    on_bestnr_cut = found_trig_bestnr > found_trig_loud_on_bestnr

    # Check whether injection is found for the purposes of exclusion
    # distance calculation.
    # Found: if louder than all on source
    # Missed: if not louder than loudest on source
    found_excl = on_bestnr_cut & (more_sig_than_onsource) & \
                (found_trig_bestnr != 0)
    # If not missed, double check bestnr against nearby triggers
    near_test = np.zeros((found_excl).sum()).astype(bool)
    for j, (t, bestnr) in enumerate(zip(found_inj_time[found_excl],\
                                        found_trig_bestnr[found_excl])):
        near_bestnr = trig_bestnr[zero_lag_slide_id]\
                      [np.abs(trig_time[zero_lag_slide_id]-t) < cluster_window]
        near_test[j] = ~((near_bestnr * glitch_check_fac > bestnr).any())
    # Apply the local test
    # FIXME: putmask does not seem to work...
    #np.putmask(found_excl, found_excl==True, near_test)
    c = 0
    for z, b in enumerate(found_excl):
        if found_excl[z]:
            found_excl[z] = near_test[c]
            c += 1

    # Loop over each random instance of the injection set
    for k in range(num_mc_injs+1):
        # Loop over the distance bins
        for j, dist_bin in enumerate(dist_bins):
            # Construct distance cut
            found_dist_cut = (dist_bin[0] <= found_inj_dist_mc[k, :]) &\
                             (found_inj_dist_mc[k, :] < dist_bin[1])
            missed_dist_cut = (dist_bin[0] <= missed_inj_dist_mc[k, :]) &\
                              (missed_inj_dist_mc[k, :] < dist_bin[1])
            long_dist_cut = (dist_bin[0] <= long_inj_dist_mc[k, :]) &\
                            (long_inj_dist_mc[k, :] < dist_bin[1])

            # Count all injections in this distance bin
            num_found_pass = (found_dist_cut).sum()
            num_missed_pass = (missed_dist_cut).sum()
            num_long_pass = long_dist_cut.sum() or 0
            # Count only zero FAR injections
            num_zero_far = (found_dist_cut & max_bestnr_cut).sum()
            # Count number found for exclusion
            num_excl = (found_dist_cut & (found_excl)).sum()

            # Record number of injections, number found for exclusion
            # and number of zero FAR
            # TODO: serial coding (and redundant items?)
            if k == 0:
                num_injections_no_mc[j] += num_found_pass + num_missed_pass +\
                                           num_long_pass
                num_injections_no_mc[-1] += num_found_pass + num_missed_pass +\
                                            num_long_pass
                found_max_bestnr_no_mc[j] += num_zero_far
                found_max_bestnr_no_mc[-1] += num_zero_far
                found_on_bestnr_no_mc[j] += num_excl
                found_on_bestnr_no_mc[-1] += num_excl
            else:
                num_injections[j] += num_found_pass + num_missed_pass +\
                                     num_long_pass
                num_injections[-1] += num_found_pass + num_missed_pass +\
                                      num_long_pass
                found_max_bestnr[j] += num_zero_far
                found_max_bestnr[-1] += num_zero_far
                found_on_bestnr[j] += num_excl
                found_on_bestnr[-1] += num_excl

    np.savetxt('%s/found_maxbestnr.txt' % outdir, found_max_bestnr.T)
    np.savetxt('%s/found_maxbestnrnomc.txt' % outdir, found_max_bestnr_no_mc.T)
    np.savetxt('%s/foundonbestnr.txt' % outdir, found_on_bestnr.T)
    np.savetxt('%s/foundonbestnrnomc.txt' % outdir, found_on_bestnr_no_mc.T)
    np.savetxt('%s/numinjections.txt' % outdir, num_injections.T)
    np.savetxt('%s/numinjectionsnomc.txt' % outdir, num_injections_no_mc.T)
    inj_rec_file = open("%s/injection_recovery.html" % outdir, "w")
    inj_rec_file.write("Total injections found louder than all background using %s "\
                       "is: %s<br>\n" % ('BestNR', found_max_bestnr[-1]))
    inj_rec_file.write("Total injections found louder than all background (and "\
                       "nearby triggers in the offsource) using %s is: %s<br>"\
                       % ('BestNR', found_on_bestnr[-1]))
    inj_rec_file.close()

    logging.info("Found/missed injection efficiency calculations completed.")

    # Get start and end times
    start = int(min(np.concatenate((found_inj_time, missed_inj_time))))
    end = int(max(np.concatenate((found_inj_time, missed_inj_time))))
    duration = end - start
    # Pad times and reset to centre on zero
    start = start - duration*0.05 - grb_time
    end = end + duration*0.05 - grb_time
    missed_inj_time = missed_inj_time - grb_time
    g_missed2_time -= grb_time
    g_found_time -= grb_time
    g_ifar_time -= grb_time

    # Write quiet triggers to file
    th = ['Dist'] + ['Eff. Dist. %s' % site for site in sites] +\
         ['Inj. m1', 'Inj. m2', 'Inj. Mc', 'Rec. m1', 'Rec. m2', 'Rec. Mc',\
          'Inj. inc', 'Inj. RA', 'Inj. Dec', 'Rec. RA', 'Rec. Dec', 'SNR',\
          'Chi^2', 'Bank veto', 'Auto veto', 'Null SNR'] +\
         ['SNR %s' % ifo for ifo in ifos] +\
         ['BestNR', 'Inj S1x', 'Inj S1y', 'Inj S1z',\
                    'Inj S2x', 'Inj S2y', 'Inj S2z']
    # Format of table data
    format_strings = ['##.##']
    format_strings.extend(['##.##' for ifo in ifos])
    format_strings.extend(['##.##', '##.##', '##.##',
                           '##.##', '##.##', '##.##',
                           '##.##', '##.##', '##.##',
                           '##.##', '##.##', '##.##', '##.##', '##.##', '##.##', '##.##'])
    format_strings.extend(['##.##' for ifo in ifos])
    format_strings.extend(['##.##',
                           '##.##', '##.##', '##.##', '##.##', '##.##',
                           '##.##'])
    # TODO: serial coding
    td = zip(*[np.concatenate((g_ifar_dist, g_missed2_dist,\
                               missed_inj_dist))] +\
              [np.concatenate((g_ifar_eff_site_dist[ifo],\
                               g_missed2_eff_site_dist[ifo],\
                               missed_inj_eff_site_dist[ifo]))\
               for ifo in sites] +\
              [np.concatenate((g_ifar_m1, g_missed2_m1, missed_inj_m1)),\
               np.concatenate((g_ifar_m2, g_missed2_m2, missed_inj_m2)),\
               np.concatenate((g_ifar_mchirp, g_missed2_mchirp,\
                                  missed_inj_mchirp)),\
               np.concatenate((g_ifar_rec_m1, g_missed2_rec_m1, missed_na)),\
               np.concatenate((g_ifar_rec_m2, g_missed2_rec_m2, missed_na)),\
               np.concatenate((g_ifar_rec_mchirp, g_missed2_rec_mchirp,\
                                  missed_na)),\
               np.concatenate((g_ifar_inc, g_missed2_inc, missed_inj_inc)),\
               np.concatenate((g_ifar_ra, g_missed2_ra, missed_inj_ra)),\
               np.concatenate((g_ifar_dec, g_missed2_dec, missed_inj_dec)),\
               np.concatenate((g_ifar_rec_ra, g_missed2_rec_ra, missed_na)),\
               np.concatenate((g_ifar_rec_dec, g_missed2_rec_dec, missed_na)),\
               np.concatenate((g_ifar_snr, g_missed2_snr, missed_na)),\
               np.concatenate((g_ifar_chisq, g_missed2_chisq, missed_na)),\
               np.concatenate((g_ifar_bank, g_missed2_bank, missed_na)),\
               np.concatenate((g_ifar_auto, g_missed2_auto, missed_na)),\
               np.concatenate((g_ifar_null, g_missed2_null, missed_na))] +\
              [np.concatenate((g_ifar_sngl_snr[ifo], g_missed2_sngl_snr[ifo],\
                                  missed_na)) for ifo in ifos] +\
              [np.concatenate((g_ifar_det_stat, g_missed2_det_stat,\
                                  missed_na)),\
               np.concatenate((g_ifar_spin1x, g_missed2_spin1x,\
                                  missed_inj_spin1x)),\
               np.concatenate((g_ifar_spin1y, g_missed2_spin1y,\
                                  missed_inj_spin1y)),\
               np.concatenate((g_ifar_spin1z, g_missed2_spin1z,\
                                  missed_inj_spin1z)),\
               np.concatenate((g_ifar_spin2x, g_missed2_spin2x,\
                                  missed_inj_spin2x)),\
               np.concatenate((g_ifar_spin2y, g_missed2_spin2y,\
                                  missed_inj_spin2y)),\
               np.concatenate((g_ifar_spin2z, g_missed2_spin2z,\
                                  missed_inj_spin2z))])
    td.sort(key=lambda elem: elem[0])
    logging.info("%d triggers written to file.", len(td))

    # Write to html file
    td = zip(*td)
    td = [np.asarray(d) for d in td]
    html_table = pycbc.results.html_table(td, th,
                                          format_strings=format_strings,
                                          page_size=50)
    html_path = "%s/quiet_found_injections.html" % outdir
    kwds = {'title' : "Quiet found injections",
            'caption' : "Recovered parameters and statistic values of \
            injections that are recovered, but not louder than background.",
            'cmd' :' '.join(sys.argv), }
    pycbc.results.save_fig_with_metadata(str(html_table), html_path, **kwds)

    t_missed = zip(*[g_missed2_dist] + \
                    [g_missed2_eff_site_dist[ifo] for ifo in sites] + \
                    [g_missed2_m1, g_missed2_m2, g_missed2_mchirp, g_missed2_rec_m1,
                     g_missed2_rec_m2, g_missed2_rec_mchirp, g_missed2_inc, g_missed2_ra,
                     g_missed2_dec, g_missed2_rec_ra, g_missed2_rec_dec, g_missed2_snr,
                     g_missed2_chisq, g_missed2_bank, g_missed2_auto,
                     g_missed2_null] + \
                    [g_missed2_sngl_snr[ifo] for ifo in ifos] + \
                    [g_missed2_det_stat, g_missed2_spin1x, g_missed2_spin1y,
                     g_missed2_spin1z, g_missed2_spin2x, g_missed2_spin2y,
                     g_missed2_spin2z])
    t_missed.sort(key=lambda elem: elem[0])
    logging.info("%d triggers written to file.", len(t_missed))

    t_missed = zip(*t_missed)
    t_missed = [np.asarray(d) for d in t_missed]
    html_table = pycbc.results.html_table(t_missed, th,
                                          format_strings=format_strings,
                                          page_size=50)
    html_path = "%s/missed_found_injections.html" % outdir
    kwds = {'title' : "Missed found injections",
            'caption' : "Recovered parameters and statistic values of \
            injections that are recovered, but downwieghted to BestNR = 0 \
            (i.e., vetoed).",
            'cmd' :' '.join(sys.argv), }
    pycbc.results.save_fig_with_metadata(str(html_table), html_path, **kwds)

# Post-processing of injections ends here
