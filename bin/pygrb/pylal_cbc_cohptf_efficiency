#!/usr/bin/env python

# Copyright (C) 2011 Ian W. Harry
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

# =============================================================================
# Preamble
# =============================================================================

from __future__ import division

import sys
import os
import copy
import logging
from glue.ligolw import lsctables
import pycbc.version
from pycbc.results.pygrb_postprocessing_utils import extract_ifos_and_vetoes, load_xml_file, load_xml_table, load_segment_dict, load_time_slides, load_triggers, pygrb_plot_opts_parser
import itertools
# TODO: check if the following are needed 
import matplotlib,re,optparse
import numpy as np
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from matplotlib import rc,cm,colors
import scipy
from scipy import stats
from ligo import segments
from glue import markup
from glue.ligolw import table,utils,ligolw
from pycbc.detector import Detector
import pycbc.results

# Deprecated
from pylal.coh_PTF_pyutils import get_bestnr,readSegFiles,get_f_resp
# import MultiInspiralUtils
from pylal import plotutils
# from pylal.dq import dqHTMLUtils

__author__  = "Francesco Pannarale <francesco.pannarale@ligo.org>"
__version__ = pycbc.version.git_verbose_msg
__date__ = pycbc.version.date
__program__ = "pycbc_pygrb_efficiency"

# Calculate error bars and fraction of recovered injections
# for efficiency/distance plot
def efficiency_with_errs(found_bestnr, num_injections, num_mc_injs=0):

    if not isinstance(num_mc_injs, int):
        err_msg = "The parameter num_mc_injs is the number of Monte-Carlo "
        err_msg += "injections.  It must be an integer."
        logging.error(err_msg)

    found_injs = found_bestnr[:-1]
    total_injs = num_injections[:-1]
    fraction = found_injs / total_injs

    # Divide by Monte-Carlo iterations
    if num_mc_injs:
        found_injs = found_injs / num_mc_injs
        total_injs = total_injs / num_mc_injs

    # TODO: optimize
    yerr_common  = total_injs * (2 * found_injs + 1)
    yerr_denom   = 2 * total_injs * (total_injs + 1)
    yerr_vary    = 4 * total_injs * found_injs * (total_injs - found_injs) + total_injs**2
    yerr_vary    = yerr_vary**0.5
    yerr_low     = (yerr_common - yerr_vary)/yerr_denom
    yerr_low_mc  = fraction - yerr_low
    yerr_high    = (yerr_common + yerr_vary)/yerr_denom
    yerr_high_mc = yerr_high - fraction

    return yerr_low_mc, yerr_high_mc, fraction

# =============================================================================
# Main script starts here
# =============================================================================
description = 'Efficiency calculator for the triggered search (PyGRB).'
usage = __program__ + ' [--options]'
opts = pygrb_plot_opts_parser(usage=usage, description=description, version=__version__)

if opts.verbose:
    level = logging.INFO
else:
    level = logging.WARNING
logging.basicConfig(format="%(asctime)s:%(levelname)s : %(message)s",
                    level=level)

# Check options
if opts.offsource_file == None:
    err_msg = "Please specify a path to the offsource trigger file."
    logging.error(err_msg)

if opts.veto_directory and (opts.veto_category == None):
    err_msg = "Must supply veto category if applying vetoes."
    logging.error(err_msg)
    
if (opts.found_file == None) and (opts.missed_file == None):
    opts.do_injections = False
elif (opts.found_file) and opts.missed_file:
    # TODO: do we need this option?! Should be enough to (not) provide inj_file
    opts.do_injections = True
else:
    err_msg = "Must provide both found and missed file if running injections."
    logging.error(err_msg)

if not opts.newsnr_threshold:
    opts.newsnr_threshold = opts.snr_threshold

# Store options used multiple times in local variables
outdir       = opts.output_path
trig_file    = opts.offsource_file
onsource_file = opts.onsource_file
doinj        = opts.do_injections
chisq_index = opts.chisq_index
chisq_nhigh = opts.chisq_nhigh
wf_err       = opts.waveform_error
cal_errs      = {}
cal_errs['H1']= opts.h1_cal_error
cal_errs['K1']= opts.k1_cal_error
cal_errs['L1']= opts.l1_cal_error
cal_errs['V1']= opts.v1_cal_error
cal_dc_errs       = {}
cal_dc_errs['H1'] = opts.h1_dc_cal_error
cal_dc_errs['K1'] = opts.k1_dc_cal_error
cal_dc_errs['L1'] = opts.l1_dc_cal_error
cal_dc_errs['V1'] = opts.v1_dc_cal_error
snr_thresh        = opts.snr_threshold
sngl_snr_thresh   = opts.sngl_snr_threshold
new_snr_thresh    = opts.newsnr_threshold
null_grad_thresh  = opts.null_grad_thresh
null_grad_val     = opts.null_grad_val
null_thresh       = map(float, opts.null_snr_threshold.split(','))
upper_dist        = opts.upper_inj_dist
lower_dist        = opts.lower_inj_dist
num_bins          = opts.num_bins
wav_err           = opts.waveform_error
cluster_window    = opts.cluster_window
glitch_check_fac  = opts.glitch_check_factor
num_mc_injs = opts.num_mc_injections
# Initialize random number generator
np.random.seed(opts.seed)
logging.info("Setting random seed to %d." % opts.seed)

# Set output directory
logging.info("Setting output directory")
if not os.path.isdir(outdir):
    os.makedirs(outdir)

# Extract IFOs and vetoes
logging.info("Extracting IFOs and vetoes.") 
ifos, vetoes = extract_ifos_and_vetoes(trig_file, opts.veto_directory, \
                                       opts.veto_category)

# Load triggers, time-slides, and segment dictionary
logging.info("Loading triggers")
trigs = load_xml_table(trig_file, lsctables.MultiInspiralTable.tableName)
#trigs = load_xml_table(trig_file, "multi_inspiral")
logging.info("Loading timeslides")
slide_dict = load_time_slides(trig_file)
logging.info("Loading segments")
segment_dict = load_segment_dict(trig_file)

# Identify the zero-lag slide
# TODO: turn most/all into a single function with load_time_slides?
#       load_triggers does a lot of this
num_slides = len(slide_dict)
zero_lag_count = [np.count_nonzero(slide_dict[i].values()) for i in range(num_slides)]
zero_lag_slide_id = zero_lag_count.index(0)
if np.count_nonzero(np.array(zero_lag_count)==0) != 1:
    err_msg = "slide_dict should contain exactly one zero lag slide."
    logging.err(err_msg)
    sys.exit()

logging.info("%d triggers loaded." % len(trigs))

# Get segments
segs = readSegFiles(opts.segment_dir)

# Separate segments
trial_time = abs(segs['on'])

# Construct trials
logging.info("Constructing trials")
trials = segments.segmentlist()
trial_dict = {}
sorted_trigs = {}

# Loop over the various slides
sorted_trig_count = 0
tmp_table = lsctables.New(lsctables.MultiInspiralTable)
for slide_id in range(num_slides):
    # Begin by sorting the triggers into each slide
    # It seems that New is pretty slow, so run it once and then use deepcopy
    sorted_trigs[slide_id] = copy.deepcopy(tmp_table)

for trig in trigs:
    sorted_trigs[int(trig.time_slide_id)].append(trig)

for slide_id in range(num_slides):
    sorted_trig_count += len(sorted_trigs[slide_id])

    # These can only *reduce* the analysis time
    curr_seg_list = segment_dict[slide_id]

    ###### TODO:below is a check we can possibly remove #####
    # Check the triggers are all in the analysed segment lists
    for trig in sorted_trigs[slide_id]:
        if trig.end_time not in curr_seg_list:
            # This can be raised if the trigger is on the segment boundary, so
            # check if the trigger is within 1/100 of a second within the list
            if (trig.get_end() + 0.01) in curr_seg_list:
                continue
            if (trig.get_end() - 0.01) in curr_seg_list:
                continue
            err_msg = "Triggers found in input files not in the list of "
            err_msg += "analysed segments. This should not happen."
            logging.error(err_msg)
            sys.exit()
    ###### end of check #####

    # Construct the buffer segment list
    buffer = segments.segmentlist()
    for ifo in ifos:
        slide_offset = slide_dict[slide_id][ifo]
        buffer.append(segments.segment(segs['buffer'][0] - slide_offset,\
                                       segs['buffer'][1] - slide_offset))
    buffer.coalesce() 

    # Construct the ifo list
    slid_vetoes = copy.deepcopy(vetoes)
    for ifo in ifos:
        slid_vetoes[ifo].shift(-slide_dict[slide_id][ifo])
            
        #### load_triggers uses the timeslide vetoes to veto trigs
        #### but the below will veto an entire offtrial if there is a
        #### veto that intersects with it. Could use the load_trigs function
        #### to first discard trigs that are vetoes and then additionally do the veto
        #### of entire segments below. 
        #### The below will for each timeslide, check how many 6s trials 
        #### can be constructed that don't intersect with the buffer or 
        #### vetoes. It will also throw away triggers if they fall into the 
        #### last bin that has a trial <6s. This might explain why a 
        #### really loud trigger that appears in offsource doesn't appear
        #### in the bestNRs list, or affect FAP.
        #### this is the only time the segment_dict and curr_seg_list is used
    
        # Construct trial list and check against buffer      
        trial_dict[slide_id] = segments.segmentlist()
        for curr_seg in curr_seg_list:
            iter_int = 0
            while 1:
                if (curr_seg[0] + trial_time*(iter_int+1)) > curr_seg[1]:
                    break
                curr_trial = segments.segment(curr_seg[0] + trial_time*iter_int,\
                                            curr_seg[0] + trial_time*(iter_int+1))
                if not buffer.intersects_segment(curr_trial):
                    for ifo in ifos:
                        if slid_vetoes[ifo].intersects_segment(curr_trial):
                            break
                    else:
                        trial_dict[slide_id].append(curr_trial)
                iter_int += 1
        # The below line works like the inverse of .veto and only returns trigs 
        # that are within the segment specified by trial_dict[slide_id]
        sorted_trigs[slide_id] = sorted_trigs[slide_id].vetoed(trial_dict[slide_id])

total_trials = sum([len(trial_dict[slide_id]) for slide_id in range(num_slides)]) 

msg = "Segments loaded and %d trials generated." % (total_trials)
logging.info(msg)

# Extract variables
# TODO: do something along the lines of PygrbFilterOutput
# TODO: do we really need these now the mass_bins are gone?
trig_all_time = {}
trig_all_snr = {}
trig_all_bestnr = {}
    
for slide_id in range(num_slides):
    # Get basics
    slide_trigs = sorted_trigs[slide_id]
    trig_all_time[slide_id]   = np.asarray(slide_trigs.get_end()).astype(float)
    trig_all_snr[slide_id]    = np.asarray(slide_trigs.get_column('snr'))
    trig_all_bestnr[slide_id] = [get_bestnr(t,q=chisq_index, n=chisq_nhigh,\
                                            null_thresh=null_thresh,\
                                            snr_threshold=snr_thresh,\
                                            sngl_snr_threshold=sngl_snr_thresh,\
                                            chisq_threshold=new_snr_thresh,\
                                            null_grad_thresh=null_grad_thresh,\
                                            null_grad_val=null_grad_val) \
                                 for t in slide_trigs]
    trig_all_bestnr[slide_id] = np.array(trig_all_bestnr[slide_id])

logging.info("Basic columns extracted.")

# Calculate SNR and BestNR values and maxima
trig_time   = {}
trig_snr    = {}
trig_bestnr = {}
time_bin_veto_max_snr = {}
time_bin_veto_max_bestnr = {}
time_bin_veto_max_snr_uncut = {}

for slide_id in range(num_slides):
    num_slide_segs = len(trial_dict[slide_id]) 
    trig_time[slide_id]   = {}
    trig_snr[slide_id]    = {}
    trig_bestnr[slide_id] = {}
    time_bin_veto_max_snr[slide_id] = np.zeros(num_slide_segs)
    time_bin_veto_max_bestnr[slide_id] = np.zeros(num_slide_segs)
    time_bin_veto_max_snr_uncut[slide_id] = np.zeros(num_slide_segs)

for slide_id in range(num_slides):
    # Record maxima for each trial
    # Apply cut
    trig_time[slide_id]   = trig_all_time[slide_id]
    trig_snr[slide_id]    = trig_all_snr[slide_id]
    trig_bestnr[slide_id] = trig_all_bestnr[slide_id]

    for j,trial in enumerate(trial_dict[slide_id]):
        trial_cut = (trial[0] <= trig_time[slide_id])\
                          & (trig_time[slide_id] < trial[1])
        if not trial_cut.any():  continue
        # Max SNR
        time_bin_veto_max_snr[slide_id][j] = \
                        max(trig_snr[slide_id][trial_cut])
        # Max BestNR
        time_bin_veto_max_bestnr[slide_id][j]  = \
                        max(trig_bestnr[slide_id][trial_cut])
        # Max SNR for triggers passing SBVs
        sbv_cut = trig_bestnr[slide_id]!=0
        if not (trial_cut&sbv_cut).any():  continue
        time_bin_veto_max_snr_uncut[slide_id][j] =\
                          max(trig_snr[slide_id][trial_cut & sbv_cut])

logging.info("SNR and bestNR maxima calculated.")

# Calculate and print fraction of trials with an event (highest FAP value)
num_events = 0
for slide_id in range(num_slides):
    for trial in range(len(trial_dict[slide_id])):
        if time_bin_veto_max_bestnr[slide_id][trial] > 0:
            num_events += 1
quietest_file=open('%s/quiet_fap_val.txt' % outdir,'w')
quietest_file.write('%s' % (num_events/total_trials))
quietest_file.close()

# Output details of (at most) 30 loudest offsouce triggers
# TODO: Do we really want this hard-coded 30?
offsource_trigs = []
for slide_id in range(num_slides):
    trial_endtimes = [s[1] for s in trial_dict[slide_id]]
    trig_endtimes = [trig.get_end() for trig in sorted_trigs[slide_id]]
    trial_ids = np.searchsorted(trial_endtimes, trig_endtimes)
    offsource_trigs.extend(zip(trig_all_bestnr[slide_id],sorted_trigs[slide_id], trial_ids))
    # offsource_trigs.extend(zip(trig_all_bestnr[slide_id],sorted_trigs[slide_id]))
offsource_trigs.sort(key = lambda element:element[0])
offsource_trigs.reverse()

#TODO: we also want the templates spin1z and spin2z. Do this after switch to hdf5
# th: table header
th = [ 'Trial', 'Slide Num', 'FAP', 'GPS',\
       'Rec. m1', 'Rec. m2', 'Rec. Mc',\
       'Rec. RA','Rec. Dec', 'SNR', 'Chi^2', 'Bank veto', 'Auto veto',\
       'Null SNR' ]
th.extend([ '%s SNR' % ifo for ifo in ifos ])
th.extend([ '%s time shift (s)' % ifo for ifo in ifos ])
th.append('BestNR')
# td: table data
td = []

# This is in PygrbFilterOutput
ifo_att = {'G1':'g', 'H1':'h1', 'H2':'h2', 'L1':'l', 'V1':'v', 'T1':'t'}
for i in range(min(len(offsource_trigs), 30)):
    bestnr = offsource_trigs[i][0]
    trig = offsource_trigs[i][1]
    trig_slide_id = int(trig.time_slide_id)

    # Get trial of trigger, triggers with 'No trial' should have been removed!
    for j,trial in enumerate(trial_dict[trig_slide_id]):
        if trig.get_end() in trial:
            chunk_num = j
            break
    else:
        chunk_num = 'No trial'

    # Get FAP of trigger
    num_trials_louder = 0
    for slide_id in range(num_slides):
        for val in time_bin_veto_max_bestnr[slide_id]:
            if val > bestnr:
                num_trials_louder += 1
    FAP = num_trials_louder/total_trials
    pval = '< %.3g' % (1./total_trials) if FAP==0 else '%.3g' % FAP

    # Get null SNR of trigger
    null_snr = trig.get_null_snr()

    # TODO: trigger spin1z and spin2z wanted
    d = [ chunk_num, trig_slide_id, pval,\
          '%.4f' % trig.get_end(),\
          '%.2f' % trig.mass1, '%.2f' % trig.mass2, '%.2f' % trig.mchirp,\
          '%.2f' % (np.degrees(trig.ra)), '%.2f'% (np.degrees(trig.dec)),\
          '%.2f' % trig.snr, '%.2f' % trig.chisq, '%.2f' % trig.bank_chisq,\
          '%.2f' % trig.cont_chisq, '%.2f' % null_snr ]
    d.extend([ '%.2f' % getattr(trig,'snr_%s' % ifo_att[ifo])\
                          for ifo in ifos ])
    d.extend([ slide_dict[trig_slide_id][ifo] for ifo in ifos])
    d.append('%.2f' % bestnr)

# Write to html file 
# TODO (holds for most htmls below too): make this table sortable by column and not static
html = pycbc.results.dq.redirect_javascript + str(pycbc.results.static_table(td, th))
# TODO (hold for most htmls below too): Should pass output_file arg on command line and put this in a seperate executable
title = 'Parameters of loudest offsource triggers'
caption = ('Parameters of 30 loudest offsource triggers.')
pycbc.results.save_fig_with_metadata(html, "%s/loudest_offsource_trigs.html" % outdir, 
                                           {},
                                           cmd=' '.join(sys.argv),
                                           title=title,
                                           caption=caption)

# ==========================
# print loudest SNRs to file
# THIS OUTPUT FILE IS CURRENTLY UNUSED - MAYBE DELETE? 
# note: the only new info from above is the median SNR, bestNR
# and loudest SNR, so could just add this to the above's caption.
# ==========================
# TODO: very similar lines of code are repeated 3-4 times

th = ['','SNR','BestNR']
td = []

full_time_bin_veto_max_snr = []
full_time_bin_veto_max_snr_uncut = []
full_time_bin_veto_max_bestnr = []
for slide_id in range(num_slides):
    full_time_bin_veto_max_snr.extend(time_bin_veto_max_snr[slide_id])
    full_time_bin_veto_max_snr_uncut.extend(\
                    time_bin_veto_max_snr_uncut[slide_id])
    full_time_bin_veto_max_bestnr.extend(time_bin_veto_max_bestnr[slide_id])
full_time_bin_veto_max_snr.sort()
full_time_bin_veto_max_snr_uncut.sort()
full_time_bin_veto_max_bestnr.sort()

max_snr = max([trig_snr[slide_id].max() if len(trig_snr[slide_id]) else 0 for slide_id in range(num_slides)])
max_bestnr = max([trig_bestnr[slide_id].max() if len(trig_snr[slide_id]) else 0 for slide_id in range(num_slides)])

if (total_trials % 2):
    median_snr = full_time_bin_veto_max_snr[(total_trials - 1) // 2]
    median_bestnr = full_time_bin_veto_max_bestnr[(total_trials - 1) // 2]
else:
    median_snr = np.mean( (full_time_bin_veto_max_snr)\
                                                    [total_trials//2 - 1 : total_trials//2 + 1])
    median_bestnr = np.mean( (full_time_bin_veto_max_bestnr)\
                                                    [total_trials//2 - 1 : total_trials//2 + 1])


d = [ 'Loudest ', max_snr, max_bestnr ]
td.append(d)
d = [ 'Median ', median_snr, median_bestnr ]
td.append(d)
td.append([]) 

# Write html table with results
html = pycbc.results.dq.redirect_javascript + str(pycbc.results.static_table(td, th))
title = 'Re-weighted SNR and SNR of the loudest and median offsource trigger'
caption = ('Re-weighted SNR and SNR of the loudest and median offsource trigger')
pycbc.results.save_fig_with_metadata(html, "%s/loudest_median_offsource.html" % outdir, 
                                           {},
                                           cmd=' '.join(sys.argv),
                                           title=title,
                                           caption=caption)

# Store BestNR and FAP values
np.savetxt('%s/bestnr_vs_fap_numbers.txt' %(outdir),
           full_time_bin_veto_max_bestnr, delimiter='/t')

# =======================
# Load on source triggers
# ======================= 
if onsource_file:

    # Get trigs
    on_trigs = load_xml_table(onsource_file, "multi_inspiral")
    msg = "%d onsource triggers loaded." % (len(on_trigs))

    # Separate off chirp mass column
    on_mchirp = on_trigs.get_column('mchirp')

    # Set loudest event arrays
    # TODO: are these necessary?
    loud_on_bestnr_trigs = None
    loud_on_snr_trigs    = None
    loud_on_bestnr       = 0
    loud_on_fap          = 1
    loud_on_snr          = 0

    # Record loudest trig by SNR and by BestNR
    bin_trigs = sorted(np.asarray(on_trigs), key=lambda t: t.snr, reverse=True)
    loud_on_snr_trigs = bin_trigs[0]
    loud_on_snr       = bin_trigs[0].snr
    bin_trigs.sort(key=lambda t: get_bestnr(t, q=chisq_index, n=chisq_nhigh,\
                                            null_thresh=null_thresh,snr_threshold=snr_thresh,\
                                            sngl_snr_threshold = sngl_snr_thresh,\
                                            chisq_threshold = new_snr_thresh,\
                                            null_grad_thresh = null_grad_thresh,\
                                            null_grad_val = null_grad_val),   reverse=True)
    loud_on_bestnr_trigs = bin_trigs[0]
    loud_on_bestnr = get_bestnr(bin_trigs[0], q=chisq_index,\
                                null_thresh=null_thresh,snr_threshold=snr_thresh,\
                                sngl_snr_threshold = sngl_snr_thresh,\
                                chisq_threshold = new_snr_thresh,n=chisq_nhigh,\
                                null_grad_thresh = null_grad_thresh,\
                                null_grad_val = null_grad_val)
    # If the loudest event has bestnr = 0, there is no event at all!
    if loud_on_bestnr == 0:
        loud_on_bestnr_trigs = None
        loud_on_bestnr = 0 

    logging.info("Onsource analysed.")

    # Table header and table data
    # TODO we will want the spins too (easier to deal with after move to hdf5)
    th = ['FAP', 'GPS', 'Rec. m1', 'Rec. m2', 'Rec. Mc', 'Rec. RA',\
          'Rec. Dec', 'SNR', 'Chi^2', 'Bank veto', 'Auto veto', 'Null SNR'] +\
         ['%s SNR' % ifo for ifo in ifos ] + ['BestNR']
    td = [] 

    if loud_on_bestnr_trigs:
        trig = loud_on_bestnr_trigs
        num_trials_louder = 0
        tot_off_snr = np.array([])
        for slide_id in range(num_slides):
            num_trials_louder += sum(time_bin_veto_max_bestnr[slide_id] > \
                                     loud_on_bestnr)
            tot_off_snr = np.concatenate([tot_off_snr,time_bin_veto_max_bestnr[slide_id]])
        fap = num_trials_louder/total_trials
        fap_test = sum(tot_off_snr>loud_on_bestnr)/total_trials
        pval = '< %.3g' % (1./total_trials) if fap==0 else '%.3g' % fap
        loud_on_fap = fap
        # TODO: spins of template
        d = [pval, trig.get_end(),\
             trig.mass1, trig.mass2, trig.mchirp,\
             np.degrees(trig.ra), np.degrees(trig.dec),\
             trig.snr, trig.chisq, trig.bank_chisq,\
             trig.cont_chisq, null_snr] + \
             [trig.get_sngl_snr(ifo) for ifo in ifos] + [loud_on_bestnr]
        file2.write('%s\n' % pval.replace('<', '&lt'))
        td.append(d)

    else:
        td.append(["There are no events"])
        file2.write('-2\n')


    # Write to html file 
    html = pycbc.results.dq.redirect_javascript + str(pycbc.results.static_table(td, th))
    title = 'Loudest event'
    caption = ('Recovered parameters and statistic values of the loudest trigger')
    pycbc.results.save_fig_with_metadata(html, "%s/loudest_events.html" % outdir, 
                                               {},
                                               cmd=' '.join(sys.argv),
                                               title=title,
                                               caption=caption)
else:
    tot_off_snr = np.array([])
    for slide_id in range(num_slides):
        tot_off_snr = np.concatenate([tot_off_snr,time_bin_veto_max_bestnr[slide_id]])
    med_snr = np.median(tot_off_snr)
    fap = sum(tot_off_snr>med_snr)/total_trials


# Make the cumulative histogram FAP plots
# TODO: all plots should be calls to function(s)
# pygrb_shared_plot_setups()


    # Triggers and injections recovered in some form
    found_trigs_nveto = MultiInspiralUtils.ReadMultiInspiralFromFiles([found_file])
    found_injs_no_veto = SimInspiralUtils.ReadSimInspiralFromFiles([found_file])

    found_trigs = lsctables.New(lsctables.MultiInspiralTable)
    found_injs = lsctables.New(lsctables.SimInspiralTable)

    for trig,sim in zip(found_trigs_nveto,found_injs_no_veto):
        if sim.get_end() not in vetoes.union(vetoes.keys()):
            found_injs.append(sim)
            found_trigs.append(trig)

    logging.info("Missed/found injections/triggers loaded.")

    # Extract columns of found injections and triggers
    found_inj_time   = np.asarray(found_injs.get_column('geocent_end_time')) +\
                       np.asarray(found_injs.get_column('geocent_end_time_ns')*\
                                  10**-9)
    found_inj_mchirp   = np.asarray(found_injs.get_column('mchirp'))
    found_inj_mtot     = np.asarray(found_injs.get_column('mtotal'))
    found_inj_m1       = np.asarray(found_injs.get_column('mass1'))
    found_inj_m2       = np.asarray(found_injs.get_column('mass2'))
    found_inj_eff_site_dist =\
        dict((ifo, found_injs.get_column('eff_dist_%s' % ifo.lower()))\
             for ifo in sites)
    found_inj_eff_dist  = np.power(np.power(\
                                  np.asarray(found_inj_eff_site_dist.values()),-1)\
                                .sum(0),-1)
    found_inj_ra       = np.asarray(found_injs.get_column('longitude'))
    found_inj_dec      = np.asarray(found_injs.get_column('latitude'))
    found_inj_dist     = np.asarray(found_injs.get_column('distance'))
    found_inj_inc      = np.asarray(found_injs.get_column('inclination'))
    found_inj_spin1x   = np.asarray(found_injs.get_column('spin1x'))
    found_inj_spin1y   = np.asarray(found_injs.get_column('spin1y'))
    found_inj_spin1z   = np.asarray(found_injs.get_column('spin1z'))
    found_inj_spin2x   = np.asarray(found_injs.get_column('spin2x'))
    found_inj_spin2y   = np.asarray(found_injs.get_column('spin2y'))
    found_inj_spin2z   = np.asarray(found_injs.get_column('spin2z'))

    # TODO: a lot of this is identical to all the stuff above
    found_trig_mchirp  = np.asarray(found_trigs.get_column('mchirp'))
    found_trig_m1       = np.asarray(found_trigs.get_column('mass1'))
    found_trig_m2       = np.asarray(found_trigs.get_column('mass2'))
    found_trig_ra       = np.asarray(found_trigs.get_column('ra'))
    found_trig_dec      = np.asarray(found_trigs.get_column('dec'))
    found_sky_angle     = np.arccos(np.cos(found_inj_dec - found_trig_dec) -\
                               np.cos(found_inj_dec)* np.cos(found_trig_dec) *\
                               (1 - np.cos(found_inj_ra - found_trig_ra)))
    found_trig_snr      = np.asarray(found_trigs.get_column('snr'))
    found_trig_chisq    = np.asarray(found_trigs.get_column('chisq'))
    found_trig_bank     = np.asarray(found_trigs.get_column('bank_chisq'))
    found_trig_auto     = np.asarray(found_trigs.get_column('cont_chisq'))
    found_trig_null_snr = np.asarray(found_trigs.get_null_snr())
    found_trig_sngl_snr = dict((ifo, np.asarray(found_trigs.get_sngl_snr(ifo)))\
                            for ifo in ifos)
 
    # Grab values of detection statistic 
    found_trig_bestnr  = [get_bestnr(t,q=chisq_index, n=chisq_nhigh,\
                             null_thresh=null_thresh,snr_threshold=snr_thresh,\
                             sngl_snr_threshold = sngl_snr_thresh,\
                             chisq_threshold = new_snr_thresh,\
                             null_grad_thresh = null_grad_thresh,\
                             null_grad_val = null_grad_val) for t in found_trigs]
    found_trig_bestnr   = np.asarray(found_trig_bestnr)

    # Construct conditions for injection:
    # 1) found louder than background,
    zero_fap = np.zeros(len(found_injs)).astype(np.bool)
    zero_fap_cut = found_trig_bestnr > max_bestnr
    zero_fap    = zero_fap | (zero_fap_cut)

    # 2) found (bestnr > 0) but not louder than background (non-zero FAP)
    nonzero_fap = ~zero_fap & (found_trig_bestnr!=0)

    # 3) missed after being recovered (i.e., vetoed)
    missed = (~zero_fap) & (~nonzero_fap)

    # Separate triggers into:
    # 1) zero_fap 'g_found'
    # 2) nonzero_fap 'g_ifar'
    # 3) missed because of vetoes 'g_missed2'
      
    # Zero FAP
    g_found_mchirp      = found_inj_mchirp[zero_fap]
    g_found_mtot        = found_inj_mtot[zero_fap]
    g_found_m1          = found_inj_m1[zero_fap]
    g_found_m2          = found_inj_m2[zero_fap]
    g_found_eff_site_dist = dict((ifo, found_inj_eff_site_dist[ifo][zero_fap])\
                             for ifo in sites)
    g_found_eff_dist    = found_inj_eff_dist[zero_fap]
    g_found_det_stat    = found_trig_bestnr[zero_fap]
    g_found_dist        = found_inj_dist[zero_fap]
    g_found_time        = found_inj_time[zero_fap]
    g_found_sky_angle   = found_sky_angle[zero_fap]
    g_found_inc         = found_inj_inc[zero_fap]
    g_found_spin1x      = found_inj_spin1x[zero_fap]
    g_found_spin1y      = found_inj_spin1y[zero_fap]
    g_found_spin1z      = found_inj_spin1z[zero_fap]
    g_found_spin2x      = found_inj_spin2x[zero_fap]
    g_found_spin2y      = found_inj_spin2y[zero_fap]
    g_found_spin2z      = found_inj_spin2z[zero_fap]

    # Non-zero FAP
    g_ifar_mchirp        = found_inj_mchirp[nonzero_fap]
    g_ifar_mtot          = found_inj_mtot[nonzero_fap]
    g_ifar_m1            = found_inj_m1[nonzero_fap]
    g_ifar_m2            = found_inj_m2[nonzero_fap]
    g_ifar_eff_site_dist = dict((ifo, found_inj_eff_site_dist[ifo][nonzero_fap])\
                              for ifo in sites)
    g_ifar_eff_dist      = found_inj_eff_dist[nonzero_fap]
    g_ifar_det_stat      = found_trig_bestnr[nonzero_fap]
    g_ifar_dist          = found_inj_dist[nonzero_fap]
    g_ifar_time          = found_inj_time[nonzero_fap]
    g_ifar_sky_angle     = found_sky_angle[nonzero_fap]
    g_ifar_inc           = found_inj_inc[nonzero_fap]
    g_ifar_spin1x        = found_inj_spin1x[nonzero_fap]
    g_ifar_spin1y        = found_inj_spin1y[nonzero_fap]
    g_ifar_spin1z        = found_inj_spin1z[nonzero_fap]
    g_ifar_spin2x        = found_inj_spin2x[nonzero_fap]
    g_ifar_spin2y        = found_inj_spin2y[nonzero_fap]
    g_ifar_spin2z        = found_inj_spin2z[nonzero_fap]
    g_ifar_ra            = found_inj_ra[nonzero_fap]
    g_ifar_dec           = found_inj_dec[nonzero_fap]

    g_ifar_trig          = np.asarray(found_trigs)[nonzero_fap]
    g_ifar_inj           = np.asarray(found_injs)[nonzero_fap]

    g_ifar_stat          = np.zeros([len(g_ifar_det_stat)])
    for ix, ( mc, bestnr ) in \
                enumerate(zip(found_trig_mchirp[nonzero_fap], g_ifar_det_stat)):
        g_ifar_stat[ix] = (full_time_bin_veto_max_bestnr > bestnr).sum()
    g_ifar_stat = g_ifar_stat / total_trials
    # Statistics: missed-found
    MF = np.argsort(g_ifar_stat)
    # Statistics: found-missed
    FM = MF[::-1]

    g_ifar_rec_m1       = found_trig_m1[nonzero_fap]
    g_ifar_rec_m2       = found_trig_m2[nonzero_fap]
    g_ifar_rec_mchirp   = found_trig_mchirp[nonzero_fap]
    g_ifar_rec_ra       = found_trig_ra[nonzero_fap]
    g_ifar_rec_dec      = found_trig_dec[nonzero_fap]
    g_ifar_snr          = found_trig_snr[nonzero_fap]
    g_ifar_chisq        = found_trig_chisq[nonzero_fap]
    g_ifar_bank         = found_trig_bank[nonzero_fap]
    g_ifar_auto         = found_trig_auto[nonzero_fap]
    g_ifar_null         = found_trig_null_snr[nonzero_fap]
    g_ifar_sngl_snr     = dict((ifo, found_trig_sngl_snr[ifo][nonzero_fap])\
                               for ifo in ifos)

    # Missed due to vetoes
    g_missed2_mchirp     = found_inj_mchirp[missed]
    g_missed2_mtot       = found_inj_mtot[missed]
    g_missed2_m1         = found_inj_m1[missed]
    g_missed2_m2         = found_inj_m2[missed]
    g_missed2_eff_site_dist = dict((ifo, found_inj_eff_site_dist[ifo][missed])\
                                   for ifo in sites)
    g_missed2_eff_dist   = found_inj_eff_dist[missed]
    g_missed2_det_stat   = found_trig_bestnr[missed]
    g_missed2_dist       = found_inj_dist[missed]
    g_missed2_time       = found_inj_time[missed]
    g_missed2_sky_angle  = found_sky_angle[missed]
    g_missed2_inc        = found_inj_inc[missed]
    g_missed2_spin1x     = found_inj_spin1x[missed]
    g_missed2_spin1y     = found_inj_spin1y[missed]
    g_missed2_spin1z     = found_inj_spin1z[missed]
    g_missed2_spin2x     = found_inj_spin2x[missed]
    g_missed2_spin2y     = found_inj_spin2y[missed]
    g_missed2_spin2z     = found_inj_spin2z[missed]
    g_missed2_ra         = found_inj_ra[missed]
    g_missed2_dec        = found_inj_dec[missed]

    g_missed2_trig       = np.asarray(found_trigs)[missed]
    g_missed2_inj        = np.asarray(found_injs)[missed]

    g_missed2_rec_m1     = found_trig_m1[missed]
    g_missed2_rec_m2     = found_trig_m2[missed]
    g_missed2_rec_mchirp = found_trig_mchirp[missed]
    g_missed2_rec_ra     = found_trig_ra[missed]
    g_missed2_rec_dec    = found_trig_dec[missed]
    g_missed2_snr        = found_trig_snr[missed]
    g_missed2_chisq      = found_trig_chisq[missed]
    g_missed2_bank       = found_trig_bank[missed]
    g_missed2_auto       = found_trig_auto[missed]
    g_missed2_null       = found_trig_null_snr[missed]
    g_missed2_sngl_snr   = dict((ifo, found_trig_sngl_snr[ifo][missed])\
                                for ifo in ifos)

    # Set the sigma values
    inj_sigma = found_trigs.get_sigmasqs()
    # If the sigmasqs are not populated, we can still do calibration errors,
    # but only in the 1-detector case
    for ifo in ifos:
        if sum(inj_sigma[ifo] == 0):
            logging.info("%s: sigmasq not set for at least "
                                         "one trigger." % ifo)
        if sum(inj_sigma[ifo] != 0) == 0: 
            logging.info("%s: sigmasq not set for any "
                                         "trigger." % ifo)
            if len(ifos) == 1:
                msg = "This is a single ifo analysis. "
                msg += "Setting sigmasq to unity for all triggers."
                logging.info(msg)
                injSigma[ifo][:] = 1.

    f_resp = dict((ifo, np.asarray([get_f_resp(inj)[ifo] \
                   for inj in found_injs]))  for ifo in ifos)

    inj_sigma_mult  = (np.asarray(inj_sigma.values()) *\
                       np.asarray(f_resp.values()))

    inj_sigma_tot = inj_sigma_mult[0,:]
    for i in range(1,len(ifos)):
        inj_sigma_tot += inj_sigma_mult[i,:]

    inj_sigma_mean = {}
    for ifo in ifos:
        inj_sigma_mean[ifo] = ((inj_sigma[ifo]*f_resp[ifo])/inj_sigma_tot).mean()

    logging.info("%d found injections analysed." % (len(found_injs)))

    # Missed injections (ones not recovered at all)
    missed_injs = SimInspiralUtils.ReadSimInspiralFromFiles([missed_file])\
            .veto(vetoes.union(vetoes.keys()))

    # Process missed injections 'missed_inj'
    missed_inj_mchirp = np.asarray(missed_injs.get_column('mchirp'))
    missed_inj_eff_site_dist =\
        dict((ifo, missed_injs.get_column('eff_dist_%s' % ifo.lower()))\
             for ifo in sites)
    missed_inj_eff_dist = np.power(np.power(\
                                   np.asarray(missed_inj_eff_site_dist.values()),-1)\
                                   .sum(0),-1)
    missed_inj_dist     = np.asarray(missed_injs.get_column('distance'))
    missed_inj_time     = np.asarray(missed_injs.get_column('geocent_end_time') +\
                                     missed_injs.get_column('geocent_end_time_ns') *\
                                     10**-9)
    missed_inj_m1       = np.asarray(missed_injs.get_column('mass1'))
    missed_inj_m2       = np.asarray(missed_injs.get_column('mass2'))
    missed_inj_inc      = np.asarray(missed_injs.get_column('inclination'))
    missed_inj_ra       = np.asarray(missed_injs.get_column('longitude'))
    missed_inj_dec      = np.asarray(missed_injs.get_column('latitude'))

    missed_inj_spin1x   = np.asarray(missed_injs.get_column('spin1x'))
    missed_inj_spin1y   = np.asarray(missed_injs.get_column('spin1y'))
    missed_inj_spin1z   = np.asarray(missed_injs.get_column('spin1z'))
    missed_inj_spin2x   = np.asarray(missed_injs.get_column('spin2x'))
    missed_inj_spin2y   = np.asarray(missed_injs.get_column('spin2y'))
    missed_inj_spin2z   = np.asarray(missed_injs.get_column('spin2z'))

    missed_na           = ['N/A'] * len(missed_injs)

    if len(missed_inj_m1):
        min_missed_inj_m1 = missed_inj_m1.min()
        max_missed_inj_m1 = missed_inj_m1.max()
        min_missed_inj_m2 = missed_inj_m2.min()
        max_missed_inj_m2 = missed_inj_m2.max()
    else:
        min_missed_inj_m1 = 1e3
        max_missed_inj_m1 = 0
        min_missed_inj_m2 = 1e3
        max_missed_inj_m2 = 0

    if len(missed_inj_spin1x):
        missed_inj_spin1 = np.sqrt(missed_inj_spin1x**2 + missed_inj_spin1y**2 + \
                                   missed_inj_spin1z**2)
        missed_inj_spin2 = np.sqrt(missed_inj_spin2x**2 + missed_inj_spin2y**2 + \
                                   missed_inj_spin2z**2)
        min_missed_inj_spin1 = missed_inj_spin1.min()
        max_missed_inj_spin1 = missed_inj_spin1.max()
        min_missed_inj_spin2 = missed_inj_spin2.min()
        max_missed_inj_spin2 = missed_inj_spin2.max()
    else:
        min_missed_inj_spin1 = 1
        max_missed_inj_spin1 = 0
        min_missed_inj_spin2 = 1
        max_missed_inj_spin2 = 0
    
    logging.info("%d missed injections analysed." % (len(missed_injs)))

    # Write inclination recovery to file
    # TODO: some times had the grb_time, others did not. Now we have both.
    grb_time = segs['on'][1] - 1 # GRB start time
    f = open('%s/found_inclinations.txt' % outdir, 'w')
    f.write('GPS time\tTime since %d\tInclination\n\n' % grb_time)
    stacked = np.column_stack([g_found_time,
                               g_found_time - grb_time,
                               g_found_inc])
    np.savetxt(f, stacked, delimiter='\t')
    f.close()
    f = open('%s/total_inclinations.txt' % outdir, 'w')
    f.write('GPS time\tTime since %d\tInclination\n\n' % grb_time)
    stacked = np.column_stack([np.concatenate((found_inj_time, missed_inj_time)),
                               np.concatenate((found_inj_time - grb_time,
                                               missed_inj_time - grb_time)),
                               np.concatenate((found_inj_inc, missed_inj_inc))])
    np.savetxt(f, stacked, delimiter='\t')
    f.close()

    # Create new set of injections for efficiency calculations
    total_injs = len(found_injs) + len(missed_injs)
    long_inj_dist = stats.uniform.rvs(size=total_injs) * (upper_dist-lower_dist) +\
                  upper_dist

    logging.info("%d long distance injections created." % (total_injs))

    # Set distance bins and data arrays 
    dist_bins = zip(np.arange(lower_dist, upper_dist + (upper_dist-lower_dist) ,\
                             (upper_dist-lower_dist)/num_bins),\
                   np.arange(lower_dist,upper_dist + (upper_dist-lower_dist),\
                             (upper_dist-lower_dist)/num_bins) +\
                             (upper_dist-lower_dist)/num_bins)

    num_injections         = np.zeros([len(dist_bins)+1])
    found_max_bestnr       = np.zeros([len(dist_bins)+1])
    found_on_bestnr        = np.zeros([len(dist_bins)+1])
    num_injections_no_mc   = np.zeros([len(dist_bins)+1])
    found_max_bestnr_no_mc = np.zeros([len(dist_bins)+1])
    found_on_bestnr_no_mc  = np.zeros([len(dist_bins)+1])

    # Construct FAP list for all found injections
    inj_fap = np.zeros(len(found_injs))
    inj_fap[nonzero_fap] = g_ifar_stat

    # Calculate the amplitude error
    # Begin by calculating the components from each detector
    cal_error = 0
    for ifo in ifos:
        cal_error += cal_errs[ifo]**2 * inj_sigma_mean[ifo]**2
    cal_error = cal_error**0.5

    max_dc_cal_error = max(cal_dc_errs.values())

    # Calibration phase uncertainties are neglected
    logging.info("Calibration amplitude uncertainty calculated.")

    # Now create the numbers for the efficiency plots; these include calibration
    # and waveform errors. These are incorporated by running over each injection
    # 100 times, where each time we draw a random value of distance

    # Distribute injections
    found_inj_dist_mc       = np.ndarray((num_mc_injs+1, len(found_injs)))
    found_inj_dist_mc[0,:]  = found_inj_dist
    missed_inj_dist_mc      = np.ndarray((num_mc_injs+1, len(missed_injs)))
    missed_inj_dist_mc[0,:] = missed_inj_dist
    long_inj_dist_mc        = np.ndarray((num_mc_injs+1, total_injs))
    long_inj_dist_mc[0,:]   = long_inj_dist
    for i in range(num_mc_injs):
        # TODO: these is a copy and paste of 3 lines of code
        cal_dist_red = stats.norm.rvs(size=len(found_injs)) * cal_error
        wav_dist_red = np.abs(stats.norm.rvs(size=len(found_injs)) * wav_err)
        found_inj_dist_mc[i+1,:] = found_inj_dist / (max_dc_cal_error * \
                                     (1 + cal_dist_red) * (1 + wav_dist_red))
        cal_dist_red = stats.norm.rvs(size=len(missed_injs)) * cal_error
        wav_dist_red = np.abs(stats.norm.rvs(size=len(missed_injs)) * wav_err)
        missed_inj_dist_mc[i+1,:] = missed_inj_dist / (max_dc_cal_error *\
                                     (1 + cal_dist_red) * (1 + wav_dist_red))
        cal_dist_red = stats.norm.rvs(size=total_injs) * cal_error
        wav_dist_red = np.abs(stats.norm.rvs(size=total_injs) * wav_err)
        long_inj_dist_mc[i+1,:] = long_inj_dist / (max_dc_cal_error *\
                                     (1 + cal_dist_red) * (1 + wav_dist_red))

    logging.info("MC injection set distributed with %d "\
                                 "iterations." % (num_mc_injs, ))

    # Check injections against on source
    # TODO: Refactor this
    if onsource_file:
        more_sig_than_onsource = np.ndarray(len(found_injs))
        more_sig_than_onsource = (inj_fap <= loud_on_fap)
        more_sig_than_onsource = more_sig_than_onsource.all(0)
    else:
        more_sig_than_onsource = np.ndarray(len(found_injs))
        more_sig_than_onsource = (inj_fap <= 0.5)
        more_sig_than_onsource = more_sig_than_onsource.all(0)

    distance_count = np.zeros(len(dist_bins))

    found_trig_max_bestnr = np.zeros([len(found_trig_mchirp)])
    for ix, mc in enumerate(found_trig_mchirp):
        found_trig_max_bestnr[ix] = max_bestnr

    max_bestnr_cut = (found_trig_bestnr > found_trig_max_bestnr)

    # Check louder than on source
    if onsource_file:
        # TODO: basically the same code as above
        found_trig_loud_on_bestnr = np.zeros([len(found_trig_mchirp)])
        for ix, mc in enumerate(found_trig_mchirp):
            found_trig_loud_on_bestnr[ix] = loud_on_bestnr
    else:
        found_trig_loud_on_bestnr = np.zeros([len(found_trig_mchirp)])
        for ix, mc in enumerate(found_trig_mchirp):
            found_trig_loud_on_bestnr[ix] = med_snr
    on_bestnr_cut  = found_trig_bestnr > found_trig_loud_on_bestnr

    # Check whether injection is found for the purposes of exclusion
    # distance calculation.
    # Found: if louder than all on source
    # Missed: if not louder than loudest on source
    found_excl = on_bestnr_cut & (more_sig_than_onsource) & \
                (found_trig_bestnr != 0)
    # If not missed, double check bestnr against nearby triggers
    near_test = np.zeros((found_excl).sum()).astype(bool)
    for j,(t,bestnr) in enumerate(zip(found_inj_time[found_excl],\
                                      found_trig_bestnr[found_excl])):
        near_bestnr  = trig_all_bestnr[zero_lag_slide_id]\
                      [np.abs(trig_all_time[zero_lag_slide_id]-t) < cluster_window]
        near_test[j] = ~((near_bestnr * glitch_check_fac > bestnr).any())
    # Apply the local test
    # FIXME: putmask does not seem to work...
    #np.putmask(found_excl, found_excl==True, near_test)
    c = 0
    for z,b in enumerate(found_excl):
        if found_excl[z]:
            found_excl[z] = near_test[c]
            c += 1

    # Loop over each random instance of the injection set
    for k in range(num_mc_injs+1): 
        # Loop over the distance bins
        for j,dist_bin in enumerate(dist_bins):
            # Construct distance cut
            found_dist_cut  = (dist_bin[0] <= found_inj_dist_mc[k,:]) &\
                              (found_inj_dist_mc[k,:] < dist_bin[1])
            missed_dist_cut = (dist_bin[0] <= missed_inj_dist_mc[k,:]) &\
                              (missed_inj_dist_mc[k,:] < dist_bin[1])
            long_dist_cut   = (dist_bin[0] <= long_inj_dist_mc[k,:]) &\
                              (long_inj_dist_mc[k,:] < dist_bin[1])

            # Count all injections in this distance bin
            num_found_pass  = (found_dist_cut).sum()
            num_missed_pass = (missed_dist_cut).sum()
            num_long_pass   = long_dist_cut.sum() or 0
            # Count only zero FAR injections
            num_zero_far = (found_dist_cut & max_bestnr_cut).sum()
            # Count number found for exclusion
            num_excl = (found_dist_cut & (found_excl)).sum()

            # Record number of injections, number found for exclusion
            # and number of zero FAR
            # TODO: serial coding (and redundant items?)
            if k == 0:
                num_injections_no_mc[j]    += num_found_pass + num_missed_pass +\
                                              num_long_pass
                num_injections_no_mc[-1]   += num_found_pass + num_missed_pass +\
                                              num_long_pass
                found_max_bestnr_no_mc[j]  += num_zero_far
                found_max_bestnr_no_mc[-1] += num_zero_far
                found_on_bestnr_no_mc[j]   += num_excl
                found_on_bestnr_no_mc[-1]  += num_excl
            else:
                num_injections[j]          += num_found_pass + num_missed_pass +\
                                              num_long_pass
                num_injections[-1]         += num_found_pass + num_missed_pass +\
                                              num_long_pass
                found_max_bestnr[j]        += num_zero_far
                found_max_bestnr[-1]       += num_zero_far
                found_on_bestnr[j]         += num_excl
                found_on_bestnr[-1]        += num_excl
 
    np.savetxt('%s/found_maxbestnr.txt' % outdir, found_max_bestnr.T)
    np.savetxt('%s/found_maxbestnrnomc.txt' % outdir, found_max_bestnr_no_mc.T)
    np.savetxt('%s/foundonbestnr.txt' % outdir, found_on_bestnr.T)
    np.savetxt('%s/foundonbestnrnomc.txt' % outdir, found_on_bestnr_no_mc.T)
    np.savetxt('%s/numinjections.txt' % outdir, num_injections.T)
    np.savetxt('%s/numinjectionsnomc.txt' % outdir, num_injections_no_mc.T)
    file = open("%s/injection_recovery.html" % outdir, "w")
    file.write("Total injections found louder than all background using %s "\
               "is: %s<br>\n" % ('BestNR', found_max_bestnr[-1]))
    file.write("Total injections found louder than all background (and "\
               "nearby triggers in the offsource) using %s is: %s<br>"\
               % ('BestNR', found_on_bestnr[-1]))
    file.close()

    logging.info("Found/missed injection efficiency calculations completed.")

    # Write data to files

    # Get start and end times
    start = int(min(np.concatenate((found_inj_time,missed_inj_time))))
    end   = int(max(np.concatenate((found_inj_time,missed_inj_time))))
    duration = end - start
    # Pad times and reset to centre on zero
    start = start - duration*0.05 - grb_time
    end   = end + duration*0.05 - grb_time
    missed_inj_time = missed_inj_time - grb_time
    g_missed2_time -= grb_time
    g_found_time   -= grb_time
    g_ifar_time    -= grb_time

    # Write quiet triggers to file      
    th = ['Num', 'Dist'] + ['Eff. Dist. %s' % site for site in sites] +\
         ['Inj. m1', 'Inj. m2', 'Inj. Mc', 'Rec. m1', 'Rec. m2', 'Rec. Mc',\
          'Inj. inc', 'Inj. RA', 'Inj. Dec', 'Rec. RA', 'Rec. Dec', 'SNR',\
          'Chi^2', 'Bank veto', 'Auto veto', 'Null SNR'] +\
         ['SNR %s' % ifo for ifo in ifos] +\
         ['BestNR', 'Inj S1x', 'Inj S1y', 'Inj S1z',\
                    'Inj S2x', 'Inj S2y', 'Inj S2z']
    # TODO: serial coding
    td = zip(*[np.concatenate((g_ifar_dist,   g_missed2_dist,\
                                  missed_inj_dist))] +\
              [np.concatenate((g_ifar_eff_site_dist[ifo],\
                                  g_missed2_eff_site_dist[ifo],\
                                  missed_inj_eff_site_dist[ifo]))\
               for ifo in sites] +\
              [np.concatenate((g_ifar_m1,     g_missed2_m1,     missed_inj_m1)),\
               np.concatenate((g_ifar_m2,     g_missed2_m2,     missed_inj_m2)),\
               np.concatenate((g_ifar_mchirp, g_missed2_mchirp,\
                                  missed_inj_mchirp)),\
               np.concatenate((g_ifar_rec_m1,  g_missed2_rec_m1,  missed_na)),\
               np.concatenate((g_ifar_rec_m2,  g_missed2_rec_m2,  missed_na)),\
               np.concatenate((g_ifar_rec_mchirp, g_missed2_rec_mchirp,\
                                  missed_na)),\
               np.concatenate((g_ifar_inc,    g_missed2_inc,    missed_inj_inc)),\
               np.concatenate((g_ifar_ra,     g_missed2_ra,     missed_inj_ra)),\
               np.concatenate((g_ifar_dec,    g_missed2_dec,    missed_inj_dec)),\
               np.concatenate((g_ifar_rec_ra,  g_missed2_rec_ra,  missed_na)),\
               np.concatenate((g_ifar_rec_dec, g_missed2_rec_dec, missed_na)),\
               np.concatenate((g_ifar_snr,    g_missed2_snr,    missed_na)),\
               np.concatenate((g_ifar_chisq,  g_missed2_chisq,  missed_na)),\
               np.concatenate((g_ifar_bank,   g_missed2_bank,   missed_na)),\
               np.concatenate((g_ifar_auto,   g_missed2_auto,   missed_na)),\
               np.concatenate((g_ifar_null,   g_missed2_null,   missed_na))] +\
              [np.concatenate((g_ifar_sngl_snr[ifo], g_missed2_sngl_snr[ifo],\
                                  missed_na)) for ifo in ifos] +\
              [np.concatenate((g_ifar_det_stat, g_missed2_det_stat,\
                                  missed_na)),\
               np.concatenate((g_ifar_spin1x, g_missed2_spin1x,\
                                  missed_inj_spin1x)),\
               np.concatenate((g_ifar_spin1y, g_missed2_spin1y,\
                                  missed_inj_spin1y)),\
               np.concatenate((g_ifar_spin1z, g_missed2_spin1z,\
                                  missed_inj_spin1z)),\
               np.concatenate((g_ifar_spin2x, g_missed2_spin2x,\
                                  missed_inj_spin2x)),\
               np.concatenate((g_ifar_spin2y, g_missed2_spin2y,\
                                  missed_inj_spin2y)),\
               np.concatenate((g_ifar_spin2z, g_missed2_spin2z,\
                                  missed_inj_spin2z))])
    td.sort(key=lambda elem: elem[0])
    td = [[i]+list(td[i]) for i in\
          range(nonzero_fap.sum()+missed.sum()+len(missed_injs))]

    file = open("%s/quiet_found_triggers.html" % outdir, "w")
    file.write(dqHTMLUtils.write_table(markup.page(), th, td)())
    file.close()
    logging.info("%d triggers written to file." % (len(td)))

    t_missed = zip(*[g_missed2_dist] + \
                    [g_missed2_eff_site_dist[ifo] for ifo in sites] + \
                    [g_missed2_m1, g_missed2_m2, g_missed2_mchirp, g_missed2_rec_m1,
                     g_missed2_rec_m2, g_missed2_rec_mchirp, g_missed2_inc, g_missed2_ra,
                     g_missed2_dec, g_missed2_rec_ra, g_missed2_rec_dec, g_missed2_snr,
                     g_missed2_chisq, g_missed2_bank, g_missed2_auto,
                     g_missed2_null] + \
                    [g_missed2_sngl_snr[ifo] for ifo in ifos] + \
                    [g_missed2_det_stat, g_missed2_spin1x, g_missed2_spin1y,
                     g_missed2_spin1z, g_missed2_spin2x, g_missed2_spin2y,
                     g_missed2_spin2z])
    t_missed.sort(key=lambda elem: elem[0])
    t_missed = [[i] + list(t_missed[i]) for i in range(missed.sum())]
    file = open("%s/missed_found_triggers.html" % outdir, "w")
    file.write(dqHTMLUtils.write_table(markup.page(), th, t_missed)())
    file.close()
# Post-processing of injections ends here

# ==========
# Make plots
# ==========

# Define the 'found' injection colour
fnd_col = cm.get_cmap()(0)
# Define FAP colour
ptfcolormap = cm.spring
ptfcolormap.set_over('g')

# TODO: promote to executable with stat as option
# Plot cumulative histograms
x_label_dict = {"bestnr": "BestNR",
                "snr": "SNR",
                "snruncut": "SNR after signal based vetoes"}
data_dict = {"bestnr": full_time_bin_veto_max_bestnr,
             "snr": full_time_bin_veto_max_snr,
             "snruncut": full_time_bin_veto_max_snr_uncut}
for stat in ["bestnr", "snr", "snruncut"]:
    fig = plt.figure()
    ax = fig.gca()
    cumplot = plotutils.CumulativeHistogramPlot(x_label_dict[stat],
                                                 "False alarm probability",
                                                 "")
    cumplot.add_background([item] for item in data_dict[stat])
    cumplot.finalize(num_bins=50)
    cumplot.ax.set_ylim(ymax=1.2)
    cumplot.savefig('%s/%s_vs_fap.png' % (outdir, stat))
    plt.close()

# TODO: promote to executable
# Produce plots and files reporting on efficiency
if doinj: 
    # Calculate distances (horizontal axis) as means
    dist_plot_vals = [np.asarray(bin).mean() for bin in dist_bins]

    # Calculate error bars for efficiency/distance plots and datafiles using max BestNR of background
    yerr_low_mc, yerr_high_mc, fraction_mc = efficiency_with_errs(found_max_bestnr, num_injections, num_mc_injs=num_mc_injs)
    yerr_low_no_mc, yerr_high_no_mc, fraction_no_mc = efficiency_with_errs(found_max_bestnr_no_mc, num_injections_no_mc)

    # Save the efficiency values to disk
    f = open('%s/efficiency_numbers.txt' % outdir, 'w')
    f.write('distance (Mpc) \tfraction\tyerr_low\tyerr_high\n\n')
    stacked = np.column_stack([dist_plot_vals, fraction_mc,
                               yerr_low_mc, yerr_high_mc])
    np.savetxt(f, stacked, fmt='%.8e', delimiter='\t')
    f.close()

    # Calculate and save to disk the 50% sensitive distance 
    eff_low = fraction_no_mc
    eff_idx = np.where(eff_low<0.5)[0]
    if len(eff_idx)==0:
        sens_dist = -1
        err_msg = "Efficiency does not drop below 50%!"
        logging.error(err_msg)
    elif eff_idx[0]==0:
        sens_dist = 0
        err_msg = "Efficiency does not drop below 90%!"
        logging.error(err_msg)
    else:
        i = eff_idx[0]
        d     = dist_plot_vals[i]
        d_low = dist_plot_vals[i-1]
        e     = eff_low[i]
        e_low = eff_low[i-1]

        sens_dist = d + (e - 0.5) * (d - d_low) / (e_low - e)
    open("%s/sensitive_distance.txt" % outdir, "w").write('%s\n' % sens_dist)

    # Plot efficiency using loudest background
    fig = plt.figure()
    ax = fig.gca()
    ax.plot(dist_plot_vals, (fraction_no_mc), 'g-',
            label='No marginalisation')
    ax.errorbar(dist_plot_vals, (fraction_no_mc),
                yerr=[yerr_low_no_mc,yerr_high_no_mc], c = 'g')
    marg_eff = fraction_mc
    if not np.isnan(marg_eff.sum()):
        ax.plot(dist_plot_vals, marg_eff, 'r-', label='Marginalised')
        ax.errorbar(dist_plot_vals, marg_eff, yerr=[yerr_low_mc,yerr_high_mc],
                    c = 'r')
    ax.legend()
    ax.grid()
    ax.set_ylim([0,1])
    ax.set_xlim(0, 2.*upper_dist - lower_dist)
    ax.set_title("Efficiency of injection finding using "+\
                 "BestNR as detection statistic")
    ax.set_ylabel("Fraction of injections found louder than loudest background")
    ax.set_xlabel("Distance (Mpc)")
    fig.savefig('%s/BestNR_max_efficiency.png' % (outdir))
    plt.close()

    # Calculate error bars for efficiency/distance plots and datafiles using max BestNR of foreground 
    yerr_low_no_mc, yerr_high_no_mc, fraction_no_mc = efficiency_with_errs(found_on_bestnr_no_mc, num_injections_no_mc)
    yerr_low, yerr_high, fraction_mc = efficiency_with_errs(found_on_bestnr, num_injections, num_mc_injs=num_mc_injs)

    # Marginalized efficiency (isf = inverse survival function)
    red_efficiency = (fraction_mc) - (yerr_low) * scipy.stats.norm.isf(0.1)

    # Print efficiency curve to file
    file = open( "%s/efficiency_curve.txt" % outdir, "w" )
    file.write('Distance (Mpc)\tEfficiency including counting errors\n\n')
    stacked = np.column_stack([dist_plot_vals, red_efficiency])
    np.savetxt(file, stacked, delimiter='\t')
    file.close()

    # Calculate and save to disk 50% and 90% exclusion distances
    for percentile in [50, 90]:
        eff_idx = np.where(red_efficiency < (percentile / 100.))[0]
        if len(eff_idx) == 0:
            green_efficiency = (fraction_no_mc)
            excl_efficiency = green_efficiency
            eff_idx = np.where(green_efficiency < (percentile / 100.))[0]
        else:
            excl_efficiency = redEfficiency
        if len(eff_idx) and eff_idx[0]!=0:
            i = eff_idx[0]
            d = dist_plot_vals[i]
            d_low = dist_plot_vals[i-1]
            e = excl_efficiency[i]
            e_low = excl_efficiency[i-1]
            excl_dist = d + (e - (percentile / 100.)) * (d - d_low) /\
                    (e_low - e)
        else:
            excl_dist = 0
            err_msg = "Efficiency below %d%% in first bin!" % (percentile)
            logging.error(err_msg)
        open("%s/exclusion_distance_%d.txt" % (outdir, percentile), "w")\
                .write('%s\n' % excl_dist)

    # Plot efficiency using loudest foreground
    fig = plt.figure()
    ax = fig.gca()
    ax.grid()
    ax.plot(dist_plot_vals, (fraction_no_mc), 'g-',
            label='No marginalisation')
    ax.errorbar(dist_plot_vals, (fraction_no_mc),
                yerr=[yerr_low_no_mc,yerr_high_no_mc], c = 'g')
    marg_eff = fraction_mc
    if not np.isnan(marg_eff.sum()):
        ax.plot(dist_plot_vals, marg_eff ,'r-', label='Marginalised')
        ax.errorbar(dist_plot_vals, marg_eff, yerr=[yerr_low,yerr_high], c = 'r')
    if not np.isnan(red_efficiency.sum()):
        ax.plot(dist_plot_vals, red_efficiency, 'm-',
                label='Inc. counting errors')
    ax.set_ylim([0,1])
    ax.grid()
    ax.legend()
    ax.get_legend().get_frame().set_alpha(0.5)
    ax.grid()
    ax.set_ylim([0,1])
    ax.set_xlim(0, 2.*upper_dist - lower_dist)
    ax.set_title("Efficiency of injection finding using "+\
                 "BestNR as detection statistic")
    ax.set_ylabel("Fraction of injections found louder than "+\
                  "loudest foreground")
    ax.set_xlabel("Distance (Mpc)")
    ax.plot([excl_dist],[0.9],'gx')
    ax.set_ylim([0,1])
    ax.set_xlim(0, 2.*upperDist - lowerDist)
    fig.savefig('%s/BestNR_on_efficiency.png' % (outdir))
    plt.close()

# TODO: turn the following into an executable and loop at workflow level
# Plot results of injection campaign with found ones on top of missed ones
# (found-missed) or vice-versa (missed-found)
if doinj: 
    inj_plots = list(itertools.product([["found_missed"], ["missed_found"]],\
                                       [["mchirp"], ["time"]],\
                                       [["eff_dist"], ["dist"],\
                                        ["eff_site_dist"], ["sky_error"]]))
    inj_plots.extend(list(itertools.product([["found_missed"], ["missed_found"]],\
                                            [["spin1", "spin2"], ["q", "mtot"],\
                                             ["incl", "mchirp"], ["cosincl", "dist"],
                                             ["dist", "sky_error"]])))
    inj_plots = list(itertools.chain(*inj_plots))
    inj_plots = list(itertools.chain(*inj_plots))
    inj_plots = [inj_plots[i:i+3] for i in range(0, len(inj_plots), 3)]

    # Info for site-specific plots
    sitename = { 'G':'GEO', 'H':'Hanford', 'L':'Livingston', 'V':'Virgo',\
                 'K':'KAGRA' }
                                       
    # Dictionary of labels for the horizontal axis
    axis_labels = {'mchirp': "Chirp Mass (solar masses)",
                   'time': "Time since %d" % grb_time,
                   'eff_dist': "Inverse sum of effective distances (Mpc)",
                   'dist': "Distance (Mpc)",
                   'eff_site_dist': "",
                   'incl': "Inclination (iota)",
                   'cosincl': "cos(iota)",
                   'q': "Mass ratio q",
                   'mtot': "Total mass M (solar masses)",
                   'spin1': "Spin on 1st binary component",
                   'spin2': "Spin on 2nd binary component",
                   'sky_error': "Rec. sky error (radians)"}

    # Dictionaries of data to plot 
    g_found_dict = {'mchirp': g_found_mchirp, 'time': g_found_time,
                    'eff_dist': g_found_eff_dist, 'dist': g_found_dist,
                    'eff_site_dist': [],
                    'incl': np.rad2deg(g_found_inc), 'cosincl': np.cos(g_found_inc),
                    'q': g_found_m2 / g_found_m1, 'mtot': g_found_m1 + g_found_m2,
                    'spin1': np.sqrt(g_found_spin1x**2 + \
                                     g_found_spin1y**2 + \
                                     g_found_spin1z**2),
                    'spin2': np.sqrt(g_found_spin2x**2 + \
                                     g_found_spin2y**2 + \
                                     g_found_spin2z**2),
                    'sky_error': g_found_sky_angle}
    g_ifar_dict = {'mchirp': g_ifar_mchirp, 'time': g_ifar_time,
                   'eff_dist': g_ifar_eff_dist, 'dist': g_ifar_dist,
                   'eff_site_dist': [],
                   'incl': np.rad2deg(g_ifar_inc), 'cosincl': np.cos(g_ifar_inc),
                   'q': g_ifar_m2 / g_ifar_m1, 'mtot': g_ifar_m1 + g_ifar_m2,
                   'spin1': np.sqrt(g_ifar_spin1x**2 + \
                                    g_ifar_spin1y**2 + \
                                    g_ifar_spin1z**2),
                   'spin2': np.sqrt(g_ifar_spin2x**2 + \
                                    g_ifar_spin2y**2 + \
                                    g_ifar_spin2z**2),
                   'sky_error': g_ifar_sky_angle}
    g_missed2_dict = {'mchirp': g_missed2_mchirp, 'time': g_missed2_time,
                      'eff_dist': g_missed2_eff_dist, 'dist': g_missed2_dist,
                      'eff_site_dist': [],
                      'incl': np.rad2deg(g_missed2_inc), 'cosincl': np.cos(g_missed2_inc),
                      'q': g_missed2_m2 / g_missed2_m1, 'mtot': g_missed2_m1 + g_missed2_m2,
                      'spin1': np.sqrt(g_missed2_spin1x**2 + \
                                       g_missed2_spin1y**2 + \
                                       g_missed2_spin1z**2),
                      'spin2': np.sqrt(g_missed2_spin2x**2 + \
                                       g_missed2_spin2y**2 + \
                                       g_missed2_spin2z**2),
                      'sky_error': g_missed2_sky_angle}
    missed_inj_dict = {'mchirp': missed_inj_mchirp, 'time': missed_inj_time,
                      'eff_dist': missed_inj_eff_dist, 'dist': missed_inj_dist,
                      'eff_site_dist': [],
                      'incl': np.rad2deg(missed_inj_inc), 'cosincl': np.cos(missed_inj_inc),
                      'q': missed_inj_m2 / missed_inj_m1, 'mtot': missed_inj_m1 + missed_inj_m2,
                      'spin1': np.sqrt(missed_inj_spin1x**2 + \
                                       missed_inj_spin1y**2 + \
                                       missed_inj_spin1z**2),
                      'spin2': np.sqrt(missed_inj_spin2x**2 + \
                                       missed_inj_spin2y**2 + \
                                       missed_inj_spin2z**2),
                      'sky_error': []}

    # Generate scatter plots
    for inj_plot in inj_plots:
        #print(inj_plot)
        fm_or_mf = inj_plot[0]
        x_qty = inj_plot[1]
        y_qty = inj_plot[2] 
        g_found_x = g_found_dict[x_qty]
        g_found_y = g_found_dict[y_qty]
        g_ifar_x = g_ifar_dict[x_qty]
        g_ifar_y = g_ifar_dict[y_qty]
        g_missed2_x = g_missed2_dict[x_qty]
        g_missed2_y = g_missed2_dict[y_qty]
        missed_inj_x = missed_inj_dict[x_qty]
        missed_inj_y = missed_inj_dict[y_qty]
        x_label = axis_labels[x_qty]
        y_label = axis_labels[y_qty]
        if x_qty == "spin1":
            found_inj_x = np.sqrt(found_inj_spin1x**2 + \
                                  found_inj_spin1y**2 + \
                                  found_inj_spin1z**2)
        elif x_qty == "q":
            missed_inj_x = np.where(missed_inj_x > 1, 1. / missed_inj_x, missed_inj_x)
            g_missed2_x = np.where(g_missed2_x > 1, 1. / g_missed2_x, g_missed2_x)
            g_ifar_x = np.where(g_ifar_x > 1, 1. / g_ifar_x, g_ifar_x)
            g_found_x = np.where(g_found_x > 1, 1. / g_found_x, g_found_x)
        #elif x_qty == "incl":
        #    #x_label = "Magnitude of inclination | iota |"
        #elif x_qty == "cosincl":
        #     x_label = "cos(|iota|)"
        #     g_found_x = 0.5 * np.pi - abs(g_found_inc - 0.5 * np.pi)
        #     g_ifar_x = 0.5 * np.pi - abs(g_ifar_inc - 0.5 * np.pi)
        #     g_missed2_x = 0.5 * np.pi - abs(g_missed2_inc - 0.5 * np.pi)
        #     missed_inj_x = 0.5 * np.pi - abs(missed_inj_inc - 0.5 * np.pi)
        elif "incl" in x_qty:
            max_inc = np.pi
            #max_inc = max(np.concatenate((g_found_x, g_ifar_x, g_missed2_x, missed_inj_x)))
            max_inc_deg = np.rad2deg(max_inc)
            max_inc_deg = np.ceil(max_inc_deg/10.0)*10
            max_inc = np.deg2rad(max_inc_deg)
        # The square brackets are for a one-iteration loop below
        plot_loop = [None] 
        if y_qty == "eff_site_dist":
            plot_loop = sites
        elif y_qty == "spin2":
            found_inj_y = np.sqrt(found_inj_spin2x**2 + \
                                  found_inj_spin2y**2 + \
                                  found_inj_spin2z**2)
        for site in plot_loop: 
            if site is not None:
                if x_qty == "eff_site_dist":
                    x_label = "%s effective distance (Mpc)" % sitename[site]
                if y_qty == "eff_site_dist":
                    y_label = "%s effective distance (Mpc)" % sitename[site]
                missed_inj_y = missed_inj_eff_site_dist[site]
                g_missed2_y = g_missed2_eff_site_dist[site]
                g_ifar_y = g_ifar_eff_site_dist[site]
                g_found_y =  g_found_eff_site_dist[site]
            fig = plt.figure()
            if y_qty in ["mtot", "spin2", "mchirp"]:
                ax = fig.gca()
            elif y_qty == "sky_error":
                if x_qty == "dist": 
                    ax = fig.gca(xscale="log")
                else:
                    ax = fig.gca()
            else:
                ax = fig.gca(yscale="log")
            if fm_or_mf == "found_missed":
                if len(missed_inj_x) and len(missed_inj_y):
                    ax.scatter(missed_inj_x, missed_inj_y, c="k", marker="x", s=10)
                if len(g_missed2_x):
                    ax.scatter(g_missed2_x, g_missed2_y, c="r", marker="x", s=10)
                if len(g_ifar_x):
                    p = ax.scatter(g_ifar_x[FM], g_ifar_y[FM], c=g_ifar_stat[FM],
                                   vmin=0, vmax=1, s=40, edgecolor="w")
                    cb = plt.colorbar(p, label="FAP")
                if len(g_found_x):
                    ax.scatter(g_found_x, g_found_y, c=fnd_col, marker="+", s=30)
            elif fm_or_mf == "missed_found":
                if len(g_found_x):
                    ax.scatter(g_found_x, g_found_y, c=fnd_col, marker="+", s=15)
                if len(g_ifar_x):
                    p = ax.scatter(g_ifar_x[MF], g_ifar_y[MF], c=g_ifar_stat[MF],
                                   vmin=0, vmax=1, s=40, edgecolor="w")
                    cb = plt.colorbar(p, label="FAP")
                if len(g_missed2_x):
                    ax.scatter(g_missed2_x, g_missed2_y, c="r", marker="x", s=40)
                if len(missed_inj_x) and len(missed_inj_y):
                    ax.scatter(missed_inj_x, missed_inj_y, c="k", marker="x", s=40)
            ax.grid()
            ax.set_xlabel(x_label)
            ax.set_ylabel(y_label)
            plot_path = "%s/%s_injections_%s_%s" % (outdir, fm_or_mf, y_qty, x_qty)
            if x_qty == "spin1":
                ax.set_title("Injection recovery with respect to component spins")
                ax.set_xlim([0, np.ceil(10 * max(max_missed_inj_spin1,
                                                 found_inj_x.max())) / 10])
                ax.set_ylim([0, np.ceil(10 * max(max_missed_inj_spin2,
                                                 found_inj_y.max())) / 10])
            elif x_qty == "incl":
                ax.set_title("Injection recovery with respect to inclination angle")
                ax.set_xlim(0, max_inc_deg)
            elif x_qty == "cosincl":
                ax.set_title("Injection recovery with respect to inclination angle")
                tt = np.arange(0, max_inc_deg + 10, 10)
                #tt = np.arange(0, 190, 10)
                tks = np.cos(np.deg2rad(tt))
                tk_labs = ['cos(%d deg)' % tk for tk in tt]
                plt.xticks(tks, tk_labs, fontsize=10)
                fig.autofmt_xdate()
                ax.set_xlim(np.cos(max_inc), 1)
                #ax.set_xlim(-1, 1)
            elif y_qty == "mtot":
                ax.set_title("Injection recovery with respect to component masses")
            elif site is not None:
                ax.set_title("Injection recovery vs background")
                plot_path += "_%s" % site.lower()
            else:
                ax.set_title("Injection recovery vs background")
            plt.tight_layout()
            plot_path += ".png"
            fig.savefig(plot_path)
            plt.close()

logging.info("Plots complete.")
