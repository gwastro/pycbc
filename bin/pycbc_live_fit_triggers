#!/bin/env python'

import numpy as np
import h5py
from pycbc import bin_utils
from pycbc.events import triggers, trigger_fits as trstats
from pycbc.io import DictArray
from pycbc.events import ranking
import argparse
import logging
import operator
import os

def inequality_string_to_function(inequ):
    if inequ == "==":
        eq_out = operator.eq
    elif inequ == "<=":
        eq_out = operator.le
    elif inequ == "<":
        eq_out = operator.lt
    elif inequ == ">=":
        eq_out = operator.ge
    elif inequ == ">":
        eq_out = operator.gt
    elif inequ == "!=":
        eq_out = operator.ne
    return eq_out

parser = argparse.ArgumentParser(usage="",
    description="Plot histograms of triggers split over various parameters")
parser.add_argument("--verbose", action="store_true",
                    help="Print extra debugging information", default=False)
parser.add_argument("--ifo", required=True,
                    help="Which ifo are we fitting the triggers for? "
                         "Required")
parser.add_argument("--top-directory", metavar='PATH', required=True,
                    help="Directory containing trigger files, top driectory, "
                         "will contain subdirectories for each day of data. "
                         "Required.")
parser.add_argument("--analysis-date", required=True,
                    help="Date to analyse, in format "
                         "YYYY_MM_DD. Required.")
parser.add_argument("--file-identifier", default="H1L1V1-Live",
                    help="String required in filename to be considered for "
                         "analysis. Default: 'H1L1V1-Live'.")
parser.add_argument("--fit-function", default="exponential",
                    choices=["exponential", "rayleigh", "power"],
                    help="Functional form for the maximum likelihood fit. "
                         "Choose from exponential, rayleigh or power. "
                         "Default: exponential")
parser.add_argument("--fit-param", default="snr",
                    choices=["new_snr", "snr"],
                    help="Which parameter to use for fitting. "
                         "Choose from new_snr or snr. "
                         "Default: new_snr")
parser.add_argument("--cut-params", nargs="+", default=None,
                    help="Parameters for cuts. Default = None.")
parser.add_argument("--cut-thresholds", nargs="+", default=None, type=float,
                    help="Parameters for cuts. Default = None.")
parser.add_argument("--cut-inequalities", nargs="+", default=None,
                    help='Operators for cuts, usage: keep thresholds (op) thresh '
                         'choose from > >= < <= == !=. Default: None',
                         choices='> >= < <= == !='.split(' '))
parser.add_argument("--duration-bin-start", type=int, default=10,
                    help="Shortest duration to use for duration bins. "
                         "Default = 10")
parser.add_argument("--duration-bin-end", type=int, default=152,
                    help="Longest duration to use for duration bins. "
                         "Default = 152 (current longest in template bank)")
parser.add_argument("--num-duration-bins", type=int, default=6,
                    help="How many template duration bins to split the bank into "
                         " before fitting. Default = 6")
parser.add_argument("--f-lower", type=float, default=20,
                    help="Lower frequency limit, used if certain parameters "
                         "are needed calculated. Default = 20")
parser.add_argument("--duration-bin-spacing", default='log',
                    choices=['linear','log'],
                    help="How to set spacing for bank split "
                         " before fitting. Default = 6")
parser.add_argument("--output-directory", required=True,
                    help="Directory in which to save the output file.")
#parser.add_argument("--", default="", help="")


#Add some input sanitisation
args = parser.parse_args()

if args.verbose:
    log_level = logging.DEBUG
else:
    log_level = logging.WARN

logging.basicConfig(format='%(asctime)s : %(message)s', level=log_level)

# Constructing full paths
full_dir = os.path.join(args.top_directory, args.analysis_date)

files = [os.path.join(full_dir, fname) for fname in os.listdir(full_dir) if args.file_identifier in fname and fname.endswith('.hdf')]

args.cut_params.append('template_duration')
args.cut_inequalities.append("<")
args.cut_thresholds.append(args.duration_bin_end)

logging.info('Found %d files' % len(files))

cut_inequalities = np.array(args.cut_inequalities)
cut_params = np.array(args.cut_params)
cut_thresholds = np.array(args.cut_thresholds)

# newsnr and reduced chisquared need special treatment as they are not
# in the saved files. Others are either in the saved files or can be
# calculated in the get_param function

cutting_newsnr = False
if 'new_snr' in cut_params:
    cutting_newsnr = True
    nsidx = np.nonzero(cut_params == 'new_snr')[0]
    # To save on chisq & newsnr calculation costs, and memory use, cut on
    # snr which, by definition is greater than or equal to newsnr
    cut_params[nsidx] = 'snr'
    nsineq = cut_inequalities[nsidx]
    nsthresh = cut_thresholds[nsidx]

cutting_rchisq = False
if 'rchisq' in cut_params:
    cutting_rchisq = True
    csidx = np.nonzero(cut_params == 'rchisq')[0]
    cut_params = np.delete(cut_params, csidx)
    csineq = cut_inequalities[csidx]
    cut_inequalities = np.delete(cut_inequalities, csidx)
    csthresh = cut_thresholds[csidx]
    cut_thresholds = np.delete(cut_thresholds, csidx)

cut_params = list(cut_params)
cut_inequalities = list(cut_inequalities)
cut_thresholds = list(cut_thresholds)

# The following datasets are required for calculation of cut parameters
required_datasets = ['snr', 'chisq', 'chisq_dof', 'template_duration',
                     'mass1', 'mass2', 'spin1z', 'spin2z']
required_datasets += cut_params
required_datasets = list(set(required_datasets))

# Make some strings for logging /saving setting for attributes
zip_inequs = zip(cut_params, cut_inequalities, cut_thresholds)
ineq_str = ''
for p, i, v in zip_inequs:
    ineq_str += '{} {} {}, '.format(p, i, v)
ineq_str = ineq_str[:-2]

all_zip_inequs = zip(args.cut_params, args.cut_inequalities, args.cut_thresholds)
ineq_str_all = ''
for p, i, v in all_zip_inequs:
    ineq_str_all += '{} {} {}, '.format(p, i, v)
ineq_str_all= ineq_str_all[:-2]
logging.info('Criteria set up as ' + ineq_str_all)

#store as a DictArray - nice as it has the .select() method
events_dict = {k : [] for k in required_datasets}
logging.info("Getting events from " + args.ifo +
             " which meet {} criteria".format(ineq_str))

#Loop through files - add events which meet the immediately gettable criteria
file_counter = 0
events = DictArray(data={rp: np.array([]) for rp in required_datasets})
live_time = 0
for f in files:
    skipping_file = False
    if not file_counter % 5000:
        logging.info('Processing file %d: %d events' % (file_counter, len(events)))
    file_counter += 1
    #If there is an IOerror with the file, don't fail, just carry on
    try:
        h5py.File(f,'r')
    except IOError:
        logging.info('IOError with file ' + f)
        continue
    with h5py.File(f,'r') as fin:
        # Open the file: does it have the ifo group and snr dataset?
        if not (args.ifo in fin and 'snr' in fin[args.ifo]):
            continue
        # Live time is not immediately obvious - get an approximation with
        # 8 second granularity by adding 8 seconds per 'valid' file
        live_time += 8
        # all the required datasets must be present - this should
        # be rare so can be printed
        if any([rd not in fin[args.ifo] for rd in required_datasets]):
            logging.info('some datasets not present in ' + f +', skipping')
            continue
        # Skip if there are no triggers
        if not fin[args.ifo + '/' + required_datasets[0]].size:
            continue
        # unpack this file into a dictarray
        file_array = DictArray(data={rd : np.array(fin[args.ifo + '/' + rd][:])
                                     for rd in required_datasets})
        for cparam, cineq, cthresh in zip(cut_params, cut_inequalities, cut_thresholds):
            # calculate parameter if not already in file
            if cparam not in file_array.data:
                file_vals = trstats.get_param(cparam, args,
                    file_array.data['mass1'], file_array.data['mass2'],
                    file_array.data['spin1z'], file_array.data['spin2z'])
                file_array.data[cparam] = file_vals
            #Apply cuts to array for this file
            cineq_fn = inequality_string_to_function(cineq)
            idx_keep = np.nonzero(cineq_fn(file_array.data[cparam], cthresh))[0]
            # if nothing remains after cuts, skip file
            if not len(idx_keep):
                skipping_file = True
                break
            file_array = file_array.select(idx_keep)
        if skipping_file: continue
        events = events + file_array

if not len(events):
    raise NotImplementedError("Too many cuts on the data - removed everything")

logging.info("{} events found".format(len(events.data[required_datasets[0]])))
# Cut on chi_squared if requested
if args.fit_param == 'new_snr' or cutting_rchisq or cutting_newsnr:
    events.data['rchisq'] = np.array(events.data['chisq']) / \
        (2. * np.array(events.data['chisq_dof'][:]) - 2.)


if cutting_rchisq:
    logging.info("Keeping events with reduced chi-squared %s %.3f" % (csineq[0], csthresh))
    ineq_fn = inequality_string_to_function(csineq)
    rchisq_cut = np.nonzero(ineq_fn(events.data['rchisq'], csthresh))[0]
    if len(rchisq_cut):
        events = events.select(rchisq_cut)
    else:
        raise NotImplementedError("Too many cuts on the data - removed everything")
    logging.info("{} events remaining".format(len(events.data[required_datasets[0]])))

if cutting_newsnr or args.fit_param == 'new_snr':
    logging.info("Calculating new_snr")
    events.data['new_snr'] = ranking.newsnr(events.data['snr'],
                                            events.data['rchisq'])

if cutting_newsnr:
    logging.info("Keeping events with new_snr %s %.3f" % (nsineq[0], nsthresh))
    ineq_fn = inequality_string_to_function(nsineq)
    idx_keep = np.nonzero(ineq_fn(events.data['new_snr'], nsthresh))[0]
    if len(idx_keep):
        events = events.select(idx_keep)
    else:
        raise NotImplementedError("Too many cuts on the data - removed everything")
    logging.info("{} events remaining".format(len(events.data[required_datasets[0]])))

# split the events into bins by template duration
logging.info('Sorting events into template duration bins')
# Note we use min and max as it will be safe regardless of whether a cut
# has been made to this parameter or not
if args.duration_bin_spacing == 'log':
    bincreator = bin_utils.LogarithmicBins
elif args.duration_bin_spacing == 'linear':
    bincreator = bin_utils.LinearBins

tbins = bincreator(args.duration_bin_start,
                   args.duration_bin_end,
                   args.num_duration_bins)

event_bin = np.array([tbins[d] for d in events.data['template_duration']])

# Fit the triggers within each bin
alphas = np.zeros(args.num_duration_bins, dtype=np.float32)
counts = np.zeros(args.num_duration_bins, dtype=np.float32)

# Take floor (to nearest 0.1) of fit_param
fit_threshold = 0.1 * np.floor(events.data[args.fit_param].min() * 10)

for bin_num in range(args.num_duration_bins):
    inbin = event_bin == bin_num
    counts[bin_num] = np.count_nonzero(inbin)
    alphas[bin_num], _ = trstats.fit_above_thresh(args.fit_function,
                                        events.data[args.fit_param][inbin],
                                        fit_threshold)

output_filename = os.path.join(args.output_directory,
                               '{}-{}-TRIGGER-FITS.hdf'.format(args.ifo,
                                                       args.analysis_date))
fout = h5py.File(output_filename,'w')
fout['fit_coeff'] = alphas
fout['counts'] = counts
fout['bins_upper'] = tbins.upper()
fout['bins_lower'] = tbins.lower()

fout.attrs['fit_threshold'] = fit_threshold
fout.attrs['cuts'] = ineq_str_all
fout.attrs['fit_function'] = args.fit_function
fout.attrs['ifo'] = args.ifo
fout.attrs['live_time'] = live_time
