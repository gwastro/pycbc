#!/usr/bin/env python

# Copyright (C) 2011 Ian W. Harry
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

"""
Stochastic aligned spin bank generator.

List of possible improvements:
   * When not running with --vary-flower the code does not need to do use all
     of the xi_i coordinates. Even for TaylorR2F4 more than 4 of the coordinates
     would not be needed. For F2 3 is fine everywhere we've tested. This would
     provide a speed up.
   * It would be interesting to see whether the biggest cost is in generating
     the points, or in calculating matches. Both with an without --vary-flower
   * I don't know why covary and vary-flower couldn't be used together. You
     would only covary the coordinate system with largest f_upper, so matches
     are not covaried. BUt the covaried coordinates can be used to minimize
     the number of matches being calculated.
"""

from __future__ import division
import sys, argparse, copy
import numpy
import logging
import pycbc
import pycbc.version
import pycbc.tmpltbank
import pycbc.psd
import pycbc.strain
from lal import LAL_PI, LAL_MTSUN_SI


__author__  = "Ian Harry <ian.harry@astro.cf.ac.uk>"
__version__ = pycbc.version.git_verbose_msg
__date__    = pycbc.version.date
__program__ = "pycbc_aligned_stoch_bank"

# Read command line option
_desc = __doc__[1:]
parser = argparse.ArgumentParser(description=_desc,
           formatter_class=pycbc.tmpltbank.IndentedHelpFormatterWithNL)

# Begin with code specific options
parser.add_argument('--version', action='version', version=__version__)
parser.add_argument("--verbose", action="store_true", default=False,\
                    help="verbose output")
parser.add_argument("-O", "--output-file",  help="Output file name."+\
                                          "REQUIRED ARGUMENT.")
parser.add_argument("-m", "--min-match", action="store", type=float,\
                  default=None, help="Minimum match to generate bank with."+\
                                      "REQUIRED ARGUMENT")
parser.add_argument("-V", "--vary-fupper", action="store_true", default=False,\
                    help="Set this to run the code using a variable f_upper."\
                   +"OPTIONAL")
parser.add_argument("-N", "--num-seeds", action="store", type=int,\
                  default=5000000,\
                  help="Number of seed points to make bank," +\
                       "OPTIONAL")
parser.add_argument("-c", "--covary", action="store_true", default=False,\
                    help="Set this to run with covaried coordinates. This will"\
                   +"provide a speed up, but cannot run with varying f-lower"\
                   +"yet. OPTIONAL")
parser.add_argument("-n", "--num-failed-cutoff", action="store", type=int,\
                  default=1000000000, help="Give up after having tested this "+\
                  "many consecutive points each of which were not accepted "+\
                  "into the bank. OPTIONAL: default=1000000000 (this is "+\
                  "really large as --num-seeds provides the default "+\
                  "termination condition.")

# Insert the metric calculation options
pycbc.tmpltbank.insert_metric_calculation_options(parser)

# Insert the mass range options
pycbc.tmpltbank.insert_mass_range_option_group(parser)

# Insert the PSD options
pycbc.psd.insert_psd_option_group(parser)

# Insert the data reading options
pycbc.strain.insert_strain_option_group(parser)

# Add the ethinca calculation options
pycbc.tmpltbank.insert_ethinca_calculation_option_group(parser)

opts = parser.parse_args()

if opts.verbose:
    log_level = logging.DEBUG
else:
    log_level = logging.WARN
logging.basicConfig(format='%(asctime)s %(message)s', level=log_level)

# Sanity check options
if not opts.output_file:
    parser.error("Must supply --output-file")
if not opts.min_match:
    parser.error("Must supply --min-match")
opts.max_mismatch = 1 - opts.min_match
pycbc.tmpltbank.verify_metric_calculation_options(opts, parser)
metricParams=pycbc.tmpltbank.metricParameters.from_argparse(opts)
pycbc.tmpltbank.verify_mass_range_options(opts, parser)
massRangeParams=pycbc.tmpltbank.massRangeParameters.from_argparse(opts)
pycbc.psd.verify_psd_options(opts, parser)
if opts.psd_estimation:
    pycbc.strain.verify_strain_options(opts, parser)
pycbc.tmpltbank.verify_ethinca_calculation_options(opts, parser)

# FIXME: Move to noise.from_cli when its written
# If we are going to use h(t) to estimate a PSD we need h(t)
if opts.psd_estimation:
    logging.info("Obtaining h(t) for PSD generation")
    strain = pycbc.strain.from_cli(opts)
else:
    strain = None

# Get the PSD using the pycbc interface
logging.info("Obtaining PSD")
# Want the number of samples to be a binary number and Nyquist must be above
# opts.f_upper. All this assumes that 1 / deltaF is a binary number
nyquistFreq = 2**numpy.ceil(numpy.log2(opts.f_upper))
numSamples = int(round(nyquistFreq / opts.delta_f)) + 1
psd = pycbc.psd.from_cli(opts, length=numSamples, delta_f=opts.delta_f, \
                         low_frequency_cutoff=opts.f_low, strain=strain,
                         dyn_range_factor=pycbc.DYN_RANGE_FAC)
metricParams.psd = psd

# Begin by calculating a metric
logging.info('Calculating metric')
metricParams = pycbc.tmpltbank.determine_eigen_directions(\
    metricParams, \
    vary_fmax=(opts.vary_fupper or opts.calculate_ethinca_metric),\
    vary_density=opts.ethinca_calc_density)

# Choose the discrete values of frequencies to use if --vary-fupper is used
if not (opts.vary_fupper or opts.calculate_ethinca_metric):
    refFreq = metricParams.fUpper
elif opts.calculate_ethinca_metric and not opts.vary_fupper:
    fs = numpy.array(metricParams.evals.keys(), dtype=float)
    fs.sort()
    refFreq = fs.max()
else:
    fs = numpy.array(metricParams.evals.keys(), dtype=float)
    fs.sort()
    maxTMass = opts.max_total_mass
    minTMass = opts.min_total_mass
    lowEve = pycbc.tmpltbank.return_nearest_isco(\
               numpy.array([maxTMass]), fs)[0]
    highEve = pycbc.tmpltbank.return_nearest_isco(\
                numpy.array([minTMass]), fs)[0]
    refFreq = lowEve

logging.info("Calculating covariance matrix")

vals = pycbc.tmpltbank.estimate_mass_range(1000000,\
       massRangeParams, metricParams, refFreq, covary=False)
cov = numpy.cov(vals)
evalsCV,evecsCV = numpy.linalg.eig(cov)
metricParams.evecsCV = {}
metricParams.evecsCV[refFreq] = evecsCV

# Estimate the largest values of \chi_1 and \chi_2 to optimise what follows
logging.info("Determining parameter space extent")

vals = pycbc.tmpltbank.estimate_mass_range(1000000,\
       massRangeParams, metricParams, refFreq, covary=True)

chi1Max = vals[0].max()
chi1Min = vals[0].min()
chi1Diff = chi1Max - chi1Min
chi2Max = vals[1].max()
chi2Min = vals[1].min()
chi2Diff = chi2Max - chi2Min
# FIXME: Maybe better to use the numerical code to find maxima here?
chi1Min = chi1Min - 0.1*chi1Diff
chi1Max = chi1Max + 0.1*chi1Diff
chi2Min = chi2Min - 0.1*chi2Diff
chi2Max = chi2Max + 0.1*chi2Diff

logging.info("Initializing bank set up")

vals = None

# Set up the bank into sections
massbank = {}
bank = {}
MMdist = (opts.max_mismatch)**0.5
for i in xrange(-2,int((chi1Max - chi1Min) // MMdist + 2)):
    bank[i] = {}
    massbank[i] = {}
    for j in xrange(-2,int((chi2Max - chi2Min) // MMdist + 2)):
        bank[i][j] = []
        massbank[i][j] = []

maxChi1Bin = int((chi1Max - chi1Min) // MMdist + 1)
maxChi2Bin = int((chi2Max - chi2Min) // MMdist + 1)

# Initialise counters
N = 0
Np = 0
Ns = 0
Nr = 0

# Map the frequency values to idx if --vary-fupper is used
if opts.vary_fupper:
    freqMap = {}
    idx = 0
    for freq in fs:
        if freq >= lowEve and freq <= highEve:
            freqMap[freq] = idx
            idx += 1

logging.info("Starting")

# Begin making the thing
outbins = [[0,0],[0,1],[1,0],[0,-1],[-1,0],[1,1],[1,-1],[-1,1],[-1,-1]]
while True:
    if not (Ns % 100000):
        # For optimization we generate points in sets of 100000
        rTotmass, rEta, rBeta, rSigma, rGamma, rSpin1z, rSpin2z =\
            pycbc.tmpltbank.get_random_mass(100000, massRangeParams)
        diff = (rTotmass*rTotmass * (1-4*rEta))**0.5
        rMass1 = (rTotmass + diff)/2.
        rMass2 = (rTotmass - diff)/2.
        rChis = (rSpin1z + rSpin2z)/2.
        if opts.vary_fupper:
            refEve = pycbc.tmpltbank.return_nearest_isco(rTotmass, fs)
            lambdas = pycbc.tmpltbank.get_chirp_params(rTotmass, rEta, rBeta,\
                      rSigma, rGamma, rChis, metricParams.f0, \
                      metricParams.pnOrder)
            mus = []
            idx = 0
            for freq in fs:
                if freq >= lowEve and freq <= highEve: 
                    mus.append(pycbc.tmpltbank.get_mu_params(lambdas,\
                                                          metricParams, freq))
                    if freqMap[freq] != idx:
                        raise BrokenError
                    idx += 1
            mus = numpy.array(mus)
        else:
            refEve = numpy.zeros(100000)
            mus = numpy.zeros([1,1,100000])
        vecs = pycbc.tmpltbank.get_cov_params(rTotmass, rEta, rBeta,\
                   rSigma, rGamma, rChis, metricParams, refFreq)
        vecs = numpy.array(vecs)
        Ns = 0
    # Then we check each point for acceptance
    if not (Np % 100000):
        logging.info("%d seeds" % Np)
    vs = vecs[:,Ns]
    # What bin should it be in?
    v1Bin = int((vs[0] - chi1Min) // MMdist)
    v2Bin = int((vs[1] - chi2Min) // MMdist)
    # FIXME: This check should not be necessary
    # Did our previous numerical placement of bins fail?
    if (v1Bin < -1) or (v1Bin >= maxChi1Bin) or\
                                         (v2Bin < -1) or (v2Bin >= maxChi2Bin):
        for tmpV1 in range(v1Bin-1,v1Bin+2):
            if not massbank.has_key(tmpV1):
                massbank[tmpV1] = {}
                bank[tmpV1] = {}
            for tmpV2 in range(v2Bin-1,v2Bin+2):
                if not massbank[tmpV1].has_key(tmpV2):
                    massbank[tmpV1][tmpV2] = []
                    bank[tmpV1][tmpV2] = []
    store = True
    Np = Np + 1
    # Stop if we hit break condition
    if Np > opts.num_seeds:
        break
    # Calculate if any existing point is too close (set store to False)
    if opts.vary_fupper:
        for i,j in outbins:
            if store:
                for entry in massbank[v1Bin+i][v2Bin+j]:
                    if pycbc.tmpltbank.calc_point_dist_vary(\
                                 mus[:,:,Ns], refEve[Ns], entry[5], entry[4],\
                                 freqMap, opts.max_mismatch):
                        store = False
                        break
    else:
        for i,j in outbins:
            if store:
                for entry in bank[v1Bin+i][v2Bin+j]:
                    if pycbc.tmpltbank.calc_point_dist(vs, entry,\
                                                       opts.max_mismatch):
                        store = False
                        break
    # Increment counters, check for break condition and continue if rejected
    if not store:
        Ns = Ns + 1
        Nr = Nr + 1
        if Nr > opts.num_failed_cutoff:
            break
        continue
    # Add point, increment counters and continue if accepted
    Nr = 0
    bank[v1Bin][v2Bin].append(copy.deepcopy(vs))
    massbank[v1Bin][v2Bin].append([copy.deepcopy(rMass1[Ns]),\
          copy.deepcopy(rMass2[Ns]), copy.deepcopy(rSpin1z[Ns]),\
          copy.deepcopy(rSpin2z[Ns]), copy.deepcopy(refEve[Ns]),\
          copy.deepcopy(mus[:,:,Ns])])
    N = N + 1
    if not (N % 100000):
        logging.info("%d templates" % N)
    Ns = Ns + 1  

logging.info("Outputting bank")

# Put the whole template bank in one list
tempBank = []
for i in xrange(-2,int((chi1Max - chi1Min) // MMdist + 2)):
    for j in xrange(-2,int((chi2Max - chi2Min) // MMdist + 2)):
        for masses in massbank[i][j]:
            tempBank.append([masses[0],masses[1],masses[2],masses[3]])

# Output to file
pycbc.tmpltbank.output_sngl_inspiral_table(opts.output_file, tempBank, 
         metricParams, calculate_ethinca_comps=opts.calculate_ethinca_metric,\
         programName=__program__,optDict=opts.__dict__,\
         comment="", ifos=[""], version=pycbc.version.git_hash,\
         cvs_repository='pycbc/'+pycbc.version.git_branch,\
         cvs_entry_time=pycbc.version.date)

# All this is useful for debugging
#outfile=open('stochastic_bank_mass.dat','w')
#outfile2=open('stochastic_bank_evs.dat','w')

#for i in range(int((chi1Max - chi1Min) // MMdist)):
#    for j in range(int((chi2Max - chi2Min) // MMdist)):
#        for entry in bank[i][j]:
#            outfile2.write('%.16e %.16e %.16e %.16e %.16e %.16e %.16e %.16e\n' %(entry[0],entry[1],entry[2],entry[3],entry[4],entry[5],entry[6],entry[7]))
#outfile2.close()

#for i in range(int((chi1Max - chi1Min) // MMdist)):
#    for j in range(int((chi2Max - chi2Min) // MMdist)):
#        for masses in massbank[i][j]:
#            outfile.write('%.16e %.16e %.16e %.16e\n' %(masses[0],masses[1],masses[2],masses[3]))
#outfile.close()
