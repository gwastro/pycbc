#! /usr/bin/env python
# Copyright (C) 2012  Alex Nitz
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

"""Calculate the fitting factors of simulated signals with a template bank."""

import logging
from tqdm import tqdm
from numpy import complex64, complex128, array
from argparse import ArgumentParser
from ligo.lw import utils as ligolw_utils
from ligo.lw import lsctables

import numpy as np
import lal
import lalsimulation as lalsim

from pycbc.pnutils import mass1_mass2_to_mchirp_eta
from pycbc.pnutils import mass1_mass2_to_tau0_tau3
from pycbc.pnutils import nearest_larger_binary_number
from pycbc.waveform import get_td_waveform, get_fd_waveform, td_approximants, fd_approximants
from pycbc.waveform.utils import taper_timeseries
from pycbc import DYN_RANGE_FAC
from pycbc.types import FrequencySeries, TimeSeries, zeros, complex_same_precision_as
from pycbc.filter import match, sigmasq, matched_filter_core
from pycbc.io.ligolw import LIGOLWContentHandler
from math import ceil, log, sqrt
import pycbc.psd, pycbc.scheme, pycbc.fft, pycbc.strain, pycbc.version
from pycbc.detector import overhead_antenna_pattern as generate_fplus_fcross
from pycbc.waveform import TemplateBank

## The THA 5-comp match function is not so trivial

_snr = [None, None, None, None, None]
def match_tha(hcomps, stilde, num_comps, low_frequency_cutoff=None,
          high_frequency_cutoff=None, stilde_norm=None):
    N = (len(stilde)-1) * 2
    if _snr[0] is None or _snr[0].dtype != stilde.dtype or len(_snr[0]) != N:
        for i in range(5):
            _snr[i] = zeros(N, dtype=complex_same_precision_as(stilde))

    snr = [None, None, None, None, None]
    snr_norm = [None, None, None, None, None]
    ret_snrs = []
    ret_ids = []
    for i in range(5):
        snr[i], _, snr_norm[i] = matched_filter_core(hcomps[i], stilde, None,
                                               low_frequency_cutoff,
                                               high_frequency_cutoff,
                                               1., out=_snr[i])
        snr[i] *= snr_norm[i] / sqrt(stilde_norm)
        snr[i] = abs(snr[i])

        # This bit is going to be slow ...
        if i > 0:
            snr[0] = (snr[0]**2 + snr[i]**2)**0.5
        maxsnr, max_id = snr[0].abs_max_loc()
        ret_snrs.append(maxsnr)
        ret_ids.append(max_id)

    num_comps_snr = ret_snrs[num_comps-1]
    ret_snrs.append(num_comps_snr)
    for i in [2,3,4]:
        if i > num_comps:
            ret_snrs.append(num_comps_snr)
        else:
            ret_snrs.append(ret_snrs[i-1])

    return ret_snrs, ret_ids


## Remove the need for these functions ########################################
    
def generate_detector_strain(template_params, h_plus, h_cross):
    latitude = 0 
    longitude = 0 
    polarization = 0 

    if hasattr(template_params, 'latitude'):
        latitude = template_params.latitude
    if hasattr(template_params, 'longitude'):
        longitude = template_params.longitude
    if hasattr(template_params, 'polarization'):
        polarization = template_params.polarization

    f_plus, f_cross = generate_fplus_fcross(longitude, latitude, polarization)

    return h_plus * f_plus + h_cross * f_cross

def make_padded_frequency_series(vec, filter_N=None, delta_f=None):
    """Convert vec (TimeSeries or FrequencySeries) to a FrequencySeries. If
    filter_N and/or delta_f are given, the output will take those values. If
    not told otherwise the code will attempt to pad a timeseries first such that
    the waveform will not wraparound. However, if delta_f is specified to be
    shorter than the waveform length then wraparound *will* be allowed.
    """
    if filter_N is None:
        power = ceil(log(len(vec), 2)) + 1
        N = 2 ** power
    else:
        N = filter_N
    n = N // 2 + 1

    if isinstance(vec, FrequencySeries):
        vectilde = FrequencySeries(zeros(n, dtype=complex_same_precision_as(vec)),
                                   delta_f=1.0, copy=False)
        if len(vectilde) < len(vec):
            cplen = len(vectilde)
        else:
            cplen = len(vec)
        vectilde[0:cplen] = vec[0:cplen]
        delta_f = vec.delta_f

    elif isinstance(vec, TimeSeries):
        # First determine if the timeseries is too short for the specified df
        # and increase if necessary
        curr_length = len(vec)
        new_length = int(nearest_larger_binary_number(curr_length))
        while new_length * vec.delta_t < 1./delta_f:
            new_length = new_length * 2
        vec.resize(new_length)
        # Then convert to frequencyseries
        v_tilde = vec.to_frequencyseries()
        # Then convert frequencyseries to required length and spacing by keeping
        # only every nth sample if delta_f needs increasing, and cutting at
        # Nyquist if the max frequency is too high.
        # NOTE: This assumes that the input and output data is using binary
        #       lengths.
        i_delta_f = v_tilde.get_delta_f()
        v_tilde = v_tilde.numpy()
        df_ratio = int(delta_f / i_delta_f)
        n_freq_len = int((n-1) * df_ratio +1)
        assert(n <= len(v_tilde))
        df_ratio = int(delta_f / i_delta_f)
        v_tilde = v_tilde[:n_freq_len:df_ratio]
        vectilde = FrequencySeries(v_tilde, delta_f=delta_f, dtype=complex64)

    return FrequencySeries(vectilde * DYN_RANGE_FAC, delta_f=delta_f,
                           dtype=complex128)

def get_waveform(approximant, phase_order, amplitude_order, spin_order,
                 wf_params, start_frequency, sample_rate, length,
                 filter_rate):

    if type(approximant) is not str:
        approximant = approximant.decode('utf-8')

    delta_f = filter_rate / length
    if approximant in fd_approximants():
        hp, hc = get_fd_waveform(wf_params, approximant=approximant,
                                 phase_order=phase_order, delta_f=delta_f,
                                 spin_order=spin_order,
                                 f_lower=start_frequency,
                                 amplitude_order=amplitude_order)
        hvec = generate_detector_strain(wf_params, hp, hc)

    elif approximant in td_approximants():
        hp, hc = get_td_waveform(wf_params,
                                 approximant=approximant,
                                 phase_order=phase_order,
                                 spin_order=spin_order,
                                 delta_t=1./sample_rate,
                                 f_lower=start_frequency,
                                 amplitude_order=amplitude_order)
        if hasattr(wf_params, 'taper'):
            hp = taper_timeseries(hp, wf_params.taper)
            hc = taper_timeseries(hc, wf_params.taper)
        hvec = generate_detector_strain(wf_params, hp, hc)
    else:
        err_msg = "Canot find waveform {}".format(approximant)
        raise ValueError(err_msg)

    return make_padded_frequency_series(hvec, filter_N, delta_f=delta_f)

#### THA-related stuff

def compute_sigmasq(htilde, deltaF):
    """
    Find norm of whitened h(f) array.
    """
    # vdot is dot with complex conjugation
    return float(np.vdot(htilde, htilde).real * 4 * deltaF)


def compute_correlation(htilde1, htilde2, deltaF):
    """
    Find the real component of correlation between htilde1 and htilde2.
    """
    # vdot is dot with complex conjugation
    return float(np.vdot(htilde1, htilde2).real * 4 * deltaF)

def compute_complex_correlation(htilde1, htilde2, deltaF):
    """
    Find the complex correlation between htilde1 and htilde2.
    """
    # vdot is dot with complex conjugation
    return np.vdot(htilde1, htilde2) * 4 * deltaF

def _dpsi(theta_jn, phi_jl, beta):
    """Calculate the difference between the polarization with respect to the
    total angular momentum and the polarization with respect to the orbital
    angular momentum using code from
    https://git.ligo.org/lscsoft/pesummary/-/blob/master/pesummary/gw/conversions/angles.py#L13
    """
    if theta_jn == 0:
        return -1. * phi_jl
    n = np.array([np.sin(theta_jn), 0, np.cos(theta_jn)])
    j = np.array([0, 0, 1])
    l = np.array([
        np.sin(beta) * np.sin(phi_jl), np.sin(beta) * np.cos(phi_jl), np.cos(beta)
    ])
    p_j = np.cross(n, j)
    p_j /= np.linalg.norm(p_j)
    p_l = np.cross(n, l)
    p_l /= np.linalg.norm(p_l)
    cosine = np.inner(p_j, p_l)
    sine = np.inner(n, np.cross(p_j, p_l))
    dpsi = np.pi / 2 + np.sign(sine) * np.arccos(cosine)
    return dpsi

def _dphi(theta_jn, phi_jl, beta):
    """Calculate the difference in the phase angle between J-aligned
    and L-aligned frames using code from
    https://git.ligo.org/lscsoft/pesummary/-/blob/master/pesummary/gw/conversions/angles.py#L36

    Parameters
    ----------
    theta_jn: np.ndarray
        the angle between J and line of sight
    phi_jl: np.ndarray
        the precession phase
    beta: np.ndarray
        the opening angle (angle between J and L)
    """
    theta_jn = np.array([theta_jn])
    phi_jl = np.array([phi_jl])
    beta = np.array([beta])
    n = np.column_stack(
        [np.repeat([0], len(theta_jn)), np.sin(theta_jn), np.cos(theta_jn)]
    )
    l = np.column_stack(
        [
            np.sin(beta) * np.cos(phi_jl), np.sin(beta) * np.sin(phi_jl),
            np.cos(beta)
        ]
    )
    cosi = [np.inner(nn, ll) for nn, ll in zip(n, l)]
    inc = np.arccos(cosi)
    sign = np.sign(np.cos(theta_jn) - (np.cos(beta) * np.cos(inc)))
    cos_d = np.cos(phi_jl) * np.sin(theta_jn) / np.sin(inc)
    inds = np.logical_or(cos_d < -1, cos_d > 1)
    cos_d[inds] = np.sign(cos_d[inds]) * 1.
    dphi = -1. * sign * np.arccos(cos_d)
    return dphi[0]

def compute_beta(tmplt):
    """ Calculate beta (thetaJL) using code from
    https://lscsoft.docs.ligo.org/lalsuite/lalsimulation/_l_a_l_sim_inspiral_8c_source.html#l06105
    """
    m1 = tmplt.m1
    m2 = tmplt.m2
    s1x = tmplt.spin1x
    s1y = tmplt.spin1y
    s1z = tmplt.spin1z
    s2x = tmplt.spin2x
    s2y = tmplt.spin2y
    s2z = tmplt.spin2z
    flow = tmplt.flow

    eta = m1 * m2 / (m1 + m2) / (m1 + m2);
    v0 = ((m1 + m2) * MTSUN_SI * PI * flow) ** (1. / 3.)

    lmag = (m1 + m2) * (m1 + m2) * eta / v0
    lmag *= (1.0 + v0 * v0 * (1.5 + eta / 6.))

    s1x = m1 * m1 * s1x
    s1y = m1 * m1 * s1y
    s1z = m1 * m1 * s1z
    s2x = m2 * m2 * s2x
    s2y = m2 * m2 * s2y
    s2z = m2 * m2 * s2z
    jx = s1x + s2x
    jy = s1y + s2y
    jz = lmag + s1z + s2z

    jnorm = (jx * jx + jy * jy + jz * jz) ** (1. / 2.)
    jhatz = jz / jnorm

    return np.arccos(jhatz)

class _FDTemplate():
    def __init__(self, m1, m2, spin1x, spin1y, spin1z, spin2x, spin2y, spin2z,
                 theta, phi, iota, psi, orb_phase, sample_rate, f_lower):
        self.flow = f_lower
        self.f_final = sample_rate / 2.

        self.mass1 = float(m1)
        self.mass2 = float(m2)
        self.spin1x = float(spin1x)
        self.spin1y = float(spin1y)
        self.spin1z = float(spin1z)
        self.spin2x = float(spin2x)
        self.spin2y = float(spin2y)
        self.spin2z = float(spin2z)

        self.theta = float(theta)
        self.phi = float(phi)
        self.iota = float(iota)
        self.psi = float(psi)
        self.orb_phase = float(orb_phase)
        self.fref = self.flow

        outs = self._model_parameters_from_source_frame(
            self.m1*MSUN_SI,
            self.m2*MSUN_SI,
            self.flow,
            self.orb_phase,
            self.iota,
            self.spin1x,
            self.spin1y,
            self.spin1z,
            self.spin2x,
            self.spin2y,
            self.spin2z,
        )
        chi1_l, chi2_l, chip, thetaJN, alpha0, phi_aligned, zeta_polariz = outs
        self.chi1_l = float(chi1_l)
        self.chi2_l = float(chi2_l)
        self.chip = float(chip)
        self.thetaJN = float(thetaJN)
        self.alpha0 = float(alpha0)
        self.phi0 = float(phi_aligned)
        self.theta = float(theta)
        self.phi = float(phi)
        self.psi = float(psi)
        # This is a correction on psi, currently unused
        self.psi_corr = zeta_polariz
        self.beta = compute_beta(self)

        self.comps = {}

    def gen_harmonics_comp(self, thetaJN, alpha0, phi0, psi, df, f_final):
        # calculate cartesian spins for waveform generator
        a1 = np.sqrt(
            np.sum(np.square([self.spin1x, self.spin1y, self.spin1z]))
        )
        a2 = np.sqrt(
            np.sum(np.square([self.spin2x, self.spin2y, self.spin2z]))
        )
        phi1 = np.fmod(
            2 * np.pi + np.arctan2(self.spin1y, self.spin1x),
            2 * np.pi
        )
        phi2 = np.fmod(
            2 * np.pi + np.arctan2(self.spin2y, self.spin2x),
            2 * np.pi
        )
        phi12 = phi2 - phi1
        if phi12 < 0:
            phi12 += 2 * np.pi
        tilt1 = np.arccos(self.spin1z / a1)
        tilt2 = np.arccos(self.spin2z / a2)
        iota, spin1x, spin1y, spin1z, spin2x, spin2y, spin2z = \
            lalsim.SimInspiralTransformPrecessingNewInitialConditions(
                thetaJN, alpha0, tilt1, tilt2, phi12, a1, a2,
                self.m1*MSUN_SI, self.m2*MSUN_SI, self.fref, phi0
            )
        # generate hp, hc for given orientation with lalsimulation
        hp, hc = lalsim.SimInspiralChooseFDWaveform(
            self.m1*MSUN_SI, self.m2*MSUN_SI, spin1x, spin1y,
            spin1z, spin2x, spin2y, spin2z, 1.e6*PC_SI, iota, phi0,
            0, 0, 0, df, self.flow, f_final, self.fref, lal.CreateDict(),
            lalsim.GetApproximantFromString(self.approximant)
        )
        # 1908.05707 defines psi in J-aligned frame. Need to rotate to
        # L-aligned frame and multiply by w+, wx
        dpsi = _dpsi(thetaJN, alpha0, self.beta)
        fp = np.cos(2 * (psi - dpsi))
        fc = -1. * np.sin(2 * (psi - dpsi))
        h = (fp * hp.data.data[:] + fc * hc.data.data[:])
        # 1908.05707 defines phi in J-aligned frame. Need to rotate to
        # L-aligned frame
        h *= np.exp(2j * _dphi(thetaJN, alpha0, self.beta))
        # create LAL frequency array and return precessing harmonic
        new = CreateCOMPLEX8FrequencySeries(
            "", lal.LIGOTimeGPS(hp.epoch), 0, df, lal.SecondUnit, len(h)
        )
        new.data.data[:] = h[:]
        return new
    
    def _compute_waveform_five_comps(self, df, f_final):
        # calculate 5 harmonic decomposition as defined in 1908.05707
        hgen1a = self.gen_harmonics_comp(
            0., 0., 0., 0., df, f_final
            )
        hgen1b = self.gen_harmonics_comp(
            0., 0., np.pi/4., np.pi/4, df, f_final
        )
        # Edit these arrays in place to avoid defining new LAL arrays
        tmp = hgen1a.data.data[:] - hgen1b.data.data[:]
        hgen1b.data.data[:] = (hgen1a.data.data[:] + hgen1b.data.data[:]) / 2.
        hgen1a.data.data[:] = tmp / 2.
        h1 = hgen1a
        h5 = hgen1b
        hgen2a = self.gen_harmonics_comp(
            np.pi/2., 0., np.pi/4., np.pi/4, df, f_final
        )
        hgen2b = self.gen_harmonics_comp(
            np.pi/2., np.pi/2., 0., np.pi/4, df, f_final
        )
        tmp = hgen2a.data.data[:] + hgen2b.data.data[:]
        hgen2b.data.data[:] = -0.25 * (
            hgen2a.data.data[:] - hgen2b.data.data[:]
        )
        hgen2a.data.data[:] = -0.25 * tmp
        h2 = hgen2a
        h4 = hgen2b
        hgen3a = self.gen_harmonics_comp(
            np.pi/2., 0., 0., 0., df, f_final
        )
        hgen3b = self.gen_harmonics_comp(
            np.pi/2., np.pi/2., 0., 0., df, f_final
        )
        hgen3a.data.data[:] = \
            1./6. * (hgen3a.data.data[:] + hgen3b.data.data[:])
        h3 = hgen3a
        hs = (h1, h2, h3, h4, h5)
        return hs

    def get_whitened_normalized_comps(self, df, psd):
        """
        Return a COMPLEX8FrequencySeries of h+ and hx, whitened by the
        given ASD and normalized. The waveform is not zero-padded to
        match the length of the ASD, so its normalization depends on
        its own length.
        """
        if df in self.comps:
            return self.comps[df]
        
        
        # Generate a new wf
        h1, h2, h3, h4, h5 = self.compute_waveform_five_comps(df, self.f_final)
        flen = h1.data.length
        ASD = psd.data**0.5

        if h1.data.length > len(ASD):
            err_msg = "waveform has length greater than ASD; cannot whiten"
            raise ValueError(err_msg)
        arr_view_h1 = h1.data.data
        arr_view_h2 = h2.data.data
        arr_view_h3 = h3.data.data
        arr_view_h4 = h4.data.data
        arr_view_h5 = h5.data.data

        # Whiten
        arr_view_h1[:] /= ASD[:h1.data.length]
        arr_view_h1[:int(self.flow / df)] = 0.
        arr_view_h1[int(self.f_final/df):h1.data.length] = 0.

        arr_view_h2[:] /= ASD[:h2.data.length]
        arr_view_h2[:int(self.flow / df)] = 0.
        arr_view_h2[int(self.f_final/df):h2.data.length] = 0.

        arr_view_h3[:] /= ASD[:h3.data.length]
        arr_view_h3[:int(self.flow / df)] = 0.
        arr_view_h3[int(self.f_final/df):h3.data.length] = 0.

        arr_view_h4[:] /= ASD[:h4.data.length]
        arr_view_h4[:int(self.flow / df)] = 0.
        arr_view_h4[int(self.f_final/df):h4.data.length] = 0.

        arr_view_h5[:] /= ASD[:h5.data.length]
        arr_view_h5[:int(self.flow / df)] = 0.
        arr_view_h5[int(self.f_final/df):h5.data.length] = 0.


        # Get normalization factors and normalize
        h1sigmasq = compute_sigmasq(arr_view_h1, df)
        h2sigmasq = compute_sigmasq(arr_view_h2, df)
        h3sigmasq = compute_sigmasq(arr_view_h3, df)
        h4sigmasq = compute_sigmasq(arr_view_h4, df)
        h5sigmasq = compute_sigmasq(arr_view_h5, df)
        arr_view_h1[:] /= h1sigmasq**0.5
        arr_view_h2[:] /= h2sigmasq**0.5
        arr_view_h3[:] /= h3sigmasq**0.5
        arr_view_h4[:] /= h4sigmasq**0.5
        arr_view_h5[:] /= h5sigmasq**0.5

        h1h2corr = compute_complex_correlation(arr_view_h1, arr_view_h2, df)
        h1h3corr = compute_complex_correlation(arr_view_h1, arr_view_h3, df)
        h1h4corr = compute_complex_correlation(arr_view_h1, arr_view_h4, df)
        h1h5corr = compute_complex_correlation(arr_view_h1, arr_view_h5, df)

        arr_view_h2[:] = \
            arr_view_h2[:] - h1h2corr * arr_view_h1[:]
        arr_view_h3[:] = \
            arr_view_h3[:] - h1h3corr * arr_view_h1[:]
        arr_view_h4[:] = \
            arr_view_h4[:] - h1h4corr * arr_view_h1[:]
        arr_view_h5[:] = \
            arr_view_h5[:] - h1h5corr * arr_view_h1[:]

        h2sigmasq = compute_sigmasq(arr_view_h2, df)
        h3sigmasq = compute_sigmasq(arr_view_h3, df)
        h4sigmasq = compute_sigmasq(arr_view_h4, df)
        h5sigmasq = compute_sigmasq(arr_view_h5, df)
        arr_view_h2[:] /= h2sigmasq**0.5
        arr_view_h3[:] /= h3sigmasq**0.5
        arr_view_h4[:] /= h4sigmasq**0.5
        arr_view_h5[:] /= h5sigmasq*0.5

        h2h3corr = compute_complex_correlation(arr_view_h2, arr_view_h3, df)
        h2h4corr = compute_complex_correlation(arr_view_h2, arr_view_h4, df)
        h2h5corr = compute_complex_correlation(arr_view_h2, arr_view_h5, df)
        arr_view_h3[:] = \
            arr_view_h3[:] - h2h3corr * arr_view_h2[:]
        arr_view_h4[:] = \
            arr_view_h4[:] - h2h4corr * arr_view_h2[:]
        arr_view_h5[:] = \
            arr_view_h5[:] - h2h5corr * arr_view_h2[:]
        h3sigmasq = compute_sigmasq(arr_view_h3, df)
        h4sigmasq = compute_sigmasq(arr_view_h4, df)
        h5sigmasq = compute_sigmasq(arr_view_h5, df)
        arr_view_h3[:] /= h3sigmasq**0.5
        arr_view_h4[:] /= h4sigmasq**0.5
        arr_view_h5[:] /= h5sigmasq**0.5

        h3h4corr = compute_complex_correlation(arr_view_h3, arr_view_h4, df)
        h3h5corr = compute_complex_correlation(arr_view_h3, arr_view_h5, df)
        arr_view_h4[:] = \
            arr_view_h4[:] - h3h4corr * arr_view_h3[:]
        arr_view_h5[:] = \
            arr_view_h5[:] - h3h5corr * arr_view_h3[:]
        h4sigmasq = compute_sigmasq(arr_view_h4, df)
        h5sigmasq = compute_sigmasq(arr_view_h5, df)
        arr_view_h4[:] /= h4sigmasq**0.5
        arr_view_h5[:] /= h5sigmasq**0.5

        h4h5corr = compute_complex_correlation(arr_view_h4, arr_view_h5, df)
        arr_view_h5[:] = \
            arr_view_h5[:] - h4h5corr * arr_view_h4[:]
        h5sigmasq = compute_sigmasq(arr_view_h5, df)
        arr_view_h5[:] /= h5sigmasq**0.5

        h1P = FrequencySeries(h1.data.data[:], delta_f=h1.deltaF, epoch=h1.epoch)
        h2P = FrequencySeries(h2.data.data[:], delta_f=h2.deltaF, epoch=h2.epoch)
        h3P = FrequencySeries(h3.data.data[:], delta_f=h1.deltaF, epoch=h3.epoch)
        h4P = FrequencySeries(h4.data.data[:], delta_f=h2.deltaF, epoch=h4.epoch)
        h5P = FrequencySeries(h5.data.data[:], delta_f=h1.deltaF, epoch=h5.epoch)
        
        self.comps[df] = [h1P, h2P, h3P, h4P, h5P]
        
        return h1P, h2P, h3P, h4P, h5P
    
    def generate_random_signal(self, df):
        thetaJN = random.random() * np.pi
        alpha0 = random.random() * 2 * np.pi
        phi0 = random.random() * 2 * np.pi
        psi = random.random() * 2 * np.pi
        
        hp, hc = self.gen_phenom_p_comp(thetaJN, alpha0, phi0, df)
        flen = hp.data.length
        psd = aLIGOZeroDetHighPower(flen, df, 30.)
        ASD = psd.data**0.5

        arr_view_h1 = hp.data.data
        arr_view_h2 = hc.data.data

        # Whiten
        arr_view_h1[:] /= ASD[:hp.data.length]
        arr_view_h1[:int(self.flow / df)] = 0.
        arr_view_h1[int(self.f_final/df):hp.data.length] = 0.

        arr_view_h2[:] /= ASD[:hp.data.length]
        arr_view_h2[:int(self.flow / df)] = 0.
        arr_view_h2[int(self.f_final/df):hp.data.length] = 0.
        
        hpP = FrequencySeries(hp.data.data[:], delta_f=hp.deltaF, epoch=hp.epoch)
        hcP = FrequencySeries(hc.data.data[:], delta_f=hc.deltaF, epoch=hc.epoch)

        return hpP * np.sin(2*psi) + hcP * np.cos(2*psi)
    
    def test_five_comps_orthogonality(self, df, psd):

        hs = self.get_whitened_normalized_comps(df, psd)

        for i in range(5):
            for j in range(i+1,5):
                absval = abs(overlap_cplx(hs[i], hs[j], low_frequency_cutoff=30.))
                if absval > 1E-10:
                    print (i, j, abs(overlap_cplx(hs[i], hs[j], low_frequency_cutoff=30.)))


class PhenomPv2Template(_FDTemplate):
    approximant = "IMRPhenomPv2"

    def _model_parameters_from_source_frame(self, *args):
        return lalsim.SimIMRPhenomPCalculateModelParametersFromSourceFrame(
            *args, lalsim.IMRPhenomPv2_V
        )


class PhenomXPTemplate(_FDTemplate):
    approximant = "IMRPhenomXP" 

    def _model_parameters_from_source_frame(self, *args):
        return lalsim.SimIMRPhenomXPCalculateModelParametersFromSourceFrame(
            *args, None
        )



def get_tha_waveform(approximant, wf_params, start_frequency, sample_rate,
                     length, filter_rate, psd):

    try:
        approximant = approximant.decode()
    except AttributeError:
        # Already a str
        pass

    assert(sample_rate == filter_rate)

    delta_f = filter_rate / length
   
    mass1 = template_params.mass1
    mass2 = template_params.mass2
    spin1x = template_params.spin1x
    spin1y = template_params.spin1y
    spin1z = template_params.spin1z
    spin2x = template_params.spin2x
    spin2y = template_params.spin2y
    spin2z = template_params.spin2z
    theta = template_params.latitude
    phi = template_params.longitude
    iota = template_params.inclination
    psi = template_params.polarization
    orb_phase = template_params.orbital_phase

    if approximant == "IMRPhenomPv2":
        cls = PhenomPv2Template
    elif approximant == "IMRPhenomXP":
        cls = PhenomXPTemplate
    else:
        print (approximant)
        raise ValueError("Can only do PhenomPv2 and PhenomXP right now!")
    curr_tmp = cls(mass1, mass2, spin1x, spin1y, spin1z, spin2x,
                   spin2y, spin2z, theta, phi, iota, psi,
                   orb_phase, sample_rate, start_frequency)


    #curr_tmp.test_five_comps_orthogonality(delta_f, psd)

    return curr_tmp.get_whitened_normalized_comps(delta_f, psd)
    


aprs = sorted(list(set(td_approximants() + fd_approximants())))

#File output Settings
parser = ArgumentParser(description=__doc__)
parser.add_argument("--match-file", dest="out_file", metavar="FILE",
                    required=True, help="File to output match results")
parser.add_argument("--verbose", action='store_true', default=False,
                    help="Print verbose statements")
parser.add_argument("--version", action="version",
                    version=pycbc.version.git_verbose_msg)

#Template Settings
parser.add_argument("--template-file", dest="bank_file", metavar="FILE",
                    required=True, help="SimInspiral or SnglInspiral XML file "
                                        "containing the template parameters")
parser.add_argument("--total-mass-divide", type=float,
                    help="Total mass to switch from --template-approximant to "
                         "--highmass-approximant.")
parser.add_argument("--highmass-approximant", choices=aprs,
                    help="Waveform approximant for highmass templates.")
parser.add_argument("--template-approximant", choices=aprs, required=True,
                    help="Waveform approximant for templates")
parser.add_argument("--template-phase-order", default=-1, type=int,
                    help="PN order to use for the template phase")
parser.add_argument("--template-amplitude-order", default=-1, type=int,
                    help="PN order to use for the template amplitude")
parser.add_argument("--template-spin-order", default=-1, type=int,
                    help="PN order to use for the template spin terms")
parser.add_argument("--template-start-frequency", type=float,
                    help="Starting frequency for templates [Hz]")
parser.add_argument("--template-sample-rate", type=float,
                    help="Sample rate for templates [Hz]")

#Signal Settings
parser.add_argument("--signal-file", dest="sim_file", metavar="FILE",
                    required=True, help="SimInspiral or SnglInspiral XML file "
                                        "containing the signal parameters")
parser.add_argument("--signal-approximant", choices=aprs, required=True,
                    help="Waveform approximant for signals")
parser.add_argument("--signal-phase-order", default=-1, type=int,
                    help="PN order to use for the signal phase")
parser.add_argument("--signal-spin-order", default=-1, type=int,
                    help="PN order to use for the signal spin terms")
parser.add_argument("--signal-amplitude-order", default=-1, type=int,
                    help="PN order to use for the signal amplitude")
parser.add_argument("--signal-start-frequency", type=float,
                    help="Starting frequency for signals [Hz]")
parser.add_argument("--signal-sample-rate", type=float,
                    help="Sample rate for signals [Hz]")
parser.add_argument("--use-sky-location", action='store_true',
                    help="Inject into a theoretical detector at the celestial "
                         "North pole of a non-rotating Earth rather than overhead")

#Filtering Settings
parser.add_argument('--filter-low-frequency-cutoff', metavar='FREQ', type=float,
                    required=True, help='low frequency cutoff of matched filter')
parser.add_argument("--filter-sample-rate", type=float, required=True,
                    help="Filter sample rate [Hz]")
parser.add_argument("--filter-signal-length", type=int, required=True,
                    help="Length of signal for filtering, shoud be longer "
                         "than all waveforms and include some padding")

# add PSD options
pycbc.psd.insert_psd_option_group(parser, output=False)

# Insert the data reading options
pycbc.strain.insert_strain_option_group(parser)

#hardware support
pycbc.scheme.insert_processing_option_group(parser)
pycbc.fft.insert_fft_option_group(parser)

#Restricted maximization
parser.add_argument("--mchirp-window", type=str, metavar="FRACTION",
                    help="Ignore templates whose chirp mass deviates from "
                         "signal's one more than given fraction. Provide two "
                         "comma separated numbers to have different bounds "
                         "above and below the signal's, with below bound "
                         "listed first.")
parser.add_argument("--tau0-window", type=float, metavar="TIME", default=None,
                    help="Ignore templates whose Newtonian order chirp time "
                         "(tau0) varies from the signals by more than the "
                         "supplied amount. If option is not provided no "
                         "window on tau0 is used. The "
                         "filter-low-frequency-cutoff is used to calculate "
                         "the value of tau0 for all cases. Provided in units "
                         "of seconds.")

options = parser.parse_args()

pycbc.init_logging(options.verbose)

pycbc.psd.verify_psd_options(options, parser)

if options.psd_estimation:
    pycbc.strain.verify_strain_options(options, parser)

if options.total_mass_divide and options.highmass_approximant is None:
    parser.error("You must provide a highmass-approximant if you want total-mass-divide.")

if options.mchirp_window is None:
    def outside_mchirp_window(template_mchirp, signal_mchirp):
        return False
elif ',' in options.mchirp_window:
    # asymmetric chirp mass window
    mchirp_window_lower = float(options.mchirp_window.split(",")[0])
    mchirp_window_upper = float(options.mchirp_window.split(",")[1])
    def outside_mchirp_window(template_mchirp, signal_mchirp):
        delta = (template_mchirp - signal_mchirp) / signal_mchirp
        return delta > mchirp_window_upper or -delta > mchirp_window_lower
else:
    # symmetric chirp mass window
    mchirp_window = float(options.mchirp_window)
    def outside_mchirp_window(template_mchirp, signal_mchirp):
        return abs(signal_mchirp - template_mchirp) > \
                (mchirp_window * signal_mchirp)

if options.tau0_window is None:
    def outside_tau0_window(template_tau0, signal_tau0, window):
        return False
else:
    def outside_tau0_window(template_tau0, signal_tau0, window):
        return abs(signal_tau0 - template_tau0) > window

# If we are going to use h(t) to estimate a PSD we need h(t)
if options.psd_estimation:
    logging.info("Obtaining h(t) for PSD generation")
    strain = pycbc.strain.from_cli(options, pycbc.DYN_RANGE_FAC)
else:
    strain = None

if options.template_sample_rate is not None:
    template_sample_rate = options.template_sample_rate
else:
    template_sample_rate = options.filter_sample_rate
if options.signal_sample_rate is not None:
    signal_sample_rate = options.signal_sample_rate
else:
    signal_sample_rate = options.filter_sample_rate

ctx = pycbc.scheme.from_cli(options)

logging.info('Reading template bank')
temp_bank = TemplateBank(options.bank_file)
template_table = temp_bank.table
logging.info("  %d templates", len(template_table))

logging.info('Reading simulation list')
indoc = ligolw_utils.load_filename(options.sim_file, False,
                                   contenthandler=LIGOLWContentHandler)
try:
    signal_table = lsctables.SimInspiralTable.get_table(indoc)
except ValueError:
    signal_table = lsctables.SnglInspiralTable.get_table(indoc)
logging.info("  %d signal waveforms", len(signal_table))

logging.info("Matches will be written to %s", options.out_file)

filter_N = int(options.filter_signal_length * options.filter_sample_rate)
filter_n = filter_N // 2 + 1
filter_delta_f = 1.0 / float(options.filter_signal_length)

logging.info("Reading and Interpolating PSD")
psd = pycbc.psd.from_cli(options, filter_n, filter_delta_f,
                         options.filter_low_frequency_cutoff, strain=strain,
                         dyn_range_factor=pycbc.DYN_RANGE_FAC,
                         precision='double')
  
with ctx: 
    pycbc.fft.from_cli(options)

    logging.info("Pregenerating Signals")

    signals = []
    # Used for getting mchirp/tau0 later
    sig_m1 = []
    sig_m2 = []
    prog = tqdm(total=len(signal_table), disable=(not options.verbose))
    for index, signal_params in enumerate(signal_table):
        prog.update(1)
        if not options.use_sky_location and hasattr(signal_params, 'latitude'):
            signal_params.latitude = 0.
            signal_params.longitude = 0.
        stilde = get_waveform(options.signal_approximant,
                              options.signal_phase_order,
                              options.signal_amplitude_order,
                              options.signal_spin_order,
                              signal_params,
                              options.signal_start_frequency,
                              signal_sample_rate,
                              filter_N, options.filter_sample_rate)
        s_norm = sigmasq(stilde, psd=psd,
                         low_frequency_cutoff=options.filter_low_frequency_cutoff)
        stilde /= psd**0.5
        signals.append((stilde, s_norm, [], signal_params))
        sig_m1.append(signal_params.mass1)
        sig_m2.append(signal_params.mass2)
    prog.close()
    sig_m1 = array(sig_m1)
    sig_m2 = array(sig_m2)
    sig_tau0, _ = mass1_mass2_to_tau0_tau3(sig_m1, sig_m2,
                                           options.filter_low_frequency_cutoff)
    sig_mchirp, _ = mass1_mass2_to_mchirp_eta(sig_m1, sig_m2)

    logging.info("Calculating Mchirp and Tau0")
    template_m1 = array([tp.mass1 for tp in template_table])
    template_m2 = array([tp.mass2 for tp in template_table])
    template_tau0, _ = mass1_mass2_to_tau0_tau3(template_m1, template_m2,
                                                options.filter_low_frequency_cutoff)
    template_mchirp, _ = mass1_mass2_to_mchirp_eta(template_m1, template_m2)

    logging.info("Calculating Overlaps")

    flow_warned = False
    prog = tqdm(total=len(template_table), disable=(not options.verbose))
    for index, template_params in enumerate(template_table):
        prog.update(1)
        f_lower = template_params.f_lower
        # If not set fall back on filter low-freq cutoff
        if f_lower < 0.000001:
            f_lower = options.filter_low_frequency_cutoff
        if f_lower < options.filter_low_frequency_cutoff:
            # Not entirely clear what to do here?
            if not flow_warned:
                logging.warn("Template's flower is smaller than "
                             "--filter-low-frequency-cutoff. Raising flower "
                             "of template to match.")
                flow_warned=True
            f_lower = options.filter_low_frequency_cutoff

        hcomps = None
        for sidx, (stilde, s_norm, matches, signal_params) in enumerate(signals):
            # Check if we need to look at this
            check_logic = stilde is None
            check_logic |= outside_tau0_window(template_tau0[index],
                                               sig_tau0[sidx],
                                               options.tau0_window)
            check_logic |= outside_mchirp_window(template_mchirp[index],
                                                 sig_mchirp[sidx])
            if check_logic:
                matches.append([0.,0.,0.,0.,0.,0.,0.,0.,0.])
                continue

            # Generate htilde if we haven't already done so
            if hcomps is None:
                # FIXME: I would like to remove the approximant options and
                #        have this entirely controlled by the template bank.
                #        However, while we are still using the high-mass divide
                #        in XML banks, this must be retained.
                try:
                    this_approximant = template_params['approximant']
                except:
                    this_approximant = options.template_approximant
                    if options.total_mass_divide is not None and (template_params.mass1+template_params.mass2) >= options.total_mass_divide:
                        this_approximant = options.highmass_approximant

                hcomps = get_tha_waveform(this_approximant,
                                          template_params,
                                          options.template_start_frequency,
                                          template_sample_rate,
                                          filter_N, options.filter_sample_rate,
                                          psd)

            curr_matches, _ = match_tha(hcomps, stilde,
                                        template_params['num_comps'],
                                        low_frequency_cutoff=f_lower,
                                        stilde_norm=s_norm)

            matches.append(curr_matches)
    prog.close()

logging.info("Determining maximum overlaps and outputting results")

# Find the maximum overlap in the bank and output to a file
with open(options.out_file, "w") as fout:
    for i, (stilde, s_norm, matches, sim_template) in enumerate(signals):
        matches = array(matches)
        match_str = "%5.5f " % max(matches[:,0])
        match_str += "%5.5f " % max(matches[:,1])
        match_str += "%5.5f " % max(matches[:,2])
        match_str += "%5.5f " % max(matches[:,3])
        match_str += "%5.5f " % max(matches[:,4])
        match_str += "%5.5f " % max(matches[:,5])
        match_str += "%5.5f " % max(matches[:,6])
        match_str += "%5.5f " % max(matches[:,7])
        match_str += "%5.5f " % max(matches[:,8])
        match_str += " " + options.bank_file
        match_str += " " + str(matches[:,0].argmax())
        match_str += " " + str(matches[:,1].argmax())
        match_str += " " + str(matches[:,2].argmax())
        match_str += " " + str(matches[:,3].argmax())
        match_str += " " + str(matches[:,4].argmax())
        match_str += " " + str(matches[:,5].argmax())
        match_str += " " + str(matches[:,6].argmax())
        match_str += " " + str(matches[:,7].argmax())
        match_str += " " + str(matches[:,8].argmax())
        match_str += " " + options.sim_file
        match_str += " %d" % i
        match_str += " %5.5f\n" % s_norm
        fout.write(match_str)
